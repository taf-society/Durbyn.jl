<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>ARAR/ARARMA · Durbyn.jl</title><meta name="title" content="ARAR/ARARMA · Durbyn.jl"/><meta property="og:title" content="ARAR/ARARMA · Durbyn.jl"/><meta property="twitter:title" content="ARAR/ARARMA · Durbyn.jl"/><meta name="description" content="Documentation for Durbyn.jl."/><meta property="og:description" content="Documentation for Durbyn.jl."/><meta property="twitter:description" content="Documentation for Durbyn.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/theme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="Durbyn.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">Durbyn.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../quickstart/">Quick Start</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../expsmoothing/">Exponential Smoothing</a></li><li><a class="tocitem" href="../intermittent/">Intermittent Demand</a></li><li><a class="tocitem" href="../arima/">ARIMA</a></li><li class="is-active"><a class="tocitem" href>ARAR/ARARMA</a><ul class="internal"><li><a class="tocitem" href="#ARAR-Model"><span>ARAR Model</span></a></li><li class="toplevel"><a class="tocitem" href="#Forecasing-in-Julia-using-Arar-Model"><span>Forecasing in Julia using Arar Model</span></a></li><li><a class="tocitem" href="#ARARMA-Model"><span>ARARMA Model</span></a></li><li class="toplevel"><a class="tocitem" href="#Forecasing-in-Julia-using-Ararma-Model"><span>Forecasing in Julia using Ararma Model</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>ARAR/ARARMA</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>ARAR/ARARMA</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/taf-society/Durbyn.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/taf-society/Durbyn.jl/blob/main/docs/src/ararma.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="ARAR-and-ARARMA-Models"><a class="docs-heading-anchor" href="#ARAR-and-ARARMA-Models">ARAR and ARARMA Models</a><a id="ARAR-and-ARARMA-Models-1"></a><a class="docs-heading-anchor-permalink" href="#ARAR-and-ARARMA-Models" title="Permalink"></a></h1><h2 id="ARAR-Model"><a class="docs-heading-anchor" href="#ARAR-Model">ARAR Model</a><a id="ARAR-Model-1"></a><a class="docs-heading-anchor-permalink" href="#ARAR-Model" title="Permalink"></a></h2><p>The ARAR model applies a memory-shortening transformation; if the underlying process of a time series <span>$\{Y_t,\ t=1,2,\ldots,n\}$</span> is “long-memory”, it then fits an autoregressive model.</p><h3 id="Memory-Shortening"><a class="docs-heading-anchor" href="#Memory-Shortening">Memory Shortening</a><a id="Memory-Shortening-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Shortening" title="Permalink"></a></h3><p>The model follows five steps to classify <span>$Y_t$</span> and take one of three actions:</p><ul><li><strong>L:</strong> declare <span>$Y_t$</span> as long memory and form <span>$\tilde Y_t = Y_t - \hat\phi\, Y_{t-\hat\tau}$</span></li><li><strong>M:</strong> declare <span>$Y_t$</span> as moderately long memory and form <span>$\tilde Y_t = Y_t - \hat\phi_1 Y_{t-1} - \hat\phi_2 Y_{t-2}$</span></li><li><strong>S:</strong> declare <span>$Y_t$</span> as short memory.</li></ul><p>If <span>$Y_t$</span> is declared <strong>L</strong> or <strong>M</strong>, the series is transformed again until the transformed series is classified as short memory. (At most three transformations are applied; in practice, more than two is rare.)</p><h3 id="Steps"><a class="docs-heading-anchor" href="#Steps">Steps</a><a id="Steps-1"></a><a class="docs-heading-anchor-permalink" href="#Steps" title="Permalink"></a></h3><ol><li>For each <span>$\tau=1,2,\ldots,15$</span>, find <span>$\hat\phi(\tau)$</span> that minimizes  <p class="math-container">\[\mathrm{ERR}(\phi,\tau) \;=\; 
\frac{\displaystyle\sum_{t=\tau+1}^{n}\!\big(Y_t-\phi\,Y_{t-\tau}\big)^2}
     {\displaystyle\sum_{t=\tau+1}^{n}\!Y_t^{\,2}},\]</p>then set <span>$\mathrm{Err}(\tau)=\mathrm{ERR}\big(\hat\phi(\tau),\tau\big)$</span> and choose   <span>$\hat\tau=\arg\min_{\tau}\mathrm{Err}(\tau)$</span>.</li><li>If <span>$\mathrm{Err}(\hat\tau)\le 8/n$</span>, then <span>$Y_t$</span> is a long-memory series.</li><li>If <span>$\hat\phi(\hat\tau)\ge 0.93$</span> and <span>$\hat\tau&gt;2$</span>, then <span>$Y_t$</span> is a long-memory series.</li><li>If <span>$\hat\phi(\hat\tau)\ge 0.93$</span> and <span>$\hat\tau\in\{1,2\}$</span>, then <span>$Y_t$</span> is a long-memory series.</li><li>If <span>$\hat\phi(\hat\tau)&lt;0.93$</span>, then <span>$Y_t$</span> is a short-memory series.</li></ol><h3 id="Subset-Autoregressive-Model"><a class="docs-heading-anchor" href="#Subset-Autoregressive-Model">Subset Autoregressive Model</a><a id="Subset-Autoregressive-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Subset-Autoregressive-Model" title="Permalink"></a></h3><p>We now describe how ARAR fits an autoregression to the mean-corrected series   <span>$X_t=S_t-\bar S$</span>, <span>$t=k+1,\ldots,n$</span>, where <span>$\{S_t\}$</span> is the memory-shortened version of <span>$\{Y_t\}$</span> obtained above and <span>$\bar S$</span> is the sample mean of <span>$S_{k+1},\ldots,S_n$</span>.</p><p>The fitted model has the form</p><p class="math-container">\[X_t \;=\; \phi_1 X_{t-1} \;+\; \phi_{l_1} X_{t-l_1} \;+\; \phi_{l_2} X_{t-l_2} \;+\; \phi_{l_3} X_{t-l_3} \;+\; Z_t,
\qquad Z_t \sim \mathrm{WN}(0,\sigma^2).\]</p><h3 id="Yule–Walker-Equations"><a class="docs-heading-anchor" href="#Yule–Walker-Equations">Yule–Walker Equations</a><a id="Yule–Walker-Equations-1"></a><a class="docs-heading-anchor-permalink" href="#Yule–Walker-Equations" title="Permalink"></a></h3><p>The coefficients <span>$\phi_j$</span> and the noise variance <span>$\sigma^2$</span> follow from the Yule–Walker equations for given lags <span>$l_1,l_2,l_3$</span>:</p><p class="math-container">\[\begin{bmatrix}
1 &amp; \hat\rho(l_1-1) &amp; \hat\rho(l_2-1) &amp; \hat\rho(l_3-1)\\
\hat\rho(l_1-1) &amp; 1 &amp; \hat\rho(l_2-l_1) &amp; \hat\rho(l_3-l_1)\\
\hat\rho(l_2-1) &amp; \hat\rho(l_2-l_1) &amp; 1 &amp; \hat\rho(l_3-l_2)\\
\hat\rho(l_3-1) &amp; \hat\rho(l_3-l_1) &amp; \hat\rho(l_3-l_2) &amp; 1
\end{bmatrix}
\begin{bmatrix}
\phi_1\\[2pt]
\phi_{l_1}\\[2pt]
\phi_{l_2}\\[2pt]
\phi_{l_3}
\end{bmatrix}
=
\begin{bmatrix}
\hat\rho(1)\\[2pt]
\hat\rho(l_1)\\[2pt]
\hat\rho(l_2)\\[2pt]
\hat\rho(l_3)
\end{bmatrix}.\]</p><p class="math-container">\[\sigma^2 \;=\; \hat\gamma(0)\,\Big( 1 - \phi_1\hat\rho(1) - \phi_{l_1}\hat\rho(l_1) - \phi_{l_2}\hat\rho(l_2) - \phi_{l_3}\hat\rho(l_3) \Big),\]</p><p>where <span>$\hat\gamma(j)$</span> and <span>$\hat\rho(j)$</span>, <span>$j=0,1,2,\ldots$</span>, are the sample autocovariances and autocorrelations of <span>$X_t$</span>.   The algorithm computes <span>$\phi(\cdot)$</span> for each set of lags with <span>$1&lt;l_1&lt;l_2&lt;l_3\le m$</span> (<span>$m$</span> typically 13 or 26) and selects the model with minimal Yule–Walker estimate of <span>$\sigma^2$</span>.</p><h3 id="Forecasting"><a class="docs-heading-anchor" href="#Forecasting">Forecasting</a><a id="Forecasting-1"></a><a class="docs-heading-anchor-permalink" href="#Forecasting" title="Permalink"></a></h3><p>If the short-memory filter found in the first step has coefficients <span>$\Psi_0,\Psi_1,\ldots,\Psi_k$</span> (<span>$k\ge0$</span>, <span>$\Psi_0=1$</span>), then</p><p class="math-container">\[S_t \;=\; \Psi(B)Y_t \;=\; Y_t + \Psi_1 Y_{t-1} + \cdots + \Psi_k Y_{t-k},
\qquad
\Psi(B) \;=\; 1 + \Psi_1 B + \cdots + \Psi_k B^k .\]</p><p>If the subset AR coefficients are <span>$\phi_1,\phi_{l_1},\phi_{l_2},\phi_{l_3}$</span> then, for <span>$X_t=S_t-\bar S$</span>, </p><p class="math-container">\[\phi(B)X_t \;=\; Z_t, \qquad 
\phi(B) \;=\; 1 - \phi_1 B - \phi_{l_1} B^{l_1} - \phi_{l_2} B^{l_2} - \phi_{l_3} B^{l_3}.\]</p><p>From the two displays above,</p><p class="math-container">\[\xi(B)Y_t \;=\; \phi(1)\,\bar S \;+\; Z_t, 
\qquad \xi(B) \;=\; \Psi(B)\,\phi(B).\]</p><p>Assuming this model is appropriate and <span>$Z_t$</span> is uncorrelated with <span>$Y_j$</span> for <span>$j&lt;t$</span>, the minimum-MSE linear predictors <span>$P_n Y_{n+h}$</span> of <span>$Y_{n+h}$</span> (for <span>$n&gt;k+l_3$</span>) satisfy the recursion</p><p class="math-container">\[P_n Y_{n+h} \;=\; - \sum_{j=1}^{k+l_3} \xi_j \, P_n Y_{n+h-j} \;+\; \phi(1)\,\bar S, \qquad h\ge 1,\]</p><p>with initial conditions <span>$P_n Y_{n+h}=Y_{n+h}$</span> for <span>$h\le 0$</span>.</p><h3 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h3><ul><li>Brockwell, Peter J., and Richard A. Davis. <em>Introduction to Time Series and Forecasting</em>. <a href="https://link.springer.com/book/10.1007/978-3-319-29854-2">Springer</a> (2016)</li></ul><h1 id="Forecasing-in-Julia-using-Arar-Model"><a class="docs-heading-anchor" href="#Forecasing-in-Julia-using-Arar-Model">Forecasing in Julia using Arar Model</a><a id="Forecasing-in-Julia-using-Arar-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Forecasing-in-Julia-using-Arar-Model" title="Permalink"></a></h1><pre><code class="language-julia hljs">using Durbyn
using Durbyn.Ararma

ap = air_passengers()

fit = arar(ap, max_ar_depth = 13)
fc  = forecast(fit, h = 12)
plot(fc)
</code></pre><h2 id="ARARMA-Model"><a class="docs-heading-anchor" href="#ARARMA-Model">ARARMA Model</a><a id="ARARMA-Model-1"></a><a class="docs-heading-anchor-permalink" href="#ARARMA-Model" title="Permalink"></a></h2><p><strong>ARARMA</strong> extends the ARAR approach by first applying an adaptive <strong>AR</strong> prefilter to shorten memory (the <em>ARAR</em> stage), and then fitting a short-memory <strong>ARMA(p, q)</strong> model on the prefiltered residuals. The goal is to capture long/persistent structure via a composed AR filter <span>$\Psi(B)$</span> and the remaining short-term dynamics via an ARMA kernel.</p><p>Given a univariate series <span>$\{Y_t,\ t=1,2,\ldots,n\}$</span>, ARARMA produces a fitted model and forecasting mechanism that combine both stages.</p><h3 id="Stage-1-—-Memory-Shortening-(ARAR)"><a class="docs-heading-anchor" href="#Stage-1-—-Memory-Shortening-(ARAR)">Stage 1 — Memory Shortening (ARAR)</a><a id="Stage-1-—-Memory-Shortening-(ARAR)-1"></a><a class="docs-heading-anchor-permalink" href="#Stage-1-—-Memory-Shortening-(ARAR)" title="Permalink"></a></h3><p>As in ARAR, we iteratively test for long memory and, if detected, apply a memory-shortening AR filter. At iteration r, the procedure evaluates delays <span>$\tau=1,\ldots,15$</span> by ordinary least squares and scores each delay by a relative error measure:</p><p class="math-container">\[\mathrm{ERR}(\phi,\tau)
\;=\;
\frac{\displaystyle\sum_{t=\tau+1}^{n}\!\big(Y_t-\phi\,Y_{t-\tau}\big)^2}
     {\displaystyle\sum_{t=\tau+1}^{n}\!Y_t^{\,2}},
\qquad
\hat\phi(\tau)\in\arg\min_{\phi}\ \mathrm{ERR}(\phi,\tau).\]</p><p>Let <span>$\mathrm{Err}(\tau) = \mathrm{ERR}\!\big(\hat\phi(\tau),\tau\big)$</span> and <span>$\hat\tau=\arg\min_\tau \mathrm{Err}(\tau)$</span>. Then:</p><ul><li>If <span>$\mathrm{Err}(\hat\tau)\le 8/n$</span> or if <span>$\hat\phi(\hat\tau)\ge 0.93$</span> with <span>$\hat\tau&gt;2$</span>, declare long memory and filter:<p class="math-container">\[\tilde Y_t \;=\; Y_t - \hat\phi\,Y_{t-\hat\tau}.\]</p></li><li>If <span>$\hat\phi(\hat\tau)\ge 0.93$</span> with <span>$\hat\tau\in\{1,2\}$</span>, fit an AR(2) at lags 1 and 2 by normal equations and filter:<p class="math-container">\[\tilde Y_t \;=\; Y_t - \hat\phi_1 Y_{t-1} - \hat\phi_2 Y_{t-2}.\]</p></li><li>Otherwise, stop.</li></ul><p>Each successful reduction composes the prefilter polynomial <span>$\Psi(B)$</span> (with <span>$\Psi_0=1$</span>):</p><p class="math-container">\[S_t \;=\; \Psi(B)Y_t \;=\; Y_t + \Psi_1 Y_{t-1} + \cdots + \Psi_k Y_{t-k},
\qquad
\Psi(B) \;=\; 1 + \Psi_1 B + \cdots + \Psi_k B^k.\]</p><p>The reduction loop terminates when short memory is reached or after three passes (rarely more than two are needed in practice).</p><h3 id="Stage-2-—-Best-Lag-Subset-AR-(on-the-prefiltered-series)"><a class="docs-heading-anchor" href="#Stage-2-—-Best-Lag-Subset-AR-(on-the-prefiltered-series)">Stage 2 — Best-Lag Subset AR (on the prefiltered series)</a><a id="Stage-2-—-Best-Lag-Subset-AR-(on-the-prefiltered-series)-1"></a><a class="docs-heading-anchor-permalink" href="#Stage-2-—-Best-Lag-Subset-AR-(on-the-prefiltered-series)" title="Permalink"></a></h3><p>Let <span>$X_t = S_t - \bar S$</span> with <span>$\bar S$</span> the sample mean of the final prefiltered series. Over 4-term lag tuples <span>$(1,i,j,k)$</span> satisfying <span>$1&lt;i&lt;j&lt;k\le m$</span> (with <span>$m$</span> typically 13 or 26), we fit the subset AR:</p><p class="math-container">\[X_t \;=\; \phi_1 X_{t-1} \;+\; \phi_{i} X_{t-i} \;+\; \phi_{j} X_{t-j} \;+\; \phi_{k} X_{t-k} \;+\; Z_t,
\qquad Z_t\sim \mathrm{WN}(0,\sigma^2).\]</p><p>Yule–Walker equations (using sample autocorrelations <span>$\hat\rho(\cdot)$</span> of <span>$X_t$</span>) yield the coefficients:</p><p class="math-container">\[\begin{bmatrix}
1 &amp; \hat\rho(i-1) &amp; \hat\rho(j-1) &amp; \hat\rho(k-1)\\
\hat\rho(i-1) &amp; 1 &amp; \hat\rho(j-i) &amp; \hat\rho(k-i)\\
\hat\rho(j-1) &amp; \hat\rho(j-i) &amp; 1 &amp; \hat\rho(k-j)\\
\hat\rho(k-1) &amp; \hat\rho(k-i) &amp; \hat\rho(k-j) &amp; 1
\end{bmatrix}
\!\!
\begin{bmatrix}
\phi_1\\[2pt]\phi_i\\[2pt]\phi_j\\[2pt]\phi_k
\end{bmatrix}
=
\begin{bmatrix}
\hat\rho(1)\\[2pt]\hat\rho(i)\\[2pt]\hat\rho(j)\\[2pt]\hat\rho(k)
\end{bmatrix}.\]</p><p>The implied variance is</p><p class="math-container">\[\sigma^2 \;=\; \hat\gamma(0)\,\Big(1 - \phi_1 \hat\rho(1) - \phi_i \hat\rho(i) - \phi_j \hat\rho(j) - \phi_k \hat\rho(k)\Big),\]</p><p>where <span>$\hat\gamma(\cdot)$</span> are sample autocovariances of <span>$X_t$</span>. The algorithm selects <span>$(1,i,j,k)$</span> minimizing this <span>$\sigma^2$</span>.</p><p>Define the <strong>composite AR kernel</strong> by convolving the prefilter with the selected subset AR:</p><p class="math-container">\[\phi(B) \;=\; 1 - \phi_1 B - \phi_i B^{i} - \phi_j B^{j} - \phi_k B^{k},
\qquad
\xi(B) \;=\; \Psi(B)\,\phi(B).\]</p><p>Let <span>$c = \big(1-\phi_1-\phi_i-\phi_j-\phi_k\big)\,\bar S$</span> be the AR intercept.</p><h3 id="Stage-3-—-Short-Memory-ARMA(p,-q)-on-AR-Residuals"><a class="docs-heading-anchor" href="#Stage-3-—-Short-Memory-ARMA(p,-q)-on-AR-Residuals">Stage 3 — Short-Memory ARMA(p, q) on AR Residuals</a><a id="Stage-3-—-Short-Memory-ARMA(p,-q)-on-AR-Residuals-1"></a><a class="docs-heading-anchor-permalink" href="#Stage-3-—-Short-Memory-ARMA(p,-q)-on-AR-Residuals" title="Permalink"></a></h3><p>Using the AR-only fit implied by <span>$\xi(B)$</span> and <span>$c$</span>, compute residuals and fit an <strong>ARMA(p, q)</strong> by maximizing the conditional Gaussian likelihood. Denote the ARMA polynomials</p><p class="math-container">\[\Phi(B) \;=\; 1 - \varphi_1 B - \cdots - \varphi_p B^{p},
\qquad
\Theta(B) \;=\; 1 + \theta_1 B + \cdots + \theta_q B^{q}.\]</p><p>The ARMA stage estimates <span>$(\varphi_1,\ldots,\varphi_p,\,\theta_1,\ldots,\theta_q,\,\sigma^2)$</span> via Nelder–Mead. The code log-parameterizes the variance for numerical stability.</p><p><strong>Information criteria.</strong> With effective residual length <span>$n_{\text{eff}}$</span> and <span>$k=p+q$</span> parameters (variance excluded), the log-likelihood <span>$\ell$</span> yields</p><p class="math-container">\[\mathrm{AIC}=2k-2\ell, \qquad \mathrm{BIC}=(\log n_{\text{eff}})\,k-2\ell.\]</p><h3 id="Forecasting-2"><a class="docs-heading-anchor" href="#Forecasting-2">Forecasting</a><a class="docs-heading-anchor-permalink" href="#Forecasting-2" title="Permalink"></a></h3><p>With the composite kernel <span>$\xi(B)$</span> and intercept <span>$c$</span> from Stage 2, and the ARMA(p,q) layer from Stage 3, h-step-ahead forecasts are formed recursively. Let <span>$P_n Y_{n+h}$</span> denote the minimum-MSE predictor of <span>$Y_{n+h}$</span>. Writing <span>$\xi(B)=1+\xi_1 B+\cdots+\xi_{K} B^{K}$</span>,</p><p class="math-container">\[P_n Y_{n+h}
\;=\;
- \sum_{j=1}^{K} \xi_j \, P_n Y_{n+h-j}
\;+\; c \;+\; \text{(MA terms from } \Theta(B)\text{)},
\qquad h\ge 1,\]</p><p>with initialization <span>$P_n Y_{n+h}=Y_{n+h}$</span> for <span>$h\le 0$</span> and future shocks set to zero for the MA recursion. Forecast standard errors follow from the MA representation and the estimated innovation variance <span>$\sigma^2$</span>.</p><h3 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h3><ul><li>Parzen, E. (1985). <em>ARARMA Models for Time Series Analysis and Forecasting</em>. <strong>Journal of Forecasting</strong>, 1(1), 67–82.</li></ul><h1 id="Forecasing-in-Julia-using-Ararma-Model"><a class="docs-heading-anchor" href="#Forecasing-in-Julia-using-Ararma-Model">Forecasing in Julia using Ararma Model</a><a id="Forecasing-in-Julia-using-Ararma-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Forecasing-in-Julia-using-Ararma-Model" title="Permalink"></a></h1><pre><code class="language-julia hljs">fit2 = ararma(ap, p = 0, q = 1)
fc2  = forecast(fit2, h = 12)
plot(fc2)

fit3 = auto_ararma(ap)
fc3  = forecast(fit3, h = 12)
plot(fc3)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../arima/">« ARIMA</a><a class="docs-footer-nextpage" href="../api/">API Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Friday 26 September 2025 13:33">Friday 26 September 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
