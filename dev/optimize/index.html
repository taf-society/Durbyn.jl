<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization · Durbyn.jl</title><meta name="title" content="Optimization · Durbyn.jl"/><meta property="og:title" content="Optimization · Durbyn.jl"/><meta property="twitter:title" content="Optimization · Durbyn.jl"/><meta name="description" content="Documentation for Durbyn.jl."/><meta property="og:description" content="Documentation for Durbyn.jl."/><meta property="twitter:description" content="Documentation for Durbyn.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/theme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="Durbyn.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">Durbyn.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../quickstart/">Quick Start</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../grammar/">Grammar</a></li><li><a class="tocitem" href="../expsmoothing/">Exponential Smoothing</a></li><li><a class="tocitem" href="../theta/">Theta</a></li><li><a class="tocitem" href="../bats/">BATS</a></li><li><a class="tocitem" href="../tbats/">TBATS</a></li><li><a class="tocitem" href="../intermittent/">Intermittent Demand</a></li><li><a class="tocitem" href="../arima/">ARIMA</a></li><li><a class="tocitem" href="../arar/">ARAR</a></li><li><a class="tocitem" href="../ararma/">ARARMA</a></li><li><a class="tocitem" href="../stats/">Statistics</a></li><li class="is-active"><a class="tocitem" href>Optimization</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Unified-Interface-(optim)"><span>Unified Interface (<code>optim</code>)</span></a></li><li><a class="tocitem" href="#Nelder-Mead-Simplex-(nmmin)"><span>Nelder-Mead Simplex (<code>nmmin</code>)</span></a></li><li><a class="tocitem" href="#BFGS-Quasi-Newton-(bfgsmin)"><span>BFGS Quasi-Newton (<code>bfgsmin</code>)</span></a></li><li><a class="tocitem" href="#L-BFGS-B-Bounded-Optimization-(lbfgsbmin)"><span>L-BFGS-B Bounded Optimization (<code>lbfgsbmin</code>)</span></a></li><li><a class="tocitem" href="#Brent&#39;s-1D-Method-(fmin)"><span>Brent&#39;s 1D Method (<code>fmin</code>)</span></a></li><li><a class="tocitem" href="#Numerical-Gradient-Computation"><span>Numerical Gradient Computation</span></a></li><li><a class="tocitem" href="#Hessian-Computation"><span>Hessian Computation</span></a></li><li><a class="tocitem" href="#Parameter-Scaling"><span>Parameter Scaling</span></a></li><li><a class="tocitem" href="#Practical-Guidelines"><span>Practical Guidelines</span></a></li><li><a class="tocitem" href="#Complete-Example:-Maximum-Likelihood-Estimation"><span>Complete Example: Maximum Likelihood Estimation</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../utils/">Utilities</a></li><li><a class="tocitem" href="../tableops/">Table Operations</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/taf-society/Durbyn.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/taf-society/Durbyn.jl/blob/main/docs/src/optimize.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimization-Module"><a class="docs-heading-anchor" href="#Optimization-Module">Optimization Module</a><a id="Optimization-Module-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-Module" title="Permalink"></a></h1><p>The Optimize module provides a comprehensive suite of numerical optimization algorithms for minimizing objective functions. These optimizers are used internally throughout Durbyn.jl for model fitting (e.g., maximum likelihood estimation in ETS, ARIMA, and BATS models) and are also available for general-purpose optimization tasks.</p><hr/><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>The module implements four main optimization algorithms and provides a unified R-like interface:</p><table><tr><th style="text-align: right">Algorithm</th><th style="text-align: right">Function</th><th style="text-align: right">Type</th><th style="text-align: right">Use Case</th></tr><tr><td style="text-align: right"><strong>Nelder-Mead</strong></td><td style="text-align: right"><code>nmmin</code></td><td style="text-align: right">Derivative-free</td><td style="text-align: right">General purpose, no gradient needed</td></tr><tr><td style="text-align: right"><strong>BFGS</strong></td><td style="text-align: right"><code>bfgsmin</code></td><td style="text-align: right">Quasi-Newton</td><td style="text-align: right">Fast convergence with gradients</td></tr><tr><td style="text-align: right"><strong>L-BFGS-B</strong></td><td style="text-align: right"><code>lbfgsbmin</code></td><td style="text-align: right">Bounded quasi-Newton</td><td style="text-align: right">Box-constrained optimization</td></tr><tr><td style="text-align: right"><strong>Brent</strong></td><td style="text-align: right"><code>fmin</code></td><td style="text-align: right">1D derivative-free</td><td style="text-align: right">Scalar optimization</td></tr></table><h3 id="Exported-Functions-and-Types"><a class="docs-heading-anchor" href="#Exported-Functions-and-Types">Exported Functions and Types</a><a id="Exported-Functions-and-Types-1"></a><a class="docs-heading-anchor-permalink" href="#Exported-Functions-and-Types" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Main optimization functions
export optim, nmmin, bfgsmin, lbfgsbmin, fmin

# Options types
export NelderMeadOptions, BFGSOptions, LBFGSBOptions, FminOptions

# Supporting functions
export numgrad, numgrad!, numgrad_with_cache!, NumericalGradientCache
export optim_hessian, bfgs_hessian_update!, BFGSWorkspace
export scaler, descaler</code></pre><hr/><h2 id="Unified-Interface-(optim)"><a class="docs-heading-anchor" href="#Unified-Interface-(optim)">Unified Interface (<code>optim</code>)</a><a id="Unified-Interface-(optim)-1"></a><a class="docs-heading-anchor-permalink" href="#Unified-Interface-(optim)" title="Permalink"></a></h2><p>The <code>optim</code> function provides a unified interface matching R&#39;s <code>optim()</code> function, making it easy to switch between optimization methods.</p><pre><code class="language-julia hljs">optim(par, fn; gr=nothing, method=&quot;Nelder-Mead&quot;, lower=-Inf, upper=Inf,
      control=Dict(), hessian=false, kwargs...)</code></pre><h3 id="Arguments"><a class="docs-heading-anchor" href="#Arguments">Arguments</a><a id="Arguments-1"></a><a class="docs-heading-anchor-permalink" href="#Arguments" title="Permalink"></a></h3><ul><li><code>par::Vector{Float64}</code>: Initial parameter vector</li><li><code>fn::Function</code>: Objective function to minimize, called as <code>fn(par; kwargs...)</code></li></ul><h3 id="Keyword-Arguments"><a class="docs-heading-anchor" href="#Keyword-Arguments">Keyword Arguments</a><a id="Keyword-Arguments-1"></a><a class="docs-heading-anchor-permalink" href="#Keyword-Arguments" title="Permalink"></a></h3><ul><li><code>gr::Union{Function,Nothing}</code>: Gradient function, called as <code>gr(par; kwargs...)</code>. If <code>nothing</code>, numerical gradients are computed automatically.</li><li><code>method::String</code>: Optimization method:<ul><li><code>&quot;Nelder-Mead&quot;</code> (default) - Derivative-free simplex</li><li><code>&quot;BFGS&quot;</code> - Quasi-Newton with line search</li><li><code>&quot;L-BFGS-B&quot;</code> - Limited-memory BFGS with box constraints</li><li><code>&quot;Brent&quot;</code> - 1D optimization (scalar <code>par</code> only)</li></ul></li><li><code>lower</code>, <code>upper</code>: Bounds for L-BFGS-B and Brent methods</li><li><code>control::Dict</code>: Control parameters (see below)</li><li><code>hessian::Bool</code>: If <code>true</code>, compute Hessian at solution</li></ul><h3 id="Control-Parameters"><a class="docs-heading-anchor" href="#Control-Parameters">Control Parameters</a><a id="Control-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Control-Parameters" title="Permalink"></a></h3><table><tr><th style="text-align: right">Parameter</th><th style="text-align: right">Default</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>trace</code></td><td style="text-align: right">0</td><td style="text-align: right">Verbosity level (0=silent, &gt;0=verbose)</td></tr><tr><td style="text-align: right"><code>fnscale</code></td><td style="text-align: right">1.0</td><td style="text-align: right">Function scaling factor</td></tr><tr><td style="text-align: right"><code>parscale</code></td><td style="text-align: right">ones(n)</td><td style="text-align: right">Parameter scaling vector</td></tr><tr><td style="text-align: right"><code>ndeps</code></td><td style="text-align: right">1e-3</td><td style="text-align: right">Step sizes for numerical derivatives</td></tr><tr><td style="text-align: right"><code>maxit</code></td><td style="text-align: right">500/100</td><td style="text-align: right">Maximum iterations (500 for NM, 100 for others)</td></tr><tr><td style="text-align: right"><code>abstol</code></td><td style="text-align: right">-Inf</td><td style="text-align: right">Absolute convergence tolerance</td></tr><tr><td style="text-align: right"><code>reltol</code></td><td style="text-align: right">sqrt(eps)</td><td style="text-align: right">Relative convergence tolerance</td></tr><tr><td style="text-align: right"><code>gtol</code></td><td style="text-align: right">0.0</td><td style="text-align: right">Gradient norm tolerance (BFGS only)</td></tr><tr><td style="text-align: right"><code>alpha</code></td><td style="text-align: right">1.0</td><td style="text-align: right">Nelder-Mead reflection coefficient</td></tr><tr><td style="text-align: right"><code>beta</code></td><td style="text-align: right">0.5</td><td style="text-align: right">Nelder-Mead contraction coefficient</td></tr><tr><td style="text-align: right"><code>gamma</code></td><td style="text-align: right">2.0</td><td style="text-align: right">Nelder-Mead expansion coefficient</td></tr><tr><td style="text-align: right"><code>REPORT</code></td><td style="text-align: right">10</td><td style="text-align: right">Reporting frequency for BFGS</td></tr><tr><td style="text-align: right"><code>lmm</code></td><td style="text-align: right">5</td><td style="text-align: right">L-BFGS-B memory parameter</td></tr><tr><td style="text-align: right"><code>factr</code></td><td style="text-align: right">1e7</td><td style="text-align: right">L-BFGS-B tolerance factor</td></tr><tr><td style="text-align: right"><code>pgtol</code></td><td style="text-align: right">0.0</td><td style="text-align: right">L-BFGS-B projected gradient tolerance</td></tr></table><h3 id="Returns"><a class="docs-heading-anchor" href="#Returns">Returns</a><a id="Returns-1"></a><a class="docs-heading-anchor-permalink" href="#Returns" title="Permalink"></a></h3><p>Named tuple with fields:</p><ul><li><code>par::Vector{Float64}</code>: Optimal parameters</li><li><code>value::Float64</code>: Function value at optimum</li><li><code>counts::NamedTuple</code>: <code>(function_=n, gradient=m)</code> evaluation counts</li><li><code>convergence::Int</code>: Status code (0=success, 1=maxit reached)</li><li><code>message</code>: Convergence message (method-dependent)</li><li><code>hessian</code>: Hessian matrix at solution (if requested)</li></ul><h3 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Durbyn.Optimize

# Define Rosenbrock function
rosenbrock(x) = 100 * (x[2] - x[1]^2)^2 + (1 - x[1])^2

# Analytical gradient
rosenbrock_grad(x) = [
    -400*x[1]*(x[2]-x[1]^2) - 2*(1-x[1]),
    200*(x[2]-x[1]^2)
]

# Nelder-Mead (no gradient needed)
result = optim([-1.2, 1.0], rosenbrock)
println(&quot;Optimal: $(result.par), Value: $(result.value)&quot;)

# BFGS with analytical gradient
result = optim([-1.2, 1.0], rosenbrock; gr=rosenbrock_grad, method=&quot;BFGS&quot;)

# BFGS with numerical gradient (automatic)
result = optim([-1.2, 1.0], rosenbrock; method=&quot;BFGS&quot;)

# L-BFGS-B with box constraints
result = optim([0.5, 0.5], rosenbrock; method=&quot;L-BFGS-B&quot;,
               lower=[0.0, 0.0], upper=[2.0, 2.0])

# With control parameters
result = optim([-1.2, 1.0], rosenbrock; method=&quot;BFGS&quot;,
               control=Dict(&quot;trace&quot; =&gt; 1, &quot;maxit&quot; =&gt; 500, &quot;gtol&quot; =&gt; 1e-6))

# Request Hessian at solution
result = optim([-1.2, 1.0], rosenbrock; gr=rosenbrock_grad,
               method=&quot;BFGS&quot;, hessian=true)
println(&quot;Hessian:\n$(result.hessian)&quot;)

# 1D optimization with Brent&#39;s method
f1d(x) = (x[1] - 2)^2
result = optim([0.0], f1d; method=&quot;Brent&quot;, lower=-5.0, upper=5.0)</code></pre><hr/><h2 id="Nelder-Mead-Simplex-(nmmin)"><a class="docs-heading-anchor" href="#Nelder-Mead-Simplex-(nmmin)">Nelder-Mead Simplex (<code>nmmin</code>)</a><a id="Nelder-Mead-Simplex-(nmmin)-1"></a><a class="docs-heading-anchor-permalink" href="#Nelder-Mead-Simplex-(nmmin)" title="Permalink"></a></h2><p>The Nelder-Mead algorithm is a derivative-free optimization method that uses a simplex (a polytope with n+1 vertices in n dimensions) to search for the minimum.</p><h3 id="Algorithm"><a class="docs-heading-anchor" href="#Algorithm">Algorithm</a><a id="Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithm" title="Permalink"></a></h3><p>The algorithm performs four operations on the simplex:</p><ol><li><strong>Reflection</strong>: Reflect the worst point through the centroid</li><li><strong>Expansion</strong>: If reflection improves the best, expand further</li><li><strong>Contraction</strong>: If reflection fails, contract toward the best</li><li><strong>Shrink</strong>: If still no improvement, shrink simplex about the best point</li></ol><h3 id="Mathematical-Details"><a class="docs-heading-anchor" href="#Mathematical-Details">Mathematical Details</a><a id="Mathematical-Details-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Details" title="Permalink"></a></h3><p>Given simplex vertices <span>$\{x_1, ..., x_{n+1}\}$</span> ordered by function values <span>$f(x_1) \leq ... \leq f(x_{n+1})$</span>:</p><ul><li><strong>Centroid</strong>: <span>$\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$</span></li><li><strong>Reflection</strong>: <span>$x_r = \bar{x} + \alpha(\bar{x} - x_{n+1})$</span></li><li><strong>Expansion</strong>: <span>$x_e = \bar{x} + \gamma(x_r - \bar{x})$</span></li><li><strong>Contraction</strong>: <span>$x_c = \bar{x} + \beta(x_{n+1} - \bar{x})$</span></li></ul><p>Default coefficients: <span>$\alpha = 1.0$</span>, <span>$\beta = 0.5$</span>, <span>$\gamma = 2.0$</span></p><h3 id="Usage"><a class="docs-heading-anchor" href="#Usage">Usage</a><a id="Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Usage" title="Permalink"></a></h3><pre><code class="language-julia hljs">nmmin(f, x0, options::NelderMeadOptions)</code></pre><p><strong>Options:</strong></p><pre><code class="language-julia hljs">NelderMeadOptions(;
    abstol = -Inf,           # Absolute tolerance on function value
    intol = sqrt(eps()),     # Relative tolerance
    alpha = 1.0,             # Reflection coefficient
    beta = 0.5,              # Contraction coefficient
    gamma = 2.0,             # Expansion coefficient
    trace = false,           # Print diagnostics
    maxit = 500,             # Maximum function evaluations
    invalid_penalty = 1e35,  # Penalty for non-finite values
    project_to_bounds = false,
    lower = nothing,
    upper = nothing,
    init_step_cap = nothing
)</code></pre><p><strong>Returns:</strong> Named tuple <code>(x_opt, f_opt, fncount, fail)</code></p><ul><li><code>fail=0</code>: Converged successfully</li><li><code>fail=1</code>: Exceeded maximum iterations</li><li><code>fail=10</code>: Degenerate simplex (shrink failure)</li></ul><h3 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Durbyn.Optimize

f(x) = (x[1] - 1)^2 + (x[2] - 2)^2

opts = NelderMeadOptions(trace=true, maxit=1000)
result = nmmin(f, [0.0, 0.0], opts)
println(&quot;Optimum: $(result.x_opt)&quot;)</code></pre><hr/><h2 id="BFGS-Quasi-Newton-(bfgsmin)"><a class="docs-heading-anchor" href="#BFGS-Quasi-Newton-(bfgsmin)">BFGS Quasi-Newton (<code>bfgsmin</code>)</a><a id="BFGS-Quasi-Newton-(bfgsmin)-1"></a><a class="docs-heading-anchor-permalink" href="#BFGS-Quasi-Newton-(bfgsmin)" title="Permalink"></a></h2><p>The Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm is a quasi-Newton method that builds an approximation to the inverse Hessian matrix using gradient information.</p><h3 id="Algorithm-2"><a class="docs-heading-anchor" href="#Algorithm-2">Algorithm</a><a class="docs-heading-anchor-permalink" href="#Algorithm-2" title="Permalink"></a></h3><p>BFGS iteratively updates the inverse Hessian approximation <span>$B_k$</span> using the formula:</p><p class="math-container">\[B_{k+1} = B_k + \frac{(1 + c^T B_k c / D_1) t t^T}{D_1} - \frac{t (B_k c)^T + (B_k c) t^T}{D_1}\]</p><p>where:</p><ul><li><span>$t = x_{k+1} - x_k$</span> (parameter step)</li><li><span>$c = \nabla f_{k+1} - \nabla f_k$</span> (gradient difference)</li><li><span>$D_1 = t^T c$</span></li></ul><h3 id="Features"><a class="docs-heading-anchor" href="#Features">Features</a><a id="Features-1"></a><a class="docs-heading-anchor-permalink" href="#Features" title="Permalink"></a></h3><ul><li><strong>Armijo line search</strong> with backtracking</li><li><strong>Periodic Hessian restarts</strong> every 2n gradient evaluations</li><li><strong>Parameter masking</strong> to freeze variables</li><li><strong>Automatic numerical gradients</strong> if analytical gradient not provided</li><li><strong>Gradient norm convergence</strong> (Julia enhancement)</li></ul><h3 id="Usage-2"><a class="docs-heading-anchor" href="#Usage-2">Usage</a><a class="docs-heading-anchor-permalink" href="#Usage-2" title="Permalink"></a></h3><pre><code class="language-julia hljs">bfgsmin(f, g, x0; mask=nothing, options=BFGSOptions(), ndeps=1e-3*ones(n),
        numgrad_cache=nothing, ex=nothing)</code></pre><p><strong>Function Signatures:</strong></p><ul><li><code>f(n, x, ex)</code> - Objective function</li><li><code>g(n, x, grad, ex)</code> - Gradient function (modifies <code>grad</code> in-place), or <code>nothing</code></li></ul><p><strong>Options:</strong></p><pre><code class="language-julia hljs">BFGSOptions(;
    abstol = -Inf,           # Absolute tolerance
    reltol = sqrt(eps()),    # Relative tolerance
    gtol = 0.0,              # Gradient norm tolerance (Julia enhancement)
    trace = false,           # Print progress
    maxit = 100,             # Maximum iterations
    nREPORT = 10             # Reporting frequency
)</code></pre><p><strong>Gradient Norm Convergence (<code>gtol</code>):</strong></p><p>When <code>gtol &gt; 0</code>, convergence is declared if:</p><p class="math-container">\[\|\nabla f(x)\| &lt; \text{gtol} \times \max(1, |f(x)|)\]</p><p>This provides a first-order optimality condition. Recommended values: <code>1e-5</code> to <code>1e-8</code>.</p><p><strong>Returns:</strong> Named tuple <code>(x_opt, f_opt, n_iter, fail, fn_evals, gr_evals)</code></p><h3 id="Example-2"><a class="docs-heading-anchor" href="#Example-2">Example</a><a class="docs-heading-anchor-permalink" href="#Example-2" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Durbyn.Optimize

# Internal function signature: f(n, x, ex)
rosenbrock_internal(n, x, ex) = 100 * (x[2] - x[1]^2)^2 + (1 - x[1])^2

# Gradient modifies grad in-place
function rosenbrock_grad_internal(n, x, grad, ex)
    grad[1] = -400*x[1]*(x[2]-x[1]^2) - 2*(1-x[1])
    grad[2] = 200*(x[2]-x[1]^2)
    return nothing
end

opts = BFGSOptions(trace=true, gtol=1e-6)
result = bfgsmin(rosenbrock_internal, rosenbrock_grad_internal, [-1.2, 1.0]; options=opts)

# With numerical gradients (g=nothing)
result = bfgsmin(rosenbrock_internal, nothing, [-1.2, 1.0]; options=opts)</code></pre><hr/><h2 id="L-BFGS-B-Bounded-Optimization-(lbfgsbmin)"><a class="docs-heading-anchor" href="#L-BFGS-B-Bounded-Optimization-(lbfgsbmin)">L-BFGS-B Bounded Optimization (<code>lbfgsbmin</code>)</a><a id="L-BFGS-B-Bounded-Optimization-(lbfgsbmin)-1"></a><a class="docs-heading-anchor-permalink" href="#L-BFGS-B-Bounded-Optimization-(lbfgsbmin)" title="Permalink"></a></h2><p>L-BFGS-B is a limited-memory variant of BFGS that supports box constraints. It stores only the last <code>m</code> iterations of gradient information, making it memory-efficient for large-scale problems.</p><h3 id="Features-2"><a class="docs-heading-anchor" href="#Features-2">Features</a><a class="docs-heading-anchor-permalink" href="#Features-2" title="Permalink"></a></h3><ul><li><strong>Box constraints</strong>: Lower and upper bounds on variables</li><li><strong>Limited memory</strong>: Stores only <code>m</code> gradient steps (default: 10)</li><li><strong>Wolfe line search</strong> with zoom refinement</li><li><strong>Projected gradient</strong> for convergence checking</li><li><strong>Parameter masking</strong> by setting <code>l[i] = u[i] = x0[i]</code></li></ul><h3 id="Usage-3"><a class="docs-heading-anchor" href="#Usage-3">Usage</a><a class="docs-heading-anchor-permalink" href="#Usage-3" title="Permalink"></a></h3><pre><code class="language-julia hljs">lbfgsbmin(f, g, x0; mask=nothing, l=-Inf, u=Inf, options=LBFGSBOptions())</code></pre><p><strong>Options:</strong></p><pre><code class="language-julia hljs">LBFGSBOptions(;
    m = 10,          # Memory size (number of stored iterations)
    factr = 1e7,     # Tolerance factor: f_tol = factr * eps()
    pgtol = 1e-5,    # Projected gradient infinity-norm tolerance
    maxit = 1000,    # Maximum iterations
    iprint = 0       # Print level (0=silent, &gt;0=verbose)
)</code></pre><p><strong>Convergence Criterion:</strong></p><p>The algorithm converges when:</p><p class="math-container">\[\|\text{proj}(\nabla f(x))\|_\infty &lt; \text{pgtol}\]</p><p>where the projected gradient accounts for variables at their bounds.</p><p><strong>Returns:</strong> Named tuple <code>(x_opt, f_opt, n_iter, fail, fn_evals, gr_evals)</code></p><h3 id="Example-3"><a class="docs-heading-anchor" href="#Example-3">Example</a><a class="docs-heading-anchor-permalink" href="#Example-3" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Durbyn.Optimize

rosenbrock(n, x, ex) = 100 * (x[2] - x[1]^2)^2 + (1 - x[1])^2

opts = LBFGSBOptions(m=5, pgtol=1e-6, iprint=1)
result = lbfgsbmin(rosenbrock, nothing, [0.5, 0.5];
                    l=[0.0, 0.0], u=[2.0, 2.0], options=opts)

println(&quot;Bounded optimum: $(result.x_opt)&quot;)</code></pre><hr/><h2 id="Brent&#39;s-1D-Method-(fmin)"><a class="docs-heading-anchor" href="#Brent&#39;s-1D-Method-(fmin)">Brent&#39;s 1D Method (<code>fmin</code>)</a><a id="Brent&#39;s-1D-Method-(fmin)-1"></a><a class="docs-heading-anchor-permalink" href="#Brent&#39;s-1D-Method-(fmin)" title="Permalink"></a></h2><p>Brent&#39;s method is a robust derivative-free algorithm for one-dimensional optimization that combines golden section search with parabolic interpolation.</p><h3 id="Algorithm-3"><a class="docs-heading-anchor" href="#Algorithm-3">Algorithm</a><a class="docs-heading-anchor-permalink" href="#Algorithm-3" title="Permalink"></a></h3><p>The algorithm alternates between:</p><ol><li><strong>Golden section search</strong>: Guaranteed progress, robust</li><li><strong>Parabolic interpolation</strong>: Fast convergence near the minimum</li></ol><h3 id="Convergence"><a class="docs-heading-anchor" href="#Convergence">Convergence</a><a id="Convergence-1"></a><a class="docs-heading-anchor-permalink" href="#Convergence" title="Permalink"></a></h3><p>For unimodal functions with positive second derivative at the minimum:</p><ul><li><strong>Superlinear convergence</strong> with order approximately 1.324</li><li>Error bound: <span>$&lt; 3\epsilon|x_{\min}| + \text{tol}$</span></li></ul><h3 id="Usage-4"><a class="docs-heading-anchor" href="#Usage-4">Usage</a><a class="docs-heading-anchor-permalink" href="#Usage-4" title="Permalink"></a></h3><pre><code class="language-julia hljs">fmin(f, lower, upper; options=FminOptions())</code></pre><p><strong>Options:</strong></p><pre><code class="language-julia hljs">FminOptions(;
    tol = 1.5e-8,    # Interval tolerance
    trace = false,   # Print diagnostics
    maxit = 1000     # Maximum iterations
)</code></pre><p><strong>Returns:</strong> Named tuple <code>(x_opt, f_opt, n_iter, fail, fn_evals)</code></p><h3 id="Example-4"><a class="docs-heading-anchor" href="#Example-4">Example</a><a class="docs-heading-anchor-permalink" href="#Example-4" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Durbyn.Optimize

f(x) = (x - 3.5)^2 + 2*sin(x)

opts = FminOptions(tol=1e-10, trace=true)
result = fmin(f, 0.0, 10.0; options=opts)

println(&quot;Minimum at x = $(result.x_opt), f(x) = $(result.f_opt)&quot;)</code></pre><hr/><h2 id="Numerical-Gradient-Computation"><a class="docs-heading-anchor" href="#Numerical-Gradient-Computation">Numerical Gradient Computation</a><a id="Numerical-Gradient-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-Gradient-Computation" title="Permalink"></a></h2><p>The module provides efficient numerical gradient computation using central finite differences.</p><h3 id="numgrad"><a class="docs-heading-anchor" href="#numgrad"><code>numgrad</code></a><a id="numgrad-1"></a><a class="docs-heading-anchor-permalink" href="#numgrad" title="Permalink"></a></h3><pre><code class="language-julia hljs">numgrad(f, n, x, ex, ndeps; usebounds=false, lower=nothing, upper=nothing)</code></pre><p>Computes the gradient using central differences:</p><p class="math-container">\[\frac{\partial f}{\partial x_i} \approx \frac{f(x + \epsilon_i e_i) - f(x - \epsilon_i e_i)}{2\epsilon_i}\]</p><h3 id="numgrad_with_cache!"><a class="docs-heading-anchor" href="#numgrad_with_cache!"><code>numgrad_with_cache!</code></a><a id="numgrad_with_cache!-1"></a><a class="docs-heading-anchor-permalink" href="#numgrad_with_cache!" title="Permalink"></a></h3><p>For repeated gradient evaluations, use a pre-allocated cache:</p><pre><code class="language-julia hljs">cache = NumericalGradientCache(n)
numgrad_with_cache!(cache, f, n, x, ex, ndeps)</code></pre><p>This eliminates memory allocations during iterative optimization.</p><h3 id="Example-5"><a class="docs-heading-anchor" href="#Example-5">Example</a><a class="docs-heading-anchor-permalink" href="#Example-5" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Durbyn.Optimize

f(n, x, ex) = x[1]^2 + x[2]^2
x = [1.0, 2.0]
ndeps = [1e-6, 1e-6]

# Single evaluation
grad = numgrad(f, 2, x, nothing, ndeps)

# With cache for repeated evaluations
cache = NumericalGradientCache(2)
for i in 1:1000
    numgrad_with_cache!(cache, f, 2, x, nothing, ndeps)
    # cache.df contains the gradient
end</code></pre><hr/><h2 id="Hessian-Computation"><a class="docs-heading-anchor" href="#Hessian-Computation">Hessian Computation</a><a id="Hessian-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#Hessian-Computation" title="Permalink"></a></h2><p>The <code>optim_hessian</code> function computes the Hessian matrix at a given point.</p><pre><code class="language-julia hljs">optim_hessian(fn, par, gr=nothing; fnscale=1.0, parscale=ones(n), ndeps=1e-3*ones(n))</code></pre><p><strong>Method:</strong></p><ul><li>If <code>gr=nothing</code>: Uses second-order finite differences</li><li>If <code>gr</code> provided: Computes Hessian from gradient via finite differences</li></ul><p><strong>Returns:</strong> Symmetric Hessian matrix (n x n)</p><h3 id="Example-6"><a class="docs-heading-anchor" href="#Example-6">Example</a><a class="docs-heading-anchor-permalink" href="#Example-6" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Durbyn.Optimize

rosenbrock(x) = 100 * (x[2] - x[1]^2)^2 + (1 - x[1])^2

# At the optimum
x_opt = [1.0, 1.0]
H = optim_hessian(rosenbrock, x_opt)
println(&quot;Hessian at optimum:\n$H&quot;)

# Eigenvalues (should be positive for minimum)
using LinearAlgebra
eigvals(H)</code></pre><hr/><h2 id="Parameter-Scaling"><a class="docs-heading-anchor" href="#Parameter-Scaling">Parameter Scaling</a><a id="Parameter-Scaling-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Scaling" title="Permalink"></a></h2><p>Scaling parameters can improve numerical conditioning when parameters have different magnitudes.</p><h3 id="scaler-and-descaler"><a class="docs-heading-anchor" href="#scaler-and-descaler"><code>scaler</code> and <code>descaler</code></a><a id="scaler-and-descaler-1"></a><a class="docs-heading-anchor-permalink" href="#scaler-and-descaler" title="Permalink"></a></h3><pre><code class="language-julia hljs">x_scaled = scaler(x, scale)       # x_scaled = x ./ scale
x_original = descaler(x_scaled, scale)  # x_original = x_scaled .* scale</code></pre><h3 id="Example-7"><a class="docs-heading-anchor" href="#Example-7">Example</a><a class="docs-heading-anchor-permalink" href="#Example-7" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Parameters with different scales
par = [1e-6, 1e6]
scale = [1e-6, 1e6]

# Scale for optimization
par_scaled = scaler(par, scale)  # [1.0, 1.0]

# After optimization, recover original scale
par_opt = descaler(par_scaled_opt, scale)</code></pre><hr/><h2 id="Practical-Guidelines"><a class="docs-heading-anchor" href="#Practical-Guidelines">Practical Guidelines</a><a id="Practical-Guidelines-1"></a><a class="docs-heading-anchor-permalink" href="#Practical-Guidelines" title="Permalink"></a></h2><h3 id="Choosing-an-Optimization-Method"><a class="docs-heading-anchor" href="#Choosing-an-Optimization-Method">Choosing an Optimization Method</a><a id="Choosing-an-Optimization-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Choosing-an-Optimization-Method" title="Permalink"></a></h3><table><tr><th style="text-align: right">Scenario</th><th style="text-align: right">Recommended Method</th></tr><tr><td style="text-align: right">No gradient available</td><td style="text-align: right">Nelder-Mead</td></tr><tr><td style="text-align: right">Smooth function, gradient available</td><td style="text-align: right">BFGS</td></tr><tr><td style="text-align: right">Box constraints needed</td><td style="text-align: right">L-BFGS-B</td></tr><tr><td style="text-align: right">Large-scale problem (many parameters)</td><td style="text-align: right">L-BFGS-B</td></tr><tr><td style="text-align: right">1D optimization</td><td style="text-align: right">Brent</td></tr><tr><td style="text-align: right">Non-smooth or noisy function</td><td style="text-align: right">Nelder-Mead</td></tr></table><h3 id="Tips-for-Better-Convergence"><a class="docs-heading-anchor" href="#Tips-for-Better-Convergence">Tips for Better Convergence</a><a id="Tips-for-Better-Convergence-1"></a><a class="docs-heading-anchor-permalink" href="#Tips-for-Better-Convergence" title="Permalink"></a></h3><ol><li><p><strong>Parameter scaling</strong>: Scale parameters to similar magnitudes</p><pre><code class="language-julia hljs">control = Dict(&quot;parscale&quot; =&gt; [1e-3, 1e3])</code></pre></li><li><p><strong>Good starting point</strong>: Provide reasonable initial values</p></li><li><p><strong>Check gradients</strong>: Verify analytical gradients match numerical</p><pre><code class="language-julia hljs">grad_analytical = my_gradient(x)
grad_numerical = numgrad(f, n, x, nothing, 1e-6*ones(n))
@assert isapprox(grad_analytical, grad_numerical, rtol=1e-4)</code></pre></li><li><p><strong>Adjust tolerances</strong>: Tighten tolerances for more precision</p><pre><code class="language-julia hljs">control = Dict(&quot;reltol&quot; =&gt; 1e-10, &quot;gtol&quot; =&gt; 1e-8)</code></pre></li><li><p><strong>Monitor convergence</strong>: Use <code>trace</code> to diagnose issues</p><pre><code class="language-julia hljs">control = Dict(&quot;trace&quot; =&gt; 1)</code></pre></li></ol><hr/><h2 id="Complete-Example:-Maximum-Likelihood-Estimation"><a class="docs-heading-anchor" href="#Complete-Example:-Maximum-Likelihood-Estimation">Complete Example: Maximum Likelihood Estimation</a><a id="Complete-Example:-Maximum-Likelihood-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Complete-Example:-Maximum-Likelihood-Estimation" title="Permalink"></a></h2><pre><code class="language-julia hljs">using Durbyn.Optimize
using Distributions

# Generate data from Normal(mu=5, sigma=2)
data = rand(Normal(5.0, 2.0), 100)

# Negative log-likelihood (to minimize)
function neg_loglik(params)
    mu, log_sigma = params
    sigma = exp(log_sigma)  # Ensure sigma &gt; 0
    n = length(data)
    ll = -n/2 * log(2*pi) - n*log_sigma - sum((data .- mu).^2) / (2*sigma^2)
    return -ll  # Return negative for minimization
end

# Analytical gradient
function neg_loglik_grad(params)
    mu, log_sigma = params
    sigma = exp(log_sigma)
    n = length(data)

    d_mu = sum(data .- mu) / sigma^2
    d_log_sigma = n - sum((data .- mu).^2) / sigma^2

    return [-d_mu, -d_log_sigma]
end

# Optimize with BFGS
result = optim([0.0, 0.0], neg_loglik;
               gr=neg_loglik_grad,
               method=&quot;BFGS&quot;,
               hessian=true)

# Extract estimates
mu_hat = result.par[1]
sigma_hat = exp(result.par[2])

println(&quot;Estimated mu: $mu_hat (true: 5.0)&quot;)
println(&quot;Estimated sigma: $sigma_hat (true: 2.0)&quot;)

# Standard errors from Hessian
using LinearAlgebra
se = sqrt.(diag(inv(result.hessian)))
println(&quot;SE(mu): $(se[1])&quot;)
println(&quot;SE(log_sigma): $(se[2])&quot;)</code></pre><hr/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ul><li>Nelder, J. A. and Mead, R. (1965). <em>A simplex method for function minimization</em>. Computer Journal, 7, 308-313.</li><li>Broyden, C. G. (1970). <em>The convergence of a class of double-rank minimization algorithms</em>. Journal of the Institute of Mathematics and Its Applications, 6, 76-90.</li><li>Fletcher, R. (1970). <em>A new approach to variable metric algorithms</em>. Computer Journal, 13, 317-322.</li><li>Goldfarb, D. (1970). <em>A family of variable metric methods derived by variational means</em>. Mathematics of Computation, 24, 23-26.</li><li>Shanno, D. F. (1970). <em>Conditioning of quasi-Newton methods for function minimization</em>. Mathematics of Computation, 24, 647-656.</li><li>Byrd, R. H., Lu, P., Nocedal, J., and Zhu, C. (1995). <em>A limited memory algorithm for bound constrained optimization</em>. SIAM Journal on Scientific Computing, 16, 1190-1208.</li><li>Brent, R. P. (1973). <em>Algorithms for Minimization Without Derivatives</em>. Prentice-Hall.</li><li>Nash, J. C. (1990). <em>Compact Numerical Methods for Computers: Linear Algebra and Function Minimisation</em>. 2nd ed. Adam Hilger.</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../stats/">« Statistics</a><a class="docs-footer-nextpage" href="../utils/">Utilities »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 26 January 2026 23:48">Monday 26 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
