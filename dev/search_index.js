var documenterSearchIndex = {"docs":
[{"location":"ararma/#ARAR-and-ARARMA-Models","page":"ARAR/ARARMA","title":"ARAR and ARARMA Models","text":"tip: Formula Interface is the Recommended Approach\nThis page starts with the formula interface (recommended for most users), which provides declarative model specification with support for panel data and model comparison. The array interface (base models) is covered later. See the Grammar Guide for complete documentation.\n\n","category":"section"},{"location":"ararma/#Formula-Interface","page":"ARAR/ARARMA","title":"Formula Interface","text":"The ARAR model participates in Durbyn's forecasting grammar, allowing you to build models declaratively with @formula and integrate them into model(...) collections or grouped workflows.","category":"section"},{"location":"ararma/#Basic-Example","page":"ARAR/ARARMA","title":"Basic Example","text":"using Durbyn\n\nseries = air_passengers()\ndata = (sales = series,)\n\n# Using ArarSpec for fit/forecast workflow\nspec = ArarSpec(@formula(sales = arar()))\nfitted = fit(spec, data)\nfc = forecast(fitted, h = 12)\nplot(fc)","category":"section"},{"location":"ararma/#Custom-Parameters","page":"ARAR/ARARMA","title":"Custom Parameters","text":"# Specify max_ar_depth and max_lag\nspec = ArarSpec(@formula(sales = arar(max_ar_depth=20, max_lag=30)))\nfitted = fit(spec, data)\nfc = forecast(fitted, h = 12)","category":"section"},{"location":"ararma/#Panel-Data-(Multiple-Series)","page":"ARAR/ARARMA","title":"Panel Data (Multiple Series)","text":"# Create panel data with multiple regions\npanel_tbl = (\n    sales = vcat(series, series .* 1.05),\n    region = vcat(fill(\"north\", length(series)), fill(\"south\", length(series)))\n)\n\n# Wrap in PanelData for grouped fitting\npanel = PanelData(panel_tbl; groupby = :region, m = 12)\n\n# Fit to all groups\nspec = ArarSpec(@formula(sales = arar()))\ngroup_fit = fit(spec, panel)\n\n# Forecast all groups\ngroup_fc = forecast(group_fit, h = 6)\nplot(group_fc)","category":"section"},{"location":"ararma/#Model-Collections-(Benchmarking)","page":"ARAR/ARARMA","title":"Model Collections (Benchmarking)","text":"ArarSpec slots into model collections for easy benchmarking against other forecasting methods:\n\n# Compare ARAR against ARIMA and ETS\nmodels = model(\n    ArarSpec(@formula(sales = arar())),\n    ArimaSpec(@formula(sales = p() + q() + P() + Q())),\n    EtsSpec(@formula(sales = e(\"Z\") + t(\"Z\") + s(\"Z\"))),\n    names = [\"arar\", \"arima\", \"ets\"]\n)\n\n# Fit all models\nfitted_models = fit(models, panel)\n\n# Forecast with all models\nfc_models = forecast(fitted_models, h = 12)\n\n# Compare forecasts\nplot(fc_models)\n\nThis shared syntax keeps ARAR on equal footing with ARIMA, ETS, and other forecasting families.\n\n","category":"section"},{"location":"ararma/#ARARMA-Formula-Interface","page":"ARAR/ARARMA","title":"ARARMA Formula Interface","text":"The ARARMA model participates in Durbyn's forecasting grammar, allowing you to build models declaratively with @formula and integrate them into model(...) collections or grouped workflows.","category":"section"},{"location":"ararma/#Basic-Example-2","page":"ARAR/ARARMA","title":"Basic Example","text":"using Durbyn\n\nseries = air_passengers()\ndata = (sales = series,)\n\n# Using ArarmaSpec for fit/forecast workflow\nspec = ArarmaSpec(@formula(sales = p(1) + q(2)))\nfitted = fit(spec, data)\nfc = forecast(fitted, h = 12)\nplot(fc)","category":"section"},{"location":"ararma/#Auto-ARARMA-(Model-Selection)","page":"ARAR/ARARMA","title":"Auto ARARMA (Model Selection)","text":"# Auto ARARMA with default search ranges\nspec = ArarmaSpec(@formula(sales = p() + q()))\nfitted = fit(spec, data)\nfc = forecast(fitted, h = 12)\n\n# Auto ARARMA with custom search ranges\nspec = ArarmaSpec(@formula(sales = p(0,3) + q(0,2)))\nfitted = fit(spec, data)\nfc = forecast(fitted, h = 12)\n\n# With custom ARAR parameters\nspec = ArarmaSpec(\n    @formula(sales = p() + q()),\n    max_ar_depth = 20,\n    max_lag = 30,\n    crit = :bic\n)\nfitted = fit(spec, data)\nfc = forecast(fitted, h = 12)","category":"section"},{"location":"ararma/#Panel-Data-(Multiple-Series)-2","page":"ARAR/ARARMA","title":"Panel Data (Multiple Series)","text":"# Create panel data with multiple regions\npanel_tbl = (\n    sales = vcat(series, series .* 1.05),\n    region = vcat(fill(\"north\", length(series)), fill(\"south\", length(series)))\n)\n\n# Wrap in PanelData for grouped fitting\npanel = PanelData(panel_tbl; groupby = :region, m = 12)\n\n# Fit to all groups\nspec = ArarmaSpec(@formula(sales = p(1) + q(1)))\ngroup_fit = fit(spec, panel)\n\n# Forecast all groups\ngroup_fc = forecast(group_fit, h = 6)\nplot(group_fc)","category":"section"},{"location":"ararma/#Model-Collections-(Benchmarking)-2","page":"ARAR/ARARMA","title":"Model Collections (Benchmarking)","text":"ArarmaSpec slots into model collections for easy benchmarking against other forecasting methods:\n\n# Compare ARARMA against ARAR, ARIMA, and ETS\nmodels = model(\n    ArarmaSpec(@formula(sales = p() + q())),\n    ArarSpec(@formula(sales = arar())),\n    ArimaSpec(@formula(sales = p() + q() + P() + Q())),\n    EtsSpec(@formula(sales = e(\"Z\") + t(\"Z\") + s(\"Z\"))),\n    names = [\"ararma\", \"arar\", \"arima\", \"ets\"]\n)\n\n# Fit all models\nfitted_models = fit(models, panel)\n\n# Forecast with all models\nfc_models = forecast(fitted_models, h = 12)\n\n# Compare forecasts\nplot(fc_models)\n\nThis shared syntax keeps ARARMA on equal footing with ARIMA, ARAR, ETS, and other forecasting families.","category":"section"},{"location":"ararma/#Automatic-vs-Fixed-Order-Selection","page":"ARAR/ARARMA","title":"Automatic vs Fixed Order Selection","text":"Automatic selection (uses auto_ararma):\n\nAny order term with a range triggers automatic model selection\np() or q() with no arguments use default search ranges\nExamples: p() + q(), p(0,3) + q(), p(1) + q(0,2)\n\nFixed orders (uses ararma directly - faster):\n\nWhen all orders are fixed, the formula interface calls ararma() directly\nMuch faster as it skips the search process\nExample: p(1) + q(2) fits ARARMA(1,2) directly\n\n","category":"section"},{"location":"ararma/#ARAR-Model-Theory","page":"ARAR/ARARMA","title":"ARAR Model Theory","text":"The ARAR model applies a memory-shortening transformation; if the underlying process of a time series Y_t t=12ldotsn is \"long-memory\", it then fits an autoregressive model.","category":"section"},{"location":"ararma/#Memory-Shortening","page":"ARAR/ARARMA","title":"Memory Shortening","text":"The model follows five steps to classify Y_t and take one of three actions:\n\nL: declare Y_t as long memory and form tilde Y_t = Y_t - hatphi Y_t-hattau\nM: declare Y_t as moderately long memory and form tilde Y_t = Y_t - hatphi_1 Y_t-1 - hatphi_2 Y_t-2\nS: declare Y_t as short memory.\n\nIf Y_t is declared L or M, the series is transformed again until the transformed series is classified as short memory. (At most three transformations are applied; in practice, more than two is rare.)","category":"section"},{"location":"ararma/#Steps","page":"ARAR/ARARMA","title":"Steps","text":"For each tau=12ldots15, find hatphi(tau) that minimizes\nmathrmERR(phitau) =\nfracdisplaystylesum_t=tau+1^nbig(Y_t-phiY_t-taubig)^2\n     displaystylesum_t=tau+1^nY_t^2\nthen set mathrmErr(tau)=mathrmERRbig(hatphi(tau)taubig) and choose hattau=argmin_taumathrmErr(tau).\nIf mathrmErr(hattau)le 8n, then Y_t is a long-memory series.\nIf hatphi(hattau)ge 093 and hattau2, then Y_t is a long-memory series.\nIf hatphi(hattau)ge 093 and hattauin12, then Y_t is a long-memory series.\nIf hatphi(hattau)093, then Y_t is a short-memory series.","category":"section"},{"location":"ararma/#Subset-Autoregressive-Model","page":"ARAR/ARARMA","title":"Subset Autoregressive Model","text":"We now describe how ARAR fits an autoregression to the mean-corrected series X_t=S_t-bar S, t=k+1ldotsn, where S_t is the memory-shortened version of Y_t obtained above and bar S is the sample mean of S_k+1ldotsS_n.\n\nThe fitted model has the form\n\nX_t = phi_1 X_t-1 + phi_l_1 X_t-l_1 + phi_l_2 X_t-l_2 + phi_l_3 X_t-l_3 + Z_t\nqquad Z_t sim mathrmWN(0sigma^2)","category":"section"},{"location":"ararma/#Yule–Walker-Equations","page":"ARAR/ARARMA","title":"Yule–Walker Equations","text":"The coefficients phi_j and the noise variance sigma^2 follow from the Yule–Walker equations for given lags l_1l_2l_3:\n\nbeginbmatrix\n1  hatrho(l_1-1)  hatrho(l_2-1)  hatrho(l_3-1)\nhatrho(l_1-1)  1  hatrho(l_2-l_1)  hatrho(l_3-l_1)\nhatrho(l_2-1)  hatrho(l_2-l_1)  1  hatrho(l_3-l_2)\nhatrho(l_3-1)  hatrho(l_3-l_1)  hatrho(l_3-l_2)  1\nendbmatrix\nbeginbmatrix\nphi_12pt\nphi_l_12pt\nphi_l_22pt\nphi_l_3\nendbmatrix\n=\nbeginbmatrix\nhatrho(1)2pt\nhatrho(l_1)2pt\nhatrho(l_2)2pt\nhatrho(l_3)\nendbmatrix\n\nsigma^2 = hatgamma(0)Big( 1 - phi_1hatrho(1) - phi_l_1hatrho(l_1) - phi_l_2hatrho(l_2) - phi_l_3hatrho(l_3) Big)\n\nwhere hatgamma(j) and hatrho(j), j=012ldots, are the sample autocovariances and autocorrelations of X_t. The algorithm computes phi(cdot) for each set of lags with 1l_1l_2l_3le m (m typically 13 or 26) and selects the model with minimal Yule–Walker estimate of sigma^2.","category":"section"},{"location":"ararma/#Forecasting","page":"ARAR/ARARMA","title":"Forecasting","text":"If the short-memory filter found in the first step has coefficients Psi_0Psi_1ldotsPsi_k (kge0, Psi_0=1), then\n\nS_t = Psi(B)Y_t = Y_t + Psi_1 Y_t-1 + cdots + Psi_k Y_t-k\nqquad\nPsi(B) = 1 + Psi_1 B + cdots + Psi_k B^k \n\nIf the subset AR coefficients are phi_1phi_l_1phi_l_2phi_l_3 then, for X_t=S_t-bar S,\n\nphi(B)X_t = Z_t qquad\nphi(B) = 1 - phi_1 B - phi_l_1 B^l_1 - phi_l_2 B^l_2 - phi_l_3 B^l_3\n\nFrom the two displays above,\n\nxi(B)Y_t = phi(1)bar S + Z_t\nqquad xi(B) = Psi(B)phi(B)\n\nAssuming this model is appropriate and Z_t is uncorrelated with Y_j for jt, the minimum-MSE linear predictors P_n Y_n+h of Y_n+h (for nk+l_3) satisfy the recursion\n\nP_n Y_n+h = - sum_j=1^k+l_3 xi_j  P_n Y_n+h-j + phi(1)bar S qquad hge 1\n\nwith initial conditions P_n Y_n+h=Y_n+h for hle 0.","category":"section"},{"location":"ararma/#Reference","page":"ARAR/ARARMA","title":"Reference","text":"Brockwell, Peter J., and Richard A. Davis. Introduction to Time Series and Forecasting. Springer (2016)\n\n","category":"section"},{"location":"ararma/#Array-Interface-(Base-Models)","page":"ARAR/ARARMA","title":"Array Interface (Base Models)","text":"The array interface provides direct access to the ARAR fitting engine for working with numeric vectors.\n\nusing Durbyn\nusing Durbyn.Ararma\n\nap = air_passengers()\n\n# Basic ARAR with default parameters\narar_fit = arar(ap)\nfc = forecast(arar_fit, h = 12)\nplot(fc)\n\n# ARAR with custom parameters\narar_fit = arar(ap, max_ar_depth = 20, max_lag = 30)\nfc = forecast(arar_fit, h = 12)\nplot(fc)\n\n","category":"section"},{"location":"ararma/#ARARMA-Model-Theory","page":"ARAR/ARARMA","title":"ARARMA Model Theory","text":"ARARMA extends the ARAR approach by first applying an adaptive AR prefilter to shorten memory (the ARAR stage), and then fitting a short-memory ARMA(p, q) model on the prefiltered residuals. The goal is to capture long/persistent structure via a composed AR filter Psi(B) and the remaining short-term dynamics via an ARMA kernel.\n\nGiven a univariate series Y_t t=12ldotsn, ARARMA produces a fitted model and forecasting mechanism that combine both stages.","category":"section"},{"location":"ararma/#Stage-1-—-Memory-Shortening-(ARAR)","page":"ARAR/ARARMA","title":"Stage 1 — Memory Shortening (ARAR)","text":"As in ARAR, we iteratively test for long memory and, if detected, apply a memory-shortening AR filter. At iteration r, the procedure evaluates delays tau=1ldots15 by ordinary least squares and scores each delay by a relative error measure:\n\nmathrmERR(phitau)\n=\nfracdisplaystylesum_t=tau+1^nbig(Y_t-phiY_t-taubig)^2\n     displaystylesum_t=tau+1^nY_t^2\nqquad\nhatphi(tau)inargmin_phi mathrmERR(phitau)\n\nLet mathrmErr(tau) = mathrmERRbig(hatphi(tau)taubig) and hattau=argmin_tau mathrmErr(tau). Then:\n\nIf mathrmErr(hattau)le 8n or if hatphi(hattau)ge 093 with hattau2, declare long memory and filter:\ntilde Y_t = Y_t - hatphiY_t-hattau\nIf hatphi(hattau)ge 093 with hattauin12, fit an AR(2) at lags 1 and 2 by normal equations and filter:\ntilde Y_t = Y_t - hatphi_1 Y_t-1 - hatphi_2 Y_t-2\nOtherwise, stop.\n\nEach successful reduction composes the prefilter polynomial Psi(B) (with Psi_0=1):\n\nS_t = Psi(B)Y_t = Y_t + Psi_1 Y_t-1 + cdots + Psi_k Y_t-k\nqquad\nPsi(B) = 1 + Psi_1 B + cdots + Psi_k B^k\n\nThe reduction loop terminates when short memory is reached or after three passes (rarely more than two are needed in practice).","category":"section"},{"location":"ararma/#Stage-2-—-Best-Lag-Subset-AR-(on-the-prefiltered-series)","page":"ARAR/ARARMA","title":"Stage 2 — Best-Lag Subset AR (on the prefiltered series)","text":"Let X_t = S_t - bar S with bar S the sample mean of the final prefiltered series. Over 4-term lag tuples (1ijk) satisfying 1ijkle m (with m typically 13 or 26), we fit the subset AR:\n\nX_t = phi_1 X_t-1 + phi_i X_t-i + phi_j X_t-j + phi_k X_t-k + Z_t\nqquad Z_tsim mathrmWN(0sigma^2)\n\nYule–Walker equations (using sample autocorrelations hatrho(cdot) of X_t) yield the coefficients:\n\nbeginbmatrix\n1  hatrho(i-1)  hatrho(j-1)  hatrho(k-1)\nhatrho(i-1)  1  hatrho(j-i)  hatrho(k-i)\nhatrho(j-1)  hatrho(j-i)  1  hatrho(k-j)\nhatrho(k-1)  hatrho(k-i)  hatrho(k-j)  1\nendbmatrix\n\nbeginbmatrix\nphi_12ptphi_i2ptphi_j2ptphi_k\nendbmatrix\n=\nbeginbmatrix\nhatrho(1)2pthatrho(i)2pthatrho(j)2pthatrho(k)\nendbmatrix\n\nThe implied variance is\n\nsigma^2 = hatgamma(0)Big(1 - phi_1 hatrho(1) - phi_i hatrho(i) - phi_j hatrho(j) - phi_k hatrho(k)Big)\n\nwhere hatgamma(cdot) are sample autocovariances of X_t. The algorithm selects (1ijk) minimizing this sigma^2.\n\nDefine the composite AR kernel by convolving the prefilter with the selected subset AR:\n\nphi(B) = 1 - phi_1 B - phi_i B^i - phi_j B^j - phi_k B^k\nqquad\nxi(B) = Psi(B)phi(B)\n\nLet c = big(1-phi_1-phi_i-phi_j-phi_kbig)bar S be the AR intercept.","category":"section"},{"location":"ararma/#Stage-3-—-Short-Memory-ARMA(p,-q)-on-AR-Residuals","page":"ARAR/ARARMA","title":"Stage 3 — Short-Memory ARMA(p, q) on AR Residuals","text":"Using the AR-only fit implied by xi(B) and c, compute residuals and fit an ARMA(p, q) by maximizing the conditional Gaussian likelihood. Denote the ARMA polynomials\n\nPhi(B) = 1 - varphi_1 B - cdots - varphi_p B^p\nqquad\nTheta(B) = 1 + theta_1 B + cdots + theta_q B^q\n\nThe ARMA stage estimates (varphi_1ldotsvarphi_ptheta_1ldotstheta_qsigma^2) via Nelder–Mead. The code log-parameterizes the variance for numerical stability.\n\nInformation criteria. With effective residual length n_texteff and k=p+q parameters (variance excluded), the log-likelihood ell yields\n\nmathrmAIC=2k-2ell qquad mathrmBIC=(log n_texteff)k-2ell","category":"section"},{"location":"ararma/#Forecasting-2","page":"ARAR/ARARMA","title":"Forecasting","text":"With the composite kernel xi(B) and intercept c from Stage 2, and the ARMA(p,q) layer from Stage 3, h-step-ahead forecasts are formed recursively. Let P_n Y_n+h denote the minimum-MSE predictor of Y_n+h. Writing xi(B)=1+xi_1 B+cdots+xi_K B^K,\n\nP_n Y_n+h\n=\n- sum_j=1^K xi_j  P_n Y_n+h-j\n+ c + text(MA terms from  Theta(B)text)\nqquad hge 1\n\nwith initialization P_n Y_n+h=Y_n+h for hle 0 and future shocks set to zero for the MA recursion. Forecast standard errors follow from the MA representation and the estimated innovation variance sigma^2.","category":"section"},{"location":"ararma/#References","page":"ARAR/ARARMA","title":"References","text":"Parzen, E. (1985). ARARMA Models for Time Series Analysis and Forecasting. Journal of Forecasting, 1(1), 67–82.\n\n","category":"section"},{"location":"ararma/#ARARMA-Array-Interface","page":"ARAR/ARARMA","title":"ARARMA Array Interface","text":"using Durbyn\nusing Durbyn.Ararma\n\nap = air_passengers()\n\n# ARARMA with specified orders\nfit1 = ararma(ap, p = 0, q = 1)\nfc1 = forecast(fit1, h = 12)\nplot(fc1)\n\n# Automatic ARARMA order selection\nfit2 = auto_ararma(ap)\nfc2 = forecast(fit2, h = 12)\nplot(fc2)","category":"section"},{"location":"expsmoothing/#Exponential-Smoothing-(ETS):-State-Space-Form,-Additive-and-Multiplicative-Models","page":"Exponential Smoothing","title":"Exponential Smoothing (ETS): State-Space Form, Additive & Multiplicative Models","text":"tip: Formula Interface is the Recommended Approach\nThis page starts with the formula interface (recommended for most users), which provides declarative model specification with EtsSpec, SesSpec, HoltSpec, HoltWintersSpec, and support for panel data and model comparison. The array interface (base models) is covered later. See the Grammar Guide for complete documentation.\n\nThis page summarizes the ETS state-space framework which is implemented in Durbyn.jl as ets() for automatic forecasting, and the admissible parameter regions for stability/forecastability. It includes both additive and multiplicative error models, following Hyndman et al. (2002, 2008).\n\n","category":"section"},{"location":"expsmoothing/#Model-taxonomy-and-notation","page":"Exponential Smoothing","title":"Model taxonomy and notation","text":"ETS models are categorized by (Error, Trend, Seasonality):\n\nANN / MNN — simple exponential smoothing (additive vs multiplicative error)  \nAAN / MAN — additive trend (Holt, with additive vs multiplicative error)  \nADN — damped additive trend (only additive error common in practice)  \nAAA / MAM — additive trend + additive/multiplicative seasonality  \nANA / AAA / ADA — seasonal additive-error forms (with no / additive / damped trend)  \nOther hybrids (e.g. multiplicative seasonality with additive error, damped multiplicative trend) can be defined analogously.\n\nWe use smoothing parameters alphabetagamma and damping phi (if present).   Additive vs multiplicative error models give the same point forecasts but different likelihoods and intervals.\n\n","category":"section"},{"location":"expsmoothing/#Additive-error-state-space-form","page":"Exponential Smoothing","title":"Additive error state-space form","text":"beginaligned\ntextbfObservationquad\n Y_t = Hx_t-1 + varepsilon_t \ntextbfStatequad\n x_t = Fx_t-1 + Gvarepsilon_t qquad varepsilon_t sim WN(0sigma^2)\nendaligned\n\nForecast mean and variance at horizon h:\n\nmu_n(h) = H F^h-1 x_n qquad\nv_n(h) = sigma^2left(1 + sum_j=1^h-1 (HF^j-1G)^2right)\n\n","category":"section"},{"location":"expsmoothing/#Multiplicative-error-form","page":"Exponential Smoothing","title":"Multiplicative error form","text":"For multiplicative error models:\n\nObservation:  \nY_t = hatY_t (1+varepsilon_t)\nwhere varepsilon_t sim WN(0sigma^2).\nKey property: Point forecasts are the same as additive-error models, but prediction intervals scale with the level.","category":"section"},{"location":"expsmoothing/#Examples","page":"Exponential Smoothing","title":"Examples","text":"MNN (no trend, no seasonality):\nY_t = ell_t-1(1+varepsilon_t) qquad\nell_t = ell_t-1(1+alphavarepsilon_t)\nMAN (additive trend):\nY_t = (ell_t-1+b_t-1)(1+varepsilon_t) \nell_t = (ell_t-1+b_t-1)(1+alphavarepsilon_t) \nb_t = b_t-1 + beta(ell_t-1+b_t-1)varepsilon_t\nMAM (additive trend + multiplicative seasonality):\nY_t = (ell_t-1+b_t-1)s_t-m(1+varepsilon_t) \nell_t = (ell_t-1+b_t-1)(1+alphavarepsilon_t) \nb_t = b_t-1+beta(ell_t-1+b_t-1)varepsilon_t \ns_t = s_t-m(1+gammavarepsilon_t)\n\nOther multiplicative combinations (e.g. damped trend, hybrid seasonality) follow analogously.\n\n","category":"section"},{"location":"expsmoothing/#Model-properties","page":"Exponential Smoothing","title":"Model properties","text":"Let M = F-GH.\n\nObservability: operatornamerank(H^top(F^top)H^topdots(F^top)^p-1H^top)=p  \nReachability: operatornamerank(GFGdotsF^p-1G)=p  \nStability: eigenvalues of M lie inside the unit circle  \nForecastability: weaker notion, unstable modes do not affect forecasts if orthogonal to forecast functional\n\nNon-seasonal additive/multiplicative ETS are minimal (reachable & observable).   Standard seasonal ETS are not (contain redundant seasonal states).\n\n","category":"section"},{"location":"expsmoothing/#Admissible-regions-(non-seasonal,-additive-and-multiplicative)","page":"Exponential Smoothing","title":"Admissible regions (non-seasonal, additive & multiplicative)","text":"For ANN/AAN/ADN (and their multiplicative analogues), the admissible stability regions are identical:\n\nANN / MNN\n0  alpha  2\nAAN / MAN\n0  alpha  2 qquad 0  beta  4-2alpha\nADN (damped additive trend)\n0  phi le 1 qquad\n1-tfrac1phi  alpha  1+tfrac1phi qquad\nalpha(phi-1)  beta  (1+phi)(2-alpha)\n\nThus, admissible regions do not depend on whether errors are additive or multiplicative.\n\n","category":"section"},{"location":"expsmoothing/#Seasonal-ETS","page":"Exponential Smoothing","title":"Seasonal ETS","text":"","category":"section"},{"location":"expsmoothing/#Standard-Holt–Winters-seasonal-form","page":"Exponential Smoothing","title":"Standard Holt–Winters seasonal form","text":"In ANA/AAA/ADA with recursion s_t=s_t-m+gammavarepsilon_t,   M has a unit eigenvalue → unstable, non-minimal.   Forecasts can remain valid (forecastable) but states are corrupted.\n\nCharacteristic polynomial factorization (ADA case):\n\nf(lambda) = (1-lambda)P(lambda)\n\nwith forecastability polynomial P(lambda) whose roots must lie inside the unit circle.   AAA is the special case phi=1.","category":"section"},{"location":"expsmoothing/#Normalized-seasonal-ETS","page":"Exponential Smoothing","title":"Normalized seasonal ETS","text":"Fix instability by imposing a sum-to-zero seasonal constraint each period:\n\nS(B)s_t = theta(B)gammavarepsilon_t\n\nwhere S(B)=1+B+cdots+B^m-1,   theta(B)=tfrac1m(m-1)+(m-2)B+cdots+B^m-2.\n\nOperationally: after updating seasonals, subtract the average of last m shocks.   This normalization restores stability.\n\n\n\ninfo: Need multiple seasonal cycles?\nThe bats models extend ETS with Box–Cox transforms, ARMA errors, damped trends, and multiple seasonal periods following De Livera, Hyndman & Snyder (2011).","category":"section"},{"location":"expsmoothing/#References","page":"Exponential Smoothing","title":"References","text":"Hyndman, Koehler, Snyder & Grose (2002). A state space framework for automatic forecasting using exponential smoothing methods.\nHyndman, Akram & Archibald (2006). The admissible parameter space for exponential smoothing models.\nHyndman, R.J., Koehler, A.B., Ord, J.K., Snyder, R.D. (2008) Forecasting with exponential smoothing: the state space approach, Springer-Verlag: New York. http://www.exponentialsmoothing.net\nHyndman and Athanasopoulos (2018) Forecasting: principles and practice, 2nd edition, OTexts: Melbourne, Australia. https://otexts.com/fpp2/\n\n","category":"section"},{"location":"expsmoothing/#Formula-Interface-(Primary-Usage)","page":"Exponential Smoothing","title":"Formula Interface (Primary Usage)","text":"The formula interface provides a modern, declarative way to specify exponential smoothing models with full support for single series, model comparison, and panel data.","category":"section"},{"location":"expsmoothing/#Example-1:-Automatic-ETS-Selection","page":"Exponential Smoothing","title":"Example 1: Automatic ETS Selection","text":"Let the algorithm choose the best error, trend, and seasonal components:\n\nusing Durbyn\nusing Durbyn.Grammar\n\n# Load data\ndata = (sales = [120, 135, 148, 152, 141, 158, 170, 165, 180, 195],)\n\n# Automatic model selection (error, trend, seasonal all set to \"Z\" for automatic)\nspec = EtsSpec(@formula(sales = e(\"Z\") + t(\"Z\") + s(\"Z\")))\nfitted = fit(spec, data, m = 12)\nfc = forecast(fitted, h = 12)\nplot(fc)\n# Check selected model\nprintln(fitted.fit.method)  # Shows selected ETS model\n\n# Access fitted values and residuals\nfitted_values = fitted.fit.fitted\nresids = fitted.fit.residuals\n\nKey features:\n\ne(\"Z\"), t(\"Z\"), s(\"Z\") trigger automatic selection\nm = 12 specifies monthly seasonality\nSearches over all admissible ETS models","category":"section"},{"location":"expsmoothing/#Example-2:-Specific-ETS-Model","page":"Exponential Smoothing","title":"Example 2: Specific ETS Model","text":"Specify exact error, trend, and seasonal components:\n\n# ETS(A,A,M): Additive error, Additive trend, Multiplicative seasonality\nspec = EtsSpec(@formula(sales = e(\"A\") + t(\"A\") + s(\"M\")))\nfitted = fit(spec, data, m = 12)\nfc = forecast(fitted, h = 12)\nplot(fc)\n# ETS(M,Ad,M): Multiplicative error, Additive damped trend, Multiplicative seasonal\nspec_damped = EtsSpec(@formula(sales = e(\"M\") + t(\"A\") + s(\"M\") + drift()))\nfitted_damped = fit(spec_damped, data, m = 12)\nfc_damped = forecast(fitted_damped, h = 12)\nplot(fc_damped)\n# ETS(A,N,N): Simple exponential smoothing (additive error, no trend, no seasonality)\nspec_ses = EtsSpec(@formula(sales = e(\"A\") + t(\"N\") + s(\"N\")))\nfitted_ses = fit(spec_ses, data)\nfc_ses = forecast(fitted_ses, h = 12)\nplot(fc_ses)\n\nComponent specification:\n\nError: \"A\" (additive), \"M\" (multiplicative), \"Z\" (auto)\nTrend: \"N\" (none), \"A\" (additive), \"Ad\" (additive damped), \"M\" (multiplicative), \"Md\" (multiplicative damped), \"Z\" (auto)\nSeasonal: \"N\" (none), \"A\" (additive), \"M\" (multiplicative), \"Z\" (auto)","category":"section"},{"location":"expsmoothing/#Example-3:-Specialized-ETS-Specs","page":"Exponential Smoothing","title":"Example 3: Specialized ETS Specs","text":"Use convenience specs for common models:\n\n# Simple Exponential Smoothing (SES)\nspec_ses = SesSpec(@formula(sales = ses()))\nfitted_ses = fit(spec_ses, data)\nfc_ses = forecast(fitted_ses, h = 12)\nplot(fc_ses)\n\n# Holt's Linear Trend\nspec_holt = HoltSpec(@formula(sales = holt()))\nfitted_holt = fit(spec_holt, data)\nfc_holt = forecast(fitted_holt, h = 12)\nplot(fc_holt)\n# Holt's method with damped trend (recommended for long horizons)\nspec_holt_damped = HoltSpec(@formula(sales = holt(damped = true)))\nfitted_holt_damped = fit(spec_holt_damped, data)\nfc_holt_damped = forecast(fitted_holt_damped, h = 12)\nplot(fc_holt_damped)\n# Holt-Winters Seasonal\nap = (passengers = air_passengers(), )\nspec_hw = HoltWintersSpec(@formula(passengers = hw(seasonal=:additive)))\nfitted_hw = fit(spec_hw, ap, m = 12)\nfc_hw = forecast(fitted_hw, h = 12)\nplot(fc_hw)\n# Holt-Winters with multiplicative seasonality\nspec_hw_mult = HoltWintersSpec(@formula(passengers = hw(seasonal=:multiplicative)))\nfitted_hw_mult = fit(spec_hw_mult, ap, m = 12)\nfc_hw = forecast(fitted_hw_mult, h = 12)\nplot(fc_hw)\n\nSpecialized specs:\n\nSesSpec: Simple exponential smoothing\nHoltSpec: Linear trend (with optional damping)\nHoltWintersSpec: Seasonal models (additive or multiplicative)","category":"section"},{"location":"expsmoothing/#Example-4:-Fitting-Multiple-Models-Together","page":"Exponential Smoothing","title":"Example 4: Fitting Multiple Models Together","text":"Fit different ETS specifications and manually compare results:\n\nusing Durbyn\nusing Durbyn.Grammar\n\n# Create synthetic monthly sales data with trend and seasonality\nn = 72  # 6 years of monthly data\ntt = 1:n\ntrend = 100 .+ 2 .* tt\nseasonal = 20 .* sin.(2π .* tt ./ 12)  # Annual seasonality\nnoise = randn(n) .* 5\nsales_data = trend .+ seasonal .+ noise\n\n# Split into training and test sets\nn_test = 12\ntrain_sales = sales_data[1:(end - n_test)]\ntest_sales = sales_data[(end - n_test + 1):end]\n\n# Create data structure for training\ndata = (sales = train_sales,)\ntest = (sales = test_sales,)\n\n# Fit multiple ETS models at once\n# Fit multiple ETS models at once\n  models = model(\n      EtsSpec(@formula(sales = e(\"A\") + t(\"A\") + s(\"A\"))),           # Additive Holt-Winters\n      EtsSpec(@formula(sales = e(\"M\") + t(\"A\") + s(\"M\"))),           # Multiplicative seasonality\n      EtsSpec(@formula(sales = e(\"A\") + t(\"A\") + drift() + s(\"A\"))), # Damped trend\n      SesSpec(@formula(sales = ses())),                              # Simple exponential smoothing\n      HoltSpec(@formula(sales = holt())),                            # Holt's method\n      names = [\"hw_aaa\", \"ets_mam\", \"hw_damped\", \"ses\", \"holt\"]\n  )\n\n# Fit all models\nfitted = fit(models, data, m = 12)\n\n# Forecast with all models\nfc = forecast(fitted, h = 12)\n\n# Compare forecasts against test data\nacc = accuracy(fc, test)\nglimpse(acc)\n\n# Manually compare information criteria\nfor (name, model_result) in zip(models.names, fitted.models)\n    println(\"$name: AIC = $(round(model_result.fit.aic, digits=2)), BIC = $(round(model_result.fit.bic, digits=2))\")\nend\n\n# Plot forecasts (if plotting is available)\nplot(fc)\n\nfc_tbl = forecast_table(fc)\nglimpse(fc_tbl)\n\n\nKey features:\n\nGenerate synthetic data with trend and seasonality\nFit multiple ETS specifications at once\nMix different exponential smoothing methods\nCompare forecasts against held-out test data\nManually inspect AIC, BIC, and other diagnostics\nForecasts generated for all models\n\nAlternative damped trend specification:\n\n# Instead of using drift() in the formula, you can use the damped parameter\nEtsSpec(@formula(sales = e(\"A\") + t(\"A\") + s(\"A\")), damped=true)","category":"section"},{"location":"expsmoothing/#Example-5:-Panel-Data-(Multiple-Time-Series)","page":"Exponential Smoothing","title":"Example 5: Panel Data (Multiple Time Series)","text":"Fit ETS models to multiple series:\n\nnote: Optional Dependencies\n\n\nThis example requires CSV and Downloads packages, which are not installed by default with Durbyn.\n\nInstall them first:\n\nusing Pkg\nPkg.add([\"CSV\", \"Downloads\"])\n\nusing Durbyn\nusing Durbyn.ModelSpecs\nusing Durbyn.Grammar\nusing Downloads\nusing Tables\nusing CSV\n\n# Download and load data\npath = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\ntbl = Tables.columntable(CSV.File(path))\n\n# Reshape to long format\ntbl = pivot_longer(tbl; id_cols=:date, names_to=:series, values_to=:value)\n\nglimpse(tbl)\n\n# Split into train and test sets using table operations\n# Get unique dates to determine split point\nall_dates = unique(tbl.date)\nn_dates = length(all_dates)\nsplit_date = all_dates[end-11]  # Hold out last 12 periods for testing\n\n# Create train and test sets\ntrain = query(tbl, row -> row.date <= split_date)\ntest = query(tbl, row -> row.date > split_date)\n\nprintln(\"Training data:\")\nglimpse(train)\nprintln(\"\\nTest data:\")\nglimpse(test)\n\n# Create panel data wrapper for training\npanel = PanelData(train; groupby=:series, date=:date, m=12);\n\nglimpse(panel)\n\n# Fit automatic ETS to all series\nspec = EtsSpec(@formula(value = e(\"Z\") + t(\"Z\") + s(\"Z\")))\nfitted = fit(spec, panel)\n\n# Forecast all series\nfc = forecast(fitted, h = 12)\n\n# Get tidy forecast table\nfc_tbl = forecast_table(fc)\n\nglimpse(fc_tbl)\n\n# Plot forecasts \nlist_series(fc)  # See what's available\nplot(fc)  # Quick look at first series\nplot(fc, series=:all, facet=true, n_cols=4)  # Overview\n\n# Detailed inspection\nplot(fc, series=\"series_1\", actual=test)\n\n\nPanel data features:\n\nFits separate model to each series\nAutomatic model selection for each series individually\nReturns structured output for all series\nEfficient for hundreds or thousands of series","category":"section"},{"location":"expsmoothing/#Example-6:-Box-Cox-Transformation","page":"Exponential Smoothing","title":"Example 6: Box-Cox Transformation","text":"Handle non-constant variance with Box-Cox transformation:\n\n# Automatic lambda selection\nspec = EtsSpec(@formula(sales = e(\"A\") + t(\"A\") + s(\"M\")))\nfitted = fit(spec, data, m = 12, lambda = \"auto\", biasadj = true)\n\n# Check selected lambda\nprintln(fitted.fit.lambda)\n\n# Manual lambda\nfitted_lambda = fit(spec, data, m = 12, lambda = 0.5)\n# Check fixed lambda\nprintln(fitted_lambda.fit.lambda)\n\n\n\nTransformation features:\n\nlambda = \"auto\" selects optimal transformation\nbiasadj = true applies bias adjustment to forecasts\nCommon values: 0 (log), 0.5 (square root), 1 (no transform)\n\n","category":"section"},{"location":"expsmoothing/#Array-Interface-(Base-Models)","page":"Exponential Smoothing","title":"Array Interface (Base Models)","text":"The array interface provides direct access to exponential smoothing engines for numeric vectors. ","category":"section"},{"location":"expsmoothing/#Simple-Exponential-Smoothing-(SES)","page":"Exponential Smoothing","title":"Simple Exponential Smoothing (SES)","text":"Simple exponential smoothing is the simplest form of exponential smoothing (equivalent to ETS(A,N,N) or ETS(M,N,N)), with no trend or seasonality components. It is suitable for forecasting data with no clear trend or seasonal pattern.","category":"section"},{"location":"expsmoothing/#Mathematical-Formulation","page":"Exponential Smoothing","title":"Mathematical Formulation","text":"","category":"section"},{"location":"expsmoothing/#Additive-Error-Form-(ANN)","page":"Exponential Smoothing","title":"Additive Error Form (ANN)","text":"beginaligned\nY_t = ell_t-1 + varepsilon_t \nell_t = ell_t-1 + alphavarepsilon_t\nendaligned\n\nwhere ell_t is the level at time t, alpha in (01) is the smoothing parameter, and varepsilon_t sim WN(0sigma^2).\n\nComponent form:\n\nell_t = alpha Y_t + (1-alpha)ell_t-1\n\nForecast function: The h-step ahead forecast is simply the last estimated level:\n\nhatY_n+hn = ell_n quad textfor all  h ge 1\n\nPrediction variance:\n\ntextVarhatY_n+hn = sigma^2 h","category":"section"},{"location":"expsmoothing/#Multiplicative-Error-Form-(MNN)","page":"Exponential Smoothing","title":"Multiplicative Error Form (MNN)","text":"beginaligned\nY_t = ell_t-1(1 + varepsilon_t) \nell_t = ell_t-1(1 + alphavarepsilon_t)\nendaligned\n\nPoint forecasts are identical to the additive form, but prediction intervals scale with the level.","category":"section"},{"location":"expsmoothing/#Admissible-Parameter-Space","page":"Exponential Smoothing","title":"Admissible Parameter Space","text":"For stability and forecastability:\n\n0  alpha  2\n\nIn practice, alpha is typically constrained to (01) for conventional exponential smoothing behavior.","category":"section"},{"location":"expsmoothing/#Usage","page":"Exponential Smoothing","title":"Usage","text":"The ses() function provides two initialization methods:\n\ninitial = \"optimal\" (default): Uses state-space optimization via ETS framework\ninitial = \"simple\": Uses conventional Holt-Winters initialization\n\nusing Durbyn\nusing Durbyn.ExponentialSmoothing\n\n# Load example data\ny = [10.5, 12.3, 11.8, 13.1, 12.9, 14.2, 13.8, 15.1, 14.7, 16.0]\n\n# Fit SES with optimal initialization\nses_model = ses(y)\n\n# Fit SES with specified alpha\nfit_fixed = ses(y, alpha = 0.3)\n\n# Fit SES with Box-Cox transformation\nfit_bc = ses(y, lambda = 0.5)\n\n# Generate forecasts\nfc = forecast(ses_model, h = 6)\n\n# For seasonal data (frequency m)\nmonthly_data = randn(60) .+ 100\nfit_seasonal = ses(monthly_data, 12)  # m = 12 for monthly data\nfc_seasonal = forecast(fit_seasonal, h = 12)","category":"section"},{"location":"expsmoothing/#Model-Output","page":"Exponential Smoothing","title":"Model Output","text":"The SES struct contains:\n\nfitted: Fitted values (one-step ahead predictions)\nresiduals: Residuals (observed - fitted)\ncomponents: Model components (level)\nx: Original time series data\npar: Model parameters (alpha)\ninitstate: Initial level estimate\nstates: Level estimates over time\nsigma2: Residual variance\naic, bic, aicc: Information criteria (when initial = \"optimal\")\nmse, amse: Mean squared error measures\nlambda: Box-Cox transformation parameter (if used)\nbiasadj: Boolean flag for bias adjustment","category":"section"},{"location":"expsmoothing/#When-to-Use-SES","page":"Exponential Smoothing","title":"When to Use SES","text":"Use simple exponential smoothing when:\n\nData exhibits no clear trend or seasonal pattern\nYou need quick, computationally efficient forecasts\nRecent observations should be weighted more heavily than older ones\nYou have limited data and want a parsimonious model\n\nLimitations:\n\nCannot capture trend or seasonality\nForecasts are constant (flat line)\nMay underperform for data with systematic patterns\n\nFor data with trend or seasonality, consider:\n\nHolt's method (holt()) for trended data\nHolt-Winters (hw()) for seasonal data\nETS (ets()) for automatic model selection\n\n","category":"section"},{"location":"expsmoothing/#Holt's-Linear-Trend-Method","page":"Exponential Smoothing","title":"Holt's Linear Trend Method","text":"Holt's method (also known as double exponential smoothing) extends SES to capture linear trends in time series data. It uses two smoothing parameters: α for the level and β for the trend component.","category":"section"},{"location":"expsmoothing/#Mathematical-Formulation-2","page":"Exponential Smoothing","title":"Mathematical Formulation","text":"","category":"section"},{"location":"expsmoothing/#Standard-Holt's-Method-(Additive-Trend)","page":"Exponential Smoothing","title":"Standard Holt's Method (Additive Trend)","text":"beginaligned\nY_t = ell_t-1 + b_t-1 + varepsilon_t \nell_t = alpha Y_t + (1-alpha)(ell_t-1 + b_t-1) \nb_t = beta(ell_t - ell_t-1) + (1-beta)b_t-1\nendaligned\n\nwhere ell_t is the level, b_t is the trend, alpha beta in (01) are smoothing parameters, and varepsilon_t sim WN(0sigma^2).\n\nComponent form:\n\nLevel: ell_t = alpha Y_t + (1-alpha)(ell_t-1 + b_t-1)\nTrend: b_t = beta(ell_t - ell_t-1) + (1-beta)b_t-1\n\nForecast function: The h-step ahead forecast incorporates the trend:\n\nhatY_n+hn = ell_n + h cdot b_n","category":"section"},{"location":"expsmoothing/#Damped-Trend","page":"Exponential Smoothing","title":"Damped Trend","text":"beginaligned\nY_t = ell_t-1 + phi b_t-1 + varepsilon_t \nell_t = alpha Y_t + (1-alpha)(ell_t-1 + phi b_t-1) \nb_t = beta(ell_t - ell_t-1) + (1-beta)phi b_t-1\nendaligned\n\nwhere phi in (01 is the damping parameter.\n\nForecast function:\n\nhatY_n+hn = ell_n + (phi + phi^2 + cdots + phi^h) b_n = ell_n + phifrac1-phi^h1-phib_n\n\nThe damping parameter controls how quickly the trend dampens:\n\nphi = 1: Standard Holt (no damping)\nphi  1: Damped trend (trend flattens out in forecasts)\n\nAdvantages of damped trend:\n\nMore realistic long-term forecasts\nPrevents unbounded linear extrapolation\nOften improves forecast accuracy for horizons h > 10","category":"section"},{"location":"expsmoothing/#Exponential-(Multiplicative)-Trend","page":"Exponential Smoothing","title":"Exponential (Multiplicative) Trend","text":"beginaligned\nY_t = ell_t-1 cdot b_t-1^phi + varepsilon_t \nell_t = alpha Y_t + (1-alpha) ell_t-1 cdot b_t-1^phi \nb_t = beta fracell_tell_t-1 + (1-beta) b_t-1^phi\nendaligned\n\nUsed when the trend grows/declines exponentially rather than linearly.","category":"section"},{"location":"expsmoothing/#Admissible-Parameter-Space-2","page":"Exponential Smoothing","title":"Admissible Parameter Space","text":"For standard Holt (no damping):\n\nbeginaligned\n0  alpha  2 \n0  beta  4 - 2alpha\nendaligned\n\nFor damped Holt (phi  1):\n\nbeginaligned\n0  phi le 1 \n1 - frac1phi  alpha  1 + frac1phi \nalpha(phi - 1)  beta  (1+phi)(2-alpha)\nendaligned","category":"section"},{"location":"expsmoothing/#Usage-2","page":"Exponential Smoothing","title":"Usage","text":"using Durbyn\nusing Durbyn.ExponentialSmoothing\n\n# Simulate data with linear trend\nt = 1:50\ny = 100 .+ 2 .* t .+ randn(50) .* 5\n\n# Standard Holt's method (m parameter optional since no seasonality)\nholt_model = holt(y)\nprintln(holt_model)\n\n# Generate forecasts\nfc = forecast(holt_model, h=10)\nplot(fc)\n\n# Damped trend (recommended for long horizons)\nfit_damped = holt(y, damped=true)\nfc_damped = forecast(fit_damped, h=24)\n\n# Holt with fixed parameters\nfit_fixed = holt(y, alpha=0.8, beta=0.2)\n\n# Exponential trend\nfit_exp = holt(y, exponential=true)\n\n# With Box-Cox transformation\nfit_bc = holt(y, lambda=\"auto\", biasadj=true)\n\n# Simple initialization\nfit_simple = holt(y, initial=\"simple\")\n\n# Can also specify m explicitly (though typically not needed)\nfit_explicit = holt(y, 1, damped=true)","category":"section"},{"location":"expsmoothing/#Model-Output-2","page":"Exponential Smoothing","title":"Model Output","text":"The Holt struct contains:\n\nfitted: Fitted values (one-step ahead predictions)\nresiduals: Residuals (observed - fitted)\ncomponents: Model components (level and trend)\nx: Original time series data\npar: Model parameters (alpha, beta, and phi if damped)\ninitstate: Initial level and trend estimates\nstates: Level and trend estimates over time\nsigma2: Residual variance\naic, bic, aicc: Information criteria (when initial = \"optimal\")\nmse, amse: Mean squared error measures\nlambda: Box-Cox transformation parameter (if used)\nbiasadj: Boolean flag for bias adjustment\nmethod: Method description (e.g., \"Holt's method\", \"Damped Holt's method\")","category":"section"},{"location":"expsmoothing/#When-to-Use-Holt's-Method","page":"Exponential Smoothing","title":"When to Use Holt's Method","text":"Use Holt's linear trend method when:\n\nData exhibits a clear linear trend (increasing or decreasing)\nNo seasonal pattern is present\nYou need to extrapolate the trend into the future\nRecent trend behavior should influence forecasts\n\nUse damped trends when:\n\nLong-horizon forecasts are needed (h > 10)\nThe trend may not continue indefinitely at the same rate\nYou want more conservative, realistic forecasts\nHistorical data shows trends that eventually flatten\n\nLimitations:\n\nCannot capture seasonality (use Holt-Winters hw() instead)\nAssumes trend is approximately linear\nWithout damping, forecasts can be unrealistic for long horizons\nMay overreact to recent trend changes\n\nComparison with SES:\n\nSES: No trend, forecasts are flat (constant)\nHolt: Linear trend, forecasts increase/decrease linearly\nDamped Holt: Trend that dampens, forecasts flatten over time\n\n","category":"section"},{"location":"expsmoothing/#Automatic-ETS-Model-Selection","page":"Exponential Smoothing","title":"Automatic ETS Model Selection","text":"using Durbyn\nusing Durbyn.ExponentialSmoothing\n# Fit automatically selected ETS model to a monthly series (m = 12)\nap = air_passengers()\nets_model = ets(ap(), 12, \"ZZZ\")\n\n# Specify a particular structure (multiplicative seasonality, additive trend, additive errors)\nfit2 = ets(ap, 12, \"AAM\")\nfc2 = forecast(fit2, h=12)\nplot(fc2)\n\n# Use a damped trend search and automatic Box–Cox selection\nfit3 = ets(ap, 12, \"ZZZ\"; damped=nothing, lambda=\"auto\", biasadj=true)\nfc3 = forecast(fit3, h=12)\nplot(fc3)","category":"section"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"note: Note\nTable operations functions (glimpse, select, query, arrange, groupby, mutate, summarise, pivot_longer, pivot_wider) are documented in the Table Operations guide.","category":"section"},{"location":"tableops/#Table-Operations","page":"Table Operations","title":"Table Operations","text":"The TableOps module provides a comprehensive set of data manipulation functions for working with Tables.jl-compatible data sources. These functions enable common data wrangling tasks like filtering, grouping, pivoting, and summarizing data.","category":"section"},{"location":"tableops/#Overview","page":"Table Operations","title":"Overview","text":"TableOps is inspired by popular data manipulation libraries like dplyr (R) and pandas (Python), but designed specifically for Julia's Tables.jl ecosystem. All functions work seamlessly with any Tables.jl-compatible data source, including:\n\nNamedTuples\nDataFrames\nCSV.File objects\nAnd many others","category":"section"},{"location":"tableops/#Getting-Started","page":"Table Operations","title":"Getting Started","text":"using CSV\nusing Downloads\nusing Tables\nusing Durbyn\nusing Durbyn.TableOps\nusing Durbyn.Grammar\nusing Durbyn.ModelSpecs\n\n# Download example retail data\nlocal_path = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\nretail = CSV.File(local_path)\ntbl = Tables.columntable(retail)\n\n# Preview the data\nglimpse(tbl)","category":"section"},{"location":"tableops/#Core-Functions","page":"Table Operations","title":"Core Functions","text":"","category":"section"},{"location":"tableops/#glimpse-Quick-Data-Preview","page":"Table Operations","title":"glimpse - Quick Data Preview","text":"Get a compact summary of your data, showing column names, types, and sample values.\n\nusing Durbyn.TableOps\n\ntbl = (date = [\"2024-01\", \"2024-02\", \"2024-03\"],\n       A = [100, 110, 120],\n       B = [200, 220, 240],\n       C = [300, 330, 360])\n\nglimpse(tbl)\n# Table glimpse\n#   Rows: 3\n#   Columns: 4\n#   date                :: String  [2024-01, 2024-02, 2024-03]\n#   A                   :: Int64   [100, 110, 120]\n#   B                   :: Int64   [200, 220, 240]\n#   C                   :: Int64   [300, 330, 360]","category":"section"},{"location":"tableops/#select-Choose-and-Rename-Columns","page":"Table Operations","title":"select - Choose and Rename Columns","text":"Select specific columns from your data, optionally renaming them.\n\nusing Durbyn.TableOps\n\ntbl = (id = [1, 2, 3],\n       name = [\"Alice\", \"Bob\", \"Charlie\"],\n       age = [25, 30, 35],\n       salary = [50000, 60000, 70000])\n\n# Select specific columns\nselect(tbl, :name, :age)\n# Output: (name = [\"Alice\", \"Bob\", \"Charlie\"], age = [25, 30, 35])\n\n# Rename while selecting\nselect(tbl, :employee => :name, :years => :age)\n# Output: (employee = [\"Alice\", \"Bob\", \"Charlie\"], years = [25, 30, 35])","category":"section"},{"location":"tableops/#query-Filter-Rows","page":"Table Operations","title":"query - Filter Rows","text":"Filter rows based on custom conditions using a predicate function.\n\nusing Durbyn.TableOps\n\ntbl = (product = [\"A\", \"B\", \"C\", \"D\", \"E\"],\n       price = [10, 25, 15, 30, 20],\n       quantity = [100, 50, 75, 25, 60])\n\n# Filter rows where price > 15\nquery(tbl, row -> row.price > 15)\n# Output: (product = [\"B\", \"D\", \"E\"], price = [25, 30, 20], quantity = [50, 25, 60])\n\n# Multiple conditions\nquery(tbl, row -> row.price > 15 && row.quantity > 30)\n# Output: (product = [\"B\", \"E\"], price = [25, 20], quantity = [50, 60])","category":"section"},{"location":"tableops/#arrange-Sort-Data","page":"Table Operations","title":"arrange - Sort Data","text":"Sort rows by one or more columns in ascending or descending order.\n\nusing Durbyn.TableOps\n\ntbl = (name = [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n       department = [\"Sales\", \"IT\", \"Sales\", \"IT\"],\n       salary = [60000, 70000, 55000, 75000])\n\n# Sort by salary (ascending)\narrange(tbl, :salary)\n# Output: (name = [\"Charlie\", \"Alice\", \"Bob\", \"David\"],\n#          department = [\"Sales\", \"Sales\", \"IT\", \"IT\"],\n#          salary = [55000, 60000, 70000, 75000])\n\n# Sort by salary (descending)\narrange(tbl, :salary => :desc)\n# Output: (name = [\"David\", \"Bob\", \"Alice\", \"Charlie\"],\n#          department = [\"IT\", \"IT\", \"Sales\", \"Sales\"],\n#          salary = [75000, 70000, 60000, 55000])\n\n# Multi-column sort: department ascending, then salary descending\narrange(tbl, :department, :salary => :desc)\n# Output: (name = [\"David\", \"Bob\", \"Alice\", \"Charlie\"],\n#          department = [\"IT\", \"IT\", \"Sales\", \"Sales\"],\n#          salary = [75000, 70000, 60000, 55000])","category":"section"},{"location":"tableops/#mutate-Add-or-Modify-Columns","page":"Table Operations","title":"mutate - Add or Modify Columns","text":"Create new columns or modify existing ones based on computations.\n\nusing Durbyn.TableOps\n\ntbl = (product = [\"A\", \"B\", \"C\"],\n       price = [10.0, 20.0, 15.0],\n       quantity = [100, 50, 75])\n\n# Add a new column\nmutate(tbl, revenue = data -> data.price .* data.quantity)\n# Output: (product = [\"A\", \"B\", \"C\"],\n#          price = [10.0, 20.0, 15.0],\n#          quantity = [100, 50, 75],\n#          revenue = [1000.0, 1000.0, 1125.0])\n\n# Add multiple columns\nmutate(tbl,\n    revenue = data -> data.price .* data.quantity,\n    discounted_price = data -> data.price .* 0.9)\n\n# Modify existing column\nmutate(tbl, price = data -> data.price .* 1.1)  # 10% price increase","category":"section"},{"location":"tableops/#groupby-Group-Data","page":"Table Operations","title":"groupby - Group Data","text":"Group rows by unique combinations of values in specified columns.\n\nusing Durbyn.TableOps\n\ntbl = (department = [\"Sales\", \"IT\", \"Sales\", \"IT\", \"Sales\"],\n       employee = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n       salary = [60000, 70000, 55000, 75000, 65000])\n\n# Group by department\ngt = groupby(tbl, :department)\n# Output: GroupedTable(2 groups by department)\n\nglimpse(gt)\n# GroupedTable glimpse\n#   Groups: 2\n#   Key columns: department\n#   Rows: 5 (avg 2.5, min 2, max 3)\n#   Group 1: (department = \"IT\",) (2 rows)\n#     ...\n#   Group 2: (department = \"Sales\",) (3 rows)\n#     ...","category":"section"},{"location":"tableops/#summarise-/-summarize-Aggregate-Data","page":"Table Operations","title":"summarise / summarize - Aggregate Data","text":"Compute summary statistics for each group in a GroupedTable.\n\nusing Durbyn.TableOps\nusing Statistics\n\ntbl = (department = [\"Sales\", \"IT\", \"Sales\", \"IT\", \"Sales\"],\n       employee = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n       salary = [60000, 70000, 55000, 75000, 65000])\n\ngt = groupby(tbl, :department)\n\n# Compute mean salary per department\nstbl = summarise(gt, avg_salary = :salary => mean)\n# Output: (department = [\"IT\", \"Sales\"], avg_salary = [72500.0, 60000.0])\nglimpse(stbl)\n\n# Multiple summary statistics\nsummarise(gt,\n    avg_salary = :salary => mean,\n    min_salary = :salary => minimum,\n    max_salary = :salary => maximum,\n    count = data -> length(data.salary))\n# Output: (department = [\"IT\", \"Sales\"],\n#          avg_salary = [72500.0, 60000.0],\n#          min_salary = [70000, 55000],\n#          max_salary = [75000, 65000],\n#          count = [2, 3])","category":"section"},{"location":"tableops/#pivot_longer-Wide-to-Long-Format","page":"Table Operations","title":"pivot_longer - Wide to Long Format","text":"Transform data from wide format to long format by pivoting columns into rows.\n\nusing CSV\nusing Downloads\nusing Tables\nusing Durbyn\nusing Durbyn.TableOps\n\n# Download and load retail data\nlocal_path = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\nretail = CSV.File(local_path)\ntbl = Tables.columntable(retail)\n\n# Preview wide format\nglimpse(tbl)\n\n# Convert from wide to long format\ntbl_long = pivot_longer(tbl, id_cols=:date, names_to=:series, values_to=:value)\nglimpse(tbl_long)\n\n# Example with simpler data\nwide = (date = [\"2024-01\", \"2024-02\", \"2024-03\"],\n        A = [100, 110, 120],\n        B = [200, 220, 240],\n        C = [300, 330, 360])\n\nlong = pivot_longer(wide, id_cols=:date, names_to=:series, values_to=:value)\n# Output: (date = [\"2024-01\", \"2024-01\", \"2024-01\", \"2024-02\", \"2024-02\", \"2024-02\", \"2024-03\", \"2024-03\", \"2024-03\"],\n#          series = [\"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\", \"B\", \"C\"],\n#          value = [100, 200, 300, 110, 220, 330, 120, 240, 360])\nglimpse(long)\nglimpse(wide)","category":"section"},{"location":"tableops/#pivot_wider-Long-to-Wide-Format","page":"Table Operations","title":"pivot_wider - Long to Wide Format","text":"Transform data from long format to wide format by spreading rows into columns.\n\nusing Durbyn.TableOps\n\n# Long format data\nlong = (date = [\"2024-01\", \"2024-01\", \"2024-01\", \"2024-02\", \"2024-02\", \"2024-02\"],\n        series = [\"A\", \"B\", \"C\", \"A\", \"B\", \"C\"],\n        value = [100, 200, 300, 110, 220, 330])\n\n# Convert to wide format\nwide = pivot_wider(long, names_from=:series, values_from=:value, id_cols=:date)\n# Output: (date = [\"2024-01\", \"2024-02\"],\n#          A = [100, 110],\n#          B = [200, 220],\n#          C = [300, 330])\n\nglimpse(long)\nglimpse(wide)\n\n# Sort column names alphabetically\npivot_wider(long, names_from=:series, values_from=:value,\n            id_cols=:date, sort_names=true)\n\n# Handle missing values with custom fill\nincomplete = (id = [1, 1, 2], category = [\"A\", \"B\", \"A\"], val = [10, 20, 30])\npivot_wider(incomplete, names_from=:category, values_from=:val, fill=0)\n# Output: (id = [1, 2], A = [10, 30], B = [20, 0])","category":"section"},{"location":"tableops/#Complete-Workflow-Example","page":"Table Operations","title":"Complete Workflow Example","text":"Here's a complete example demonstrating how to chain multiple operations together for a typical data analysis workflow:\n\nusing CSV\nusing Downloads\nusing Tables\nusing Durbyn.TableOps\nusing Statistics\n\n# Download retail data\nlocal_path = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\nretail = CSV.File(local_path)\ntbl = Tables.columntable(retail)\n\n# Step 1: Preview the data\nglimpse(tbl)\n\n# Step 2: Transform from wide to long format\ntbl_long = pivot_longer(tbl, id_cols=:date, names_to=:series, values_to=:value)\nglimpse(tbl_long)\n\n# Step 3: Filter to specific series\ntbl_filtered = query(tbl_long, row -> row.series in [\"series_10\", \"series_20\", \"series_30\"])\n\n# Step 4: Add computed columns\ntbl_with_log = mutate(tbl_filtered, log_value = data -> log.(data.value))\n\n# Step 5: Group by series\ngt = groupby(tbl_with_log, :series)\n\n# Step 6: Compute summary statistics\nsummary = summarise(gt,\n    mean_value = :value => mean,\n    std_value = :value => std,\n    min_value = :value => minimum,\n    max_value = :value => maximum,\n    count = data -> length(data.value))\n\nglimpse(summary)\n\n# Step 7: Sort by mean value\nresult = arrange(summary, :mean_value => :desc)\nglimpse(result)","category":"section"},{"location":"tableops/#Chaining-Operations","page":"Table Operations","title":"Chaining Operations","text":"While Julia doesn't have a built-in pipe operator for data manipulation (like R's %>% or |>), you can chain operations by nesting function calls or using intermediate variables:\n\nusing Durbyn.TableOps\nusing Statistics\n\ntbl = (department = [\"Sales\", \"IT\", \"Sales\", \"IT\", \"Sales\", \"HR\", \"HR\"],\n       employee = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\", \"Grace\"],\n       salary = [60000, 70000, 55000, 75000, 65000, 50000, 52000],\n       years = [5, 8, 3, 10, 6, 2, 4])\n\n# Method 1: Nested functions\nresult = arrange(\n    summarise(\n        groupby(\n            query(tbl, row -> row.salary > 52000),\n            :department),\n        avg_salary = :salary => mean,\n        avg_years = :years => mean,\n        count = data -> length(data.salary)),\n    :avg_salary => :desc)\n\nglimpse(result)\n\n# Method 2: Step by step with intermediate variables (recommended for readability)\nfiltered = query(tbl, row -> row.salary > 52000)\ngrouped = groupby(filtered, :department)\nsummarized = summarise(grouped,\n    avg_salary = :salary => mean,\n    avg_years = :years => mean,\n    count = data -> length(data.salary))\nresult = arrange(summarized, :avg_salary => :desc)\n\nglimpse(result)","category":"section"},{"location":"tableops/#Working-with-GroupedTable","page":"Table Operations","title":"Working with GroupedTable","text":"The GroupedTable type is a central concept in TableOps, similar to grouped data frames in other languages.\n\nusing Durbyn.TableOps\nusing Statistics\n\nsales_data = (\n    region = [\"North\", \"South\", \"North\", \"South\", \"East\", \"East\", \"West\"],\n    product = [\"A\", \"A\", \"B\", \"B\", \"A\", \"B\", \"A\"],\n    revenue = [1000, 1500, 2000, 2500, 1800, 2200, 1200],\n    units = [100, 150, 200, 250, 180, 220, 120]\n)\n\n# Group by multiple columns\ngt = groupby(sales_data, :region, :product)\nglimpse(gt)\n\n# Compute complex summaries\nsummary = summarise(gt,\n    total_revenue = :revenue => sum,\n    total_units = :units => sum,\n    avg_price = data -> sum(data.revenue) / sum(data.units),\n    count = data -> length(data.revenue))\n\nglimpse(summary)","category":"section"},{"location":"tableops/#Tips-and-Best-Practices","page":"Table Operations","title":"Tips and Best Practices","text":"Use glimpse frequently: It's a quick way to understand your data's structure and verify transformations.\nPredicate functions in query: Keep them simple and readable. For complex filters, break them into logical parts.\nType stability in mutate: Ensure your computed columns have consistent types across all rows.\nGroup before summarize: Always create a GroupedTable with groupby before using summarise.\nColumn naming: Use descriptive names in mutate and summarise to make your data self-documenting.\nPivot operations:\nUse pivot_longer when you need to reshape data for modeling or plotting\nUse pivot_wider when you need to create summary tables or compare values across categories\nMemory efficiency: TableOps functions return new NamedTuples, so be mindful of memory when working with very large datasets.","category":"section"},{"location":"tableops/#Function-Reference","page":"Table Operations","title":"Function Reference","text":"Core functions provided by TableOps:\n\nselect — Select specific columns\nquery — Filter rows based on conditions\narrange — Sort rows by column values\ngroupby — Group data by column values\nmutate — Add or transform columns\nsummarise / summarize — Aggregate grouped data\npivot_longer — Reshape from wide to long format\npivot_wider — Reshape from long to wide format\nglimpse — Quick data preview with types and samples\n\nAll functions are documented above with examples.","category":"section"},{"location":"quickstart/#Quick-Start","page":"Quick Start","title":"Quick Start","text":"","category":"section"},{"location":"quickstart/#Installation","page":"Quick Start","title":"Installation","text":"Install the development version:\n\nusing Pkg\nPkg.add(url=\"https://github.com/taf-society/Durbyn.jl\")","category":"section"},{"location":"quickstart/#Formula-Interface-(Recommended)","page":"Quick Start","title":"Formula Interface (Recommended)","text":"Durbyn provides a modern, declarative interface for model specification with full support for tables, regressors (features in ML terminology), model comparison, and panel data.","category":"section"},{"location":"quickstart/#Example-1:-Single-Time-Series","page":"Quick Start","title":"Example 1: Single Time Series","text":"using Durbyn\n\n# Load data\ndata = (sales = [120, 135, 148, 152, 141, 158, 170, 165, 180, 195],)\n\n# ARIMA with automatic order selection\nspec = ArimaSpec(@formula(sales = p() + q() + P() + Q()))\nfitted = fit(spec, data, m = 12)\nfc = forecast(fitted, h = 12)\nplot(fc)\n\n\n# Load data another data\ndata = (passengers = air_passengers(),)\n\n# ARIMA with automatic order selection\nspec = ArimaSpec(@formula(passengers = p() + q() + P() + Q()))\nfitted = fit(spec, data, m = 12)\nfc = forecast(fitted, h = 12)\nplot(fc)\n","category":"section"},{"location":"quickstart/#Example-2:-With-Regressors-(Features)","page":"Quick Start","title":"Example 2: With Regressors (Features)","text":"using Durbyn\nusing Random\nRandom.seed!(123)\n\n# Simulate data \nn = 120\nidx = 1:n\ntemperature = -(15 .+ 8 .* sin.(2π .* idx ./ 12) .+ 0.5 .* randn(n))\nmarketing = -(0.3 .+ 0.15 .* sin.(2π .* idx ./ 6) .+ 0.05 .* randn(n))\nsales = 120 .+ 1.5 .* temperature .+ 30 .* marketing .+ randn(n)\ndata = (sales = sales, temperature = temperature, marketing = marketing)\n\nspec = ArimaSpec(@formula(sales = temperature + marketing + p() + d() + q() + P() + D() + Q()))\n# spec = ArimaSpec(@formula(sales = auto()))\nfitted = fit(spec, data, m = 12)\n\n# Simulate future data\nn_ahead = 24\nfuture_idx = (n + 1):(n + n_ahead)\nfuture_temp = -(15 .+ 8 .* sin.(2π .* future_idx ./ 12))\nfuture_marketing = -(0.3 .+ 0.15 .* sin.(2π .* future_idx ./ 6))\nnewdata = (temperature = future_temp, marketing = future_marketing)\n\n\nfc = forecast(fitted, h = n_ahead, newdata = newdata)\n\nplot(fc)\n","category":"section"},{"location":"quickstart/#Example-3:-Fitting-Multiple-Models-Together","page":"Quick Start","title":"Example 3: Fitting Multiple Models Together","text":"# Fit multiple model specifications at once\nmodels = model(\n    ArimaSpec(@formula(sales = p() + q())),\n    EtsSpec(@formula(sales = e(\"A\") + t(\"A\") + s(\"A\"))),\n    ArimaSpec(@formula(sales = p(2) + d(1) + q(2))),\n    names = [\"auto_arima\", \"ets_aaa\", \"arima_212\"]\n)\n\n# Fit all models\nfitted = fit(models, data, m = 12)\n\n# Forecast with all models\nfc = forecast(fitted, h = 12)\n\n# Compare results\nfor (name, model_result) in zip(models.names, fitted.models)\n    println(\"$name: AIC = $(round(model_result.fit.aic, digits=2)), BIC = $(round(model_result.fit.bic, digits=2))\")\nend","category":"section"},{"location":"quickstart/#Example-4:-Panel-Data-(Multiple-Series)","page":"Quick Start","title":"Example 4: Panel Data (Multiple Series)","text":"note: Optional Dependencies\nThis example requires CSV and Downloads:using Pkg\nPkg.add([\"CSV\", \"Downloads\"])\n\nusing Durbyn, Durbyn.TableOps\nusing CSV, Downloads, Tables\n\n# Load and reshape data\npath = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\nwide = Tables.columntable(CSV.File(path))\n\nlong = pivot_longer(wide; id_cols = :date, names_to = :series, values_to = :value)\npanel = PanelData(long; groupby = :series, date = :date, m = 12)\nglimpse(panel)\n# Fit model to all series at once\nspec = ArimaSpec(@formula(value = p() + q()))\nfitted = fit(spec, panel)\n\n# Forecast all series\nfc = forecast(fitted, h = 12)\n\n# Get tidy forecast table\ntbl = forecast_table(fc)\nglimpse(tbl)","category":"section"},{"location":"quickstart/#Example-5:-ETS-Models-with-Formula","page":"Quick Start","title":"Example 5: ETS Models with Formula","text":"\nusing Durbyn.Grammar\n\n# Automatic ETS model selection\nspec_ets = EtsSpec(@formula(sales = e(\"Z\") + t(\"Z\") + s(\"Z\")))\nfitted = fit(spec_ets, data, m = 12)\nfc = forecast(fitted, h = 12)\nplot(fc)\n# Specialized ETS specifications\nspec_ses = SesSpec(@formula(sales = ses()))\nspec_holt = HoltSpec(@formula(sales = holt(damped=true)))\nspec_hw = HoltWintersSpec(@formula(sales = hw(seasonal=:multiplicative)))\n\n# Fit and forecast\nfitted_ses = fit(spec_ses, data)\nfc_ses = forecast(fitted_ses, h = 12)\n\nplot(fc_ses)\n\n\n","category":"section"},{"location":"quickstart/#Base-Models-(Array-Interface)","page":"Quick Start","title":"Base Models (Array Interface)","text":"The array interface provides direct access to forecasting engines for working with numeric vectors.","category":"section"},{"location":"quickstart/#Exponential-Smoothing-(ETS)","page":"Quick Start","title":"Exponential Smoothing (ETS)","text":"using Durbyn\nusing Durbyn.ExponentialSmoothing\n\nap = air_passengers()\n\n# Automatic ETS model selection\nfit_ets = ets(ap, 12, \"ZZZ\")\nfc_ets  = forecast(fit_ets, h = 12)\nplot(fc_ets)\n\n# Simple exponential smoothing\nses_fit = ses(ap)\nses_fc  = forecast(ses_fit, h = 12)\nplot(ses_fc)\n\n# Holt's linear trend method\nholt_fit = holt(ap)\nholt_fc  = forecast(holt_fit, h = 12)\nplot(holt_fc)\n\n# Holt-Winters seasonal method\nhw_fit = holt_winters(ap, 12)\nhw_fc  = forecast(hw_fit, h = 12)\nplot(hw_fc)","category":"section"},{"location":"quickstart/#ARIMA","page":"Quick Start","title":"ARIMA","text":"using Durbyn.Arima\n\nap = air_passengers()\n\n# Manual ARIMA specification\narima_model = arima(ap, 12, order = PDQ(2,1,1), seasonal = PDQ(0,1,0))\nfc  = forecast(arima_model, h = 12)\nplot(fc)\n\n# Automatic ARIMA selection\nauto_arima_model = auto_arima(ap, 12)\nfc_auto  = forecast(auto_arima_model, h = 12)\nplot(fc_auto)\n\n","category":"section"},{"location":"quickstart/#Performance:-Multi-Threading-for-Parallel-Computing","page":"Quick Start","title":"Performance: Multi-Threading for Parallel Computing","text":"Durbyn's fit function automatically leverages Julia's multi-threading for massive parallel computing when fitting models to panel data (multiple time series) or comparing multiple model specifications. Performance scales nearly linearly with CPU cores—from laptops to large cloud instances with 96+ cores.","category":"section"},{"location":"quickstart/#When-Does-Multi-Threading-Help?","page":"Quick Start","title":"When Does Multi-Threading Help?","text":"Multi-threading provides dramatic performance improvements when:\n\nFitting models to panel data with many series (e.g., 40+ series)\nComparing multiple models across series simultaneously\nRunning ensemble methods or model selection procedures\n\nExample: Without multi-threading (1 thread)\n\nFitting 6 models to 42 series = 252 individual fits\nTime: ~5-10 minutes (sequential processing)\n\nWith multi-threading\n\nSame 252 fits processed in parallel\n8 cores (laptop): ~60-90 seconds (5-8x faster)\n16 cores (workstation): ~30-45 seconds (10-15x faster)\n32+ cores (cloud): ~15-30 seconds (15-20x faster)","category":"section"},{"location":"quickstart/#How-to-Enable-Multi-Threading","page":"Quick Start","title":"How to Enable Multi-Threading","text":"Julia must be started with multiple threads to enable parallel processing. Here are all the methods:","category":"section"},{"location":"quickstart/#Method-1:-VS-Code-Julia-Extension-Settings-(Recommended-for-VS-Code-Users)","page":"Quick Start","title":"Method 1: VS Code Julia Extension Settings (Recommended for VS Code Users)","text":"Add to your VS Code settings.json (File → Preferences → Settings → Open Settings JSON):\n\n{\n    \"julia.additionalArgs\": [\n        \"-t\",\n        \"auto\"\n    ]\n}\n\nOptions:\n\n\"auto\" — Use all available CPU cores (recommended)\nSpecific number (e.g., \"8\", \"12\") — Limit threads if you want to reserve cores for other tasks\n\nTo apply:\n\nSave settings.json\nRestart Julia REPL in VS Code (click trash icon in Julia REPL, then restart)\nVerify with Threads.nthreads()","category":"section"},{"location":"quickstart/#Method-2:-Command-Line","page":"Quick Start","title":"Method 2: Command Line","text":"# Use all available cores (recommended)\njulia -t auto\n\n# Use specific number of threads (e.g., 8 threads)\njulia -t 8\n\n# Alternative syntax\njulia --threads=auto","category":"section"},{"location":"quickstart/#Method-3:-Environment-Variable-(Persistent)","page":"Quick Start","title":"Method 3: Environment Variable (Persistent)","text":"Set once and applies to all Julia sessions.\n\nLinux/macOS — Add to ~/.bashrc, ~/.zshrc, or ~/.profile:\n\nexport JULIA_NUM_THREADS=auto\n\nWindows (PowerShell) — Add to PowerShell profile:\n\n$env:JULIA_NUM_THREADS = \"auto\"\n\nWindows (System Environment Variables):\n\nSearch \"Environment Variables\" in Windows\nAdd new system variable: JULIA_NUM_THREADS = auto\n\nAfter setting, restart terminal/IDE for changes to take effect.","category":"section"},{"location":"quickstart/#Method-4:-Julia-Startup-File","page":"Quick Start","title":"Method 4: Julia Startup File","text":"Create/edit ~/.julia/config/startup.jl (Linux/macOS) or %USERPROFILE%\\.julia\\config\\startup.jl (Windows):\n\n# Set before Julia starts - less reliable, use environment variable instead\nENV[\"JULIA_NUM_THREADS\"] = \"auto\"\n\nNote: This method is less reliable. Prefer environment variable or command-line methods.","category":"section"},{"location":"quickstart/#Verifying-Multi-Threading-Is-Active","page":"Quick Start","title":"Verifying Multi-Threading Is Active","text":"julia> Threads.nthreads()\n8  # Number of threads available (depends on your CPU and settings)\n\njulia> Threads.threadpoolsize()\n8  # Confirms thread pool size","category":"section"},{"location":"quickstart/#Real-World-Example:-Panel-Data-Model-Comparison","page":"Quick Start","title":"Real-World Example: Panel Data Model Comparison","text":"Here's how multi-threading accelerates fitting multiple models to panel data:\n\nusing Durbyn, Durbyn.TableOps, Durbyn.Grammar\nusing CSV, Downloads, Tables\n\n# Load panel data (42 retail series)\npath = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\nwide = Tables.columntable(CSV.File(path))\nlong = pivot_longer(wide; id_cols=:date, names_to=:series, values_to=:value)\npanel = PanelData(long; groupby=:series, date=:date, m=12)\n\n# Define multiple models for comparison\nmodels = model(\n    ArarSpec(@formula(value = arar())),                                # ARAR\n    ArimaSpec(@formula(value = p() + q())),                              # Auto ARIMA\n    EtsSpec(@formula(value = e(\"Z\") + t(\"Z\") + s(\"Z\") + drift(:auto))),  # Auto ETS with drift\n    SesSpec(@formula(value = ses())),                                    # Simple exponential smoothing\n    HoltSpec(@formula(value = holt(damped=true))),                       # Damped Holt\n    HoltWintersSpec(@formula(value = hw(seasonal=:multiplicative))),     # Holt-Winters multiplicative\n    CrostonSpec(@formula(value = croston())),                            # Croston's method\n    names=[\"arar\", \"arima\", \"ets_auto\", \"ses\", \"holt_damped\", \"hw_mul\", \"croston\"]\n)\n\n# Fit all models to all series IN PARALLEL\n# Automatically uses available threads - no code changes needed!\nfitted = fit(models, panel)\n# Performance scales with cores:\n#   1 thread:    ~400-500 seconds (baseline)\n#   8 threads:   ~60-90 seconds (laptop/desktop)\n#   16 threads:  ~30-45 seconds (workstation)\n#   32+ threads: ~15-30 seconds (cloud/HPC)\n\n# Generate forecasts (also parallelized)\nfc = forecast(fitted, h=12)\n\n# Convert to tidy table format\nfc_tbl = forecast_table(fc)\nglimpse(fc_tbl)\n\nWhat's happening under the hood:\n\n42 series × 7 models = 294 model fits\nWith multiple threads: Fits are distributed across available cores\nEach thread handles a series/model combination independently\nNo code changes needed — parallelization is automatic!","category":"section"},{"location":"quickstart/#Troubleshooting","page":"Quick Start","title":"Troubleshooting","text":"Problem: Threads.nthreads() returns 1\n\nSolution: Julia was started without -t flag. Restart Julia with multi-threading enabled.\n\nProblem: VS Code settings not working\n\nSolution: Fully restart VS Code (not just Julia REPL). Settings only apply on fresh start.\n\nProblem: Performance not improving\n\nSolution: Check you have enough series/models. Small datasets (< 10 series) may not show speedup due to threading overhead.","category":"section"},{"location":"quickstart/#Recommended-Settings","page":"Quick Start","title":"Recommended Settings","text":"Development/Interactive: julia -t auto or VS Code settings with \"auto\"\nProduction/Scripts: export JULIA_NUM_THREADS=auto in environment\nCloud/HPC Systems: julia -t auto to leverage all available cores (e.g., 32, 64, 128+ threads)\nShared Systems: Use specific number (e.g., -t 8) to avoid consuming all resources and leave cores for other users\n\n","category":"section"},{"location":"quickstart/#Next-Steps","page":"Quick Start","title":"Next Steps","text":"tip: Complete End-to-End Example\nWant to see a comprehensive workflow with train/test split, model comparison, accuracy evaluation, and visualization? Check out the Complete End-to-End Example in Grammar Guide — demonstrates fitting 6 models to panel data with full evaluation pipeline.\n\nDocumentation:\n\nGrammar Guide — Complete formula interface documentation for ARIMA and ETS\nTable Operations — Data wrangling for time series and panel data\nARIMA — Formula interface and base models (ARIMA, SARIMA, Auto ARIMA)\nExponential Smoothing — Formula interface and base models (SES, Holt, Holt-Winters, ETS)\nIntermittent Demand — Croston methods for sparse/intermittent data\nARAR/ARARMA — Memory-shortening algorithms","category":"section"},{"location":"bats/#BATS:-Box-Cox,-ARMA-errors,-Trend,-Seasonal-Models","page":"BATS","title":"BATS: Box-Cox, ARMA errors, Trend, Seasonal Models","text":"The BATS framework extends exponential smoothing to accommodate multiple, possibly long seasonal cycles together with Box–Cox variance stabilization and ARMA error correction. It was introduced by De Livera, Hyndman & Snyder (2011) as part of the innovation-state-space family and is the method implemented by Durbyn’s [bats] function.\n\nThis page summarizes the core equations, highlights limitations (and why TBATS was proposed in the paper), and shows how to use the Julia interface.\n\n","category":"section"},{"location":"bats/#1.-Box–Cox-transformation","page":"BATS","title":"1. Box–Cox transformation","text":"Each BATS model may apply a Box–Cox transformation to the observed series, which stabilizes variance prior to modeling:\n\ny_t^(omega) =\nbegincases\ndfracy_t^omega - 1omega  omega neq 0 \nln y_t  omega = 0 \nendcases\n\nThe parameter omega (often denoted lambda in code) is estimated within the automated model search when the user permits Box–Cox transforms.\n\n","category":"section"},{"location":"bats/#2.-BATS-state-space-formulation","page":"BATS","title":"2. BATS state-space formulation","text":"After optional transformation, BATS is written in innovations form with an ARMA error process.","category":"section"},{"location":"bats/#Observation-equation","page":"BATS","title":"Observation equation","text":"y_t^(omega) = ell_t-1 + phi b_t-1 + sum_i s_it-1 + d_t\n\nwhere ell_t is the level, b_t the trend, phi the damping parameter, s_it the seasonal state for seasonal period m_i, and d_t the ARMA error term.","category":"section"},{"location":"bats/#State-equations","page":"BATS","title":"State equations","text":"Level and trend:\n\nell_t = ell_t-1 + phi b_t-1 + alpha d_t qquad\nb_t = phi b_t-1 + beta d_t\n\nAdditive seasonality for each seasonal block i (normalized form):\n\ns_it = -sum_j=1^m_i-1 s_it-j + gamma_i d_t","category":"section"},{"location":"bats/#ARMA-error-component","page":"BATS","title":"ARMA error component","text":"d_t = varepsilon_t + sum_k=1^p varphi_k varepsilon_t-k\n      + sum_ell=1^q theta_ell d_t-ell\nqquad varepsilon_t sim mathcalN(0 sigma^2)\n\nCombining these pieces yields the descriptor BATS(ω, {p,q}, φ, {m₁,…,m_J}) that Durbyn prints for each fitted model.\n\n","category":"section"},{"location":"bats/#3.-Limitations-and-relation-to-TBATS","page":"BATS","title":"3. Limitations and relation to TBATS","text":"In the original paper, TBATS was introduced to address several BATS limitations:\n\nSeasonal periods must be integers, and each requires storing m_i state components, which becomes expensive for very long cycles.\nNon-integer or dual-calendar seasonalities (e.g., Hijri and Gregorian) cannot be represented exactly.\n\nTBATS replaces the seasonal states with Fourier (trigonometric) terms to overcome those issues. TBATS is not yet implemented in Durbyn; the current bats function corresponds strictly to the BATS formulation above.\n\nnote: TBATS documentation will follow\nOnce TBATS is implemented, it will live on its own documentation page paralleling this guide so each innovation-state-space variant remains easy to reference independently.\n\n","category":"section"},{"location":"bats/#4.-Usage-in-Durbyn","page":"BATS","title":"4. Usage in Durbyn","text":"","category":"section"},{"location":"bats/#Basic-example","page":"BATS","title":"Basic example","text":"using Durbyn\n\n# Hourly demand with weekly (24*7) and yearly (24*365) seasonality\nm = [168, 8760]\nfit = bats(load, m; use_box_cox = true, use_arma_errors = true)\n\nprintln(string(fit))\nfc = forecast(fit; h = 168)","category":"section"},{"location":"bats/#Key-keyword-arguments","page":"BATS","title":"Key keyword arguments","text":"use_box_cox, use_trend, use_damped_trend: Bool, Vector{Bool}, or nothing to try both options; the best combination is chosen using AIC.\nuse_arma_errors: toggles fitting an ARMA(p, q) model to the residuals via [auto_arima]; if the selected ARMA orders are zero, the pure exponential-smoothing state-space model is retained.\nbc_lower, bc_upper: bounds for the Box–Cox search when enabled.\nbiasadj: apply bias correction during inverse Box–Cox transformation.\nmodel: pass a previous BATSModel to refit the same structure to new data without re-running the full model selection process.\n\nThe convenience method bats(y, m::Int; kwargs...) simply wraps the vector interface ([m]), making single-season calls ergonomic.\n\n","category":"section"},{"location":"bats/#5.-Reference","page":"BATS","title":"5. Reference","text":"De Livera, A.M., Hyndman, R.J., & Snyder, R.D. (2011). Forecasting time series with complex seasonal patterns using exponential smoothing. Journal of the American Statistical Association, 106(496), 1513–1527.","category":"section"},{"location":"arima/#Forecasting-Using-ARIMA,-SARIMA,-ARIMAX,-SARIMAX,-and-Auto-ARIMA","page":"ARIMA","title":"Forecasting Using ARIMA, SARIMA, ARIMAX, SARIMAX, and Auto ARIMA","text":"tip: Formula Interface is the Recommended Approach\nThis page starts with the formula interface (recommended for most users), which provides declarative model specification with support for regressors, panel data, and model comparison. The array interface (base models) is covered later. See the Grammar Guide for complete documentation.","category":"section"},{"location":"arima/#1.-ARIMA-(AutoRegressive-Integrated-Moving-Average)","page":"ARIMA","title":"1. ARIMA (AutoRegressive Integrated Moving Average)","text":"","category":"section"},{"location":"arima/#Definition","page":"ARIMA","title":"Definition","text":"An ARIMA model is denoted as ARIMA(p, d, q), where:\n\np: order of the autoregressive (AR) part\nd: degree of differencing needed to achieve stationarity\nq: order of the moving average (MA) part\n\nFormally, the model is written as:\n\nPhi(B) Delta^d X_t = Theta(B) varepsilon_t\n\nwhere:\n\nB is the backshift operator (BX_t = X_t-1),\nPhi(B) = 1 - phi_1B - cdots - phi_pB^p,\nTheta(B) = 1 + theta_1B + cdots + theta_qB^q,\nDelta^d = (1 - B)^d is the differencing operator,\nvarepsilon_t is white noise.\n\nIf d = 0, the model reduces to ARMA(p, q).","category":"section"},{"location":"arima/#Key-Features","page":"ARIMA","title":"Key Features","text":"Handles non-stationary time series via differencing.\nShocks (innovations) have permanent effects for d  0.\nCommonly used for macroeconomic and financial data.\n\n","category":"section"},{"location":"arima/#2.-SARIMA-(Seasonal-ARIMA)","page":"ARIMA","title":"2. SARIMA (Seasonal ARIMA)","text":"","category":"section"},{"location":"arima/#Definition-2","page":"ARIMA","title":"Definition","text":"Seasonal ARIMA extends ARIMA to account for seasonality. It is denoted as:\n\nARIMA(p d q)(P D Q)_m\n\nwhere:\n\nP D Q are the seasonal AR, differencing, and MA orders,\nm is the seasonal period (e.g., 12 for monthly data with yearly seasonality).","category":"section"},{"location":"arima/#Model-Form","page":"ARIMA","title":"Model Form","text":"Phi(B)Phi_s(B^m) Delta^d Delta_m^D X_t = Theta(B)Theta_s(B^m)varepsilon_t\n\nwhere:\n\nPhi_s(B^m) and Theta_s(B^m) capture seasonal AR and MA terms,\nDelta_m^D = (1 - B^m)^D applies seasonal differencing.","category":"section"},{"location":"arima/#Key-Features-2","page":"ARIMA","title":"Key Features","text":"Captures both short-term dynamics (p, d, q) and seasonal effects (P, D, Q).\nWidely applied to monthly or quarterly economic indicators, sales, or climate data.\n\n","category":"section"},{"location":"arima/#3.-ARIMAX-(ARIMA-with-Exogenous-Variables)","page":"ARIMA","title":"3. ARIMAX (ARIMA with Exogenous Variables)","text":"","category":"section"},{"location":"arima/#Definition-3","page":"ARIMA","title":"Definition","text":"An ARIMAX model incorporates external regressors (covariates) into the ARIMA framework:\n\nPhi(B) Delta^d X_t = beta Z_t + Theta(B) varepsilon_t\n\nwhere:\n\nZ_t is a vector of exogenous predictors,\nbeta are their coefficients.","category":"section"},{"location":"arima/#Key-Features-3","page":"ARIMA","title":"Key Features","text":"Useful when external factors (e.g., interest rates, marketing spend, policy variables) explain additional variance beyond past values of the series.\nRequires careful checking of exogeneity assumptions.\n\n","category":"section"},{"location":"arima/#4.-SARIMAX-(Seasonal-ARIMAX)","page":"ARIMA","title":"4. SARIMAX (Seasonal ARIMAX)","text":"","category":"section"},{"location":"arima/#Definition-4","page":"ARIMA","title":"Definition","text":"SARIMAX generalizes SARIMA by including exogenous regressors:\n\nPhi(B)Phi_s(B^m) Delta^d Delta_m^D X_t = beta Z_t + Theta(B)Theta_s(B^m)varepsilon_t","category":"section"},{"location":"arima/#Key-Features-4","page":"ARIMA","title":"Key Features","text":"Combines seasonality and exogenous influences.\nPowerful for real-world applications such as:\nForecasting retail sales with promotions (exogenous variable) and seasonal cycles.\nModeling energy demand with weather as an exogenous driver.\n\n","category":"section"},{"location":"arima/#5.-Auto-ARIMA","page":"ARIMA","title":"5. Auto ARIMA","text":"","category":"section"},{"location":"arima/#Definition-5","page":"ARIMA","title":"Definition","text":"Auto ARIMA automates the process of identifying the best ARIMA/SARIMA model by searching across possible values of (p, d, q) and seasonal (P, D, Q), selecting the model that minimizes an information criterion such as AIC, AICc, or BIC.","category":"section"},{"location":"arima/#Algorithm-(Hyndman-and-Khandakar,-2008)","page":"ARIMA","title":"Algorithm (Hyndman & Khandakar, 2008)","text":"Unit root tests (ADF, KPSS, or combinations) to determine differencing orders ( d ) and ( D ).\nInitial model selection based on heuristics.  \nStepwise search over (p, q, P, Q) with bounds (e.g., up to 5 for non-seasonal and 2 for seasonal).  \nEvaluate models by likelihood and information criteria.  \nRefit the best model with full maximum likelihood.  ","category":"section"},{"location":"arima/#Advantages","page":"ARIMA","title":"Advantages","text":"Removes the manual effort of model identification.  \nScales well to large numbers of series.  \nEnsures differencing is tested systematically (avoids over-differencing).","category":"section"},{"location":"arima/#Limitations","page":"ARIMA","title":"Limitations","text":"Stepwise search may not find the global optimum.  \nComputationally expensive for very large seasonal periods.  \nStill requires diagnostic checking of residuals.  \n\n","category":"section"},{"location":"arima/#6.-Model-Selection-and-Diagnostics","page":"ARIMA","title":"6. Model Selection & Diagnostics","text":"","category":"section"},{"location":"arima/#Identification","page":"ARIMA","title":"Identification","text":"Use ACF/PACF plots and unit root tests (ADF, PP, KPSS) to choose orders manually (or confirm Auto ARIMA results).\nDifferencing ensures stationarity (d D).","category":"section"},{"location":"arima/#Estimation","page":"ARIMA","title":"Estimation","text":"Maximum Likelihood Estimation (MLE) or Conditional Sum of Squares.","category":"section"},{"location":"arima/#Diagnostics","page":"ARIMA","title":"Diagnostics","text":"Residual analysis: check for white noise.\nInformation criteria: AIC, BIC, AICc.  \nOut-of-sample forecast validation.\n\n","category":"section"},{"location":"arima/#Formula-Interface-(Primary-Usage)","page":"ARIMA","title":"Formula Interface (Primary Usage)","text":"The formula interface provides a modern, declarative way to specify ARIMA models with full support for single series, regressors, model comparison, and panel data.","category":"section"},{"location":"arima/#Example-1:-Single-ARIMA-Model","page":"ARIMA","title":"Example 1: Single ARIMA Model","text":"using Durbyn\n\n# Load data\ndata = (sales = [120, 135, 148, 152, 141, 158, 170, 165, 180, 195],)\n\n# Specify model with automatic order selection\nspec = ArimaSpec(@formula(sales = p() + q() + P() + Q() + d() + D()))\nfitted_model = fit(spec, data, m = 12)\nfc = forecast(fitted_model, h = 12)\n\n# Check model summary\nprintln(fitted_model)\n\n# Access fitted values and residuals\nfitted_values = fitted(fitted_model)\nresids = residuals(fitted_model)\n\nKey features:\n\np(), q(), P(), Q(), d() and D() with no arguments triggers automatic order selection\nm = 12 specifies monthly seasonality\nFormula syntax clearly shows response variable (sales)","category":"section"},{"location":"arima/#Example-2:-ARIMA-with-Regressors","page":"ARIMA","title":"Example 2: ARIMA with Regressors","text":"When you have external variables that influence the response, include them as regressors:\n\n# Model with exogenous regressors\ndata = (\n    sales = rand(100),\n    temperature = rand(100),\n    promotion = rand(0:1, 100)\n)\n\n# Specify model with regressors\nspec = ArimaSpec(@formula(sales = p(1,3) + q(1,3) + temperature + promotion))\nfitted = fit(spec, data, m = 7)\n\n# Forecast requires future regressor values\nnewdata = (temperature = rand(7), promotion = rand(0:1, 7))\nfc = forecast(fitted, h = 7, newdata = newdata)\n\nTerminology:\n\nResponse variable: The variable being forecasted (sales)\nRegressors: External predictors (temperature, promotion)\n\nKey features:\n\np(1,3) starts searching for best AR order between 1 and 3\nRegressors are simply added to the formula\nFuture regressor values must be provided via newdata","category":"section"},{"location":"arima/#Example-3:-Manual-ARIMA-Specification","page":"ARIMA","title":"Example 3: Manual ARIMA Specification","text":"For full control over model orders:\n\n# Specify exact orders for SARIMA model\nspec = ArimaSpec(@formula(sales = p(2) + d(1) + q(1) + P(1) + D(1) + Q(1)))\nfitted = fit(spec, data, m = 12)\nfc = forecast(fitted, h = 12)\n\n# Or use specific values with regressors\nspec = ArimaSpec(@formula(sales = p(1) + d(1) + q(1) + temperature + promotion))\nfitted = fit(spec, data, m = 12)\n\nARIMA order specification:\n\np(k): AR order = k\nd(k): Differencing order = k\nq(k): MA order = k\nP(k): Seasonal AR order = k\nD(k): Seasonal differencing = k\nQ(k): Seasonal MA order = k","category":"section"},{"location":"arima/#Example-4:-Fitting-Multiple-Models-Together","page":"ARIMA","title":"Example 4: Fitting Multiple Models Together","text":"Fit different model specifications and manually compare results:\n\n# Define multiple candidate models\nmodels = model(\n    ArimaSpec(@formula(sales = p() + q())),                    # Auto ARIMA\n    ArimaSpec(@formula(sales = p(2) + d(1) + q(2))),          # ARIMA(2,1,2)\n    ArimaSpec(@formula(sales = p(1) + d(1) + q(1) + P(1) + D(1) + Q(1))),  # SARIMA\n    names = [\"auto_arima\", \"arima_212\", \"sarima_111_111\"]\n)\n\n# Fit all models\nfitted = fit(models, data, m = 12)\n\n# Forecast with all models\nfc = forecast(fitted, h = 12)\n\n# Check forecast accuracy\naccuracy(fc, test)\n\nKey features:\n\nFit multiple specifications at once\nMix different model types (ARIMA, ETS, etc.)\nCheck model accuracy\nForecasts generated for all models","category":"section"},{"location":"arima/#Example-5:-Panel-Data-(Multiple-Time-Series)","page":"ARIMA","title":"Example 5: Panel Data (Multiple Time Series)","text":"Fit the same model specification to many series efficiently:\n\nusing Durbyn.TableOps\nusing CSV, Downloads\n\n# Load panel data\npath = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\nwide = Tables.columntable(CSV.File(path))\n\n# Reshape to long format\nlong = pivot_longer(wide; id_cols = :date, names_to = :series, values_to = :value)\n\n# Create panel data wrapper\npanel = PanelData(long; groupby = :series, date = :date, m = 12)\n\n# Fit model to all series at once\nspec = ArimaSpec(@formula(value = p() + q()))\nfitted = fit(spec, panel)\n\n# Forecast all series\nfc = forecast(fitted, h = 12)\n\n# Get tidy forecast table\ntbl = forecast_table(fc)\n\n# Optional: Save forecasts to CSV\n# CSV.write(\"forecasts.csv\", tbl)\n\n# Calculate accuracy metrics\n# Method 1: Using ForecastModelCollection directly\nacc_results = accuracy(fc, test)\n\nprintln(\"\\nAccuracy by Series and Model:\")\nglimpse(acc_results)\n\nlist_series(fc)  # See what's available\nplot(fc)  # Quick look at first series\nplot(fc, series=:all, facet=true, n_cols=4)  # Overview\n\n# Detailed inspection\nplot(fc, series=\"series_1\", actual=test)\n\n# Calculate accuracy\nacc = accuracy(fc, test)\n\n# Find and plot interesting cases\nbest = acc.series[argmin(acc.MAPE)]\nworst = acc.series[argmax(acc.MAPE)]\n\nplot(fc, series=[best, worst], facet=true, actual=test)\n\n\nPanel data features:\n\nFits model separately to each group\nReturns structured output for all series\nforecast_table creates tidy format for analysis\nEfficient for hundreds or thousands of series","category":"section"},{"location":"arima/#Example-6:-Panel-Data-with-Grouping-Variables","page":"ARIMA","title":"Example 6: Panel Data with Grouping Variables","text":"For complex panel structures:\n\n\n# Use PanelData interface\npanel = PanelData(train; groupby=[:product, :location, :product_line], date=:date, m=7);\n\nspec = ArimaSpec(@formula(sales = p() + q()))\nfitted = fit(spec, panel)\nfc = forecast(fitted, h = 14)\n\n# Data with multiple grouping variables\nspec = ArimaSpec(@formula(sales = p() + q()))\nfitted = fit(spec, data,\n             groupby = [:product, :location, :product_line],\n             m = 7)\nfc = forecast(fitted, h = 7)\n\n# Filter forecasts for specific groups\ntbl = forecast_table(fc)\n\n\n","category":"section"},{"location":"arima/#Array-Interface-(Base-Models)","page":"ARIMA","title":"Array Interface (Base Models)","text":"The array interface provides direct access to ARIMA estimation for numeric vectors. This is useful for quick analyses or integration with existing code for example using Durbyn base models as backend for Python or R packages.","category":"section"},{"location":"arima/#Forecasting-Using-Seasonal-ARIMA-Model","page":"ARIMA","title":"Forecasting Using Seasonal ARIMA Model","text":"using Durbyn\nusing Durbyn.Arima\n\nap  = air_passengers()\narima_model = arima(ap, 12, order = PDQ(2,1,1), seasonal = PDQ(0,1,0))\nfc  = forecast(arima_model, h = 12)\nplot(fc)\n","category":"section"},{"location":"arima/#Forecasting-Using-Auto-ARIMA-Model","page":"ARIMA","title":"Forecasting Using Auto-ARIMA Model","text":"auto_arima_model = auto_arima(ap, 12)\nfc2  = forecast(auto_arima_model, h = 12)\nplot(fc2)","category":"section"},{"location":"arima/#References","page":"ARIMA","title":"References","text":"Kunst, R. (2011). Applied Time Series Analysis — Part II. University of Vienna.  \nHyndman, R.J., & Khandakar, Y. (2008). Automatic Time Series Forecasting: The forecast Package for R. Journal of Statistical Software, 27(3).  \nBox, G.E.P., Jenkins, G.M., & Reinsel, G.C. (1994). Time Series Analysis, Forecasting and Control.  \nHamilton, J.D. (1994). Time Series Analysis.  ","category":"section"},{"location":"#Durbyn.jl","page":"Home","title":"Durbyn.jl","text":"(Image: Durbyn.jl logo)\n\n(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage)\n\nDurbyn is a Julia package that implements functionality of the R forecast package, providing tools for time-series forecasting.\n\nDurbyn — Kurdish for “binoculars” (Dur, far + Byn, to see), embodies foresight through science. Like Hari Seldon’s psychohistory in Asimov’s Foundation, we seek to glimpse the shape of tomorrow through the disciplined clarity of mathematics.\n\nThis site documents the development version. After your first tagged release, see stable docs for the latest release.\n\n","category":"section"},{"location":"#About-TAFS","page":"Home","title":"About TAFS","text":"TAFS (Time Series Analysis and Forecasting Society) is a non-profit association (“Verein”) in Vienna, Austria. It connects academics, experts, practitioners, and students focused on time-series, forecasting, and decision science. Contributions remain fully open source.   Learn more at taf-society.org.\n\n","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"Durbyn is under active development. For the latest dev version:\n\nusing Pkg\nPkg.add(url=\"https://github.com/taf-society/Durbyn.jl\")\n\ntip: Performance: Multi-Threading\nDurbyn automatically uses parallel computing when fitting models to panel data. Start Julia with multiple threads for massive speedups that scale with your CPU cores:julia -t autoSee Performance Guide for all setup methods including VS Code configuration.\n\n","category":"section"},{"location":"#Formula-Interface-(Recommended)","page":"Home","title":"Formula Interface (Recommended)","text":"Durbyn provides a modern, declarative interface for model specification using @formula. This is the recommended approach for most users, supporting single series, model comparison, and panel data forecasting.\n\nnote: Optional Dependencies\nPanel data examples require CSV and Downloads packages:using Pkg\nPkg.add([\"CSV\", \"Downloads\"])","category":"section"},{"location":"#Complete-Workflow:-Model-Comparison-with-Panel-Data","page":"Home","title":"Complete Workflow: Model Comparison with Panel Data","text":"using Durbyn, Durbyn.TableOps, Durbyn.Grammar\nusing CSV, Downloads, Tables\n\n# 1. Load and prepare data\npath = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\nwide = Tables.columntable(CSV.File(path))\n\n# Reshape to long format\ntbl = pivot_longer(wide; id_cols=:date, names_to=:series, values_to=:value)\nglimpse(tbl)\n\n# 2. Split into train and test sets\nall_dates = unique(tbl.date)\nsplit_date = all_dates[end-11]  # Hold out last 12 periods for testing\n\ntrain = query(tbl, row -> row.date <= split_date)\ntest = query(tbl, row -> row.date > split_date)\n\nprintln(\"Training data:\")\nglimpse(train)\nprintln(\"\\nTest data:\")\nglimpse(test)\n\n# 3. Create panel data wrapper\npanel = PanelData(train; groupby=:series, date=:date, m=12)\nglimpse(panel)\n\n# 4. Define multiple models for comparison\nmodels = model(\n    ArarSpec(@formula(value = arar())),                                # ARAR\n    ArimaSpec(@formula(value = p() + q())),                              # Auto ARIMA\n    EtsSpec(@formula(value = e(\"Z\") + t(\"Z\") + s(\"Z\") + drift(:auto))),  # Auto ETS with drift\n    SesSpec(@formula(value = ses())),                                    # Simple exponential smoothing\n    HoltSpec(@formula(value = holt(damped=true))),                       # Damped Holt\n    HoltWintersSpec(@formula(value = hw(seasonal=:multiplicative))),     # Holt-Winters multiplicative\n    CrostonSpec(@formula(value = croston())),                            # Croston's method\n    names=[\"arar\", \"arima\", \"ets_auto\", \"ses\", \"holt_damped\", \"hw_mul\", \"croston\"]\n)\n\n# 5. Fit all models to all series\nfitted = fit(models, panel)\n\n# 6. Generate forecasts (h=12 to match test set)\nfc = forecast(fitted, h=12)\n\n# 7. Convert to tidy table format\nfc_tbl = forecast_table(fc)\nglimpse(fc_tbl)\n\n# 8. Calculate accuracy metrics across all models and series\nacc_results = accuracy(fc, test)\nprintln(\"\\nAccuracy by Series and Model:\")\nglimpse(acc_results)\n\n# 9. Visualization\nlist_series(fc)  # Show available series\n\n# Quick overview of all series for first model\nplot(fc, series=:all, facet=true, n_cols=4)\n\n# Detailed inspection with actual values from test set\nplot(fc, series=\"series_10\", actual=test)\n\n# 10. Find best and worst performing series\nbest_series = acc_results.series[argmin(acc_results.MAPE)]\nworst_series = acc_results.series[argmax(acc_results.MAPE)]\n\n# Compare best vs worst performers\nplot(fc, series=[best_series, worst_series], facet=true, actual=test)\n\nThis example demonstrates:\n\nData wrangling: Load, reshape, and split data using TableOps\nModel comparison: Fit 7 forecasting methods (ARAR, ARIMA, ETS variants, Croston)\nPanel forecasting: Automatic iteration over multiple time series\nOut-of-sample evaluation: Train/test split with accuracy metrics\nVisualization: Faceted plots, actual vs forecast comparison\nTidy output: Structured tables ready for further analysis","category":"section"},{"location":"#Quick-Examples","page":"Home","title":"Quick Examples","text":"","category":"section"},{"location":"#Single-Series-ARIMA","page":"Home","title":"Single Series ARIMA","text":"using Durbyn\n\ndata = (sales = [120, 135, 148, 152, 141, 158, 170, 165, 180, 195],)\n\nspec = ArimaSpec(@formula(sales = p() + q()))\nfitted = fit(spec, data, m = 12)\nfc = forecast(fitted, h = 12)","category":"section"},{"location":"#ARIMA-with-Regressors-(Features)","page":"Home","title":"ARIMA with Regressors (Features)","text":"data = (\n    sales = rand(100),\n    temperature = rand(100),\n    promotion = rand(0:1, 100)\n)\n\nspec = ArimaSpec(@formula(sales = p(1,3) + q(1,3) + temperature + promotion))\nfitted = fit(spec, data, m = 7)\n\n# Provide future values of regressors\nnewdata = (temperature = rand(7), promotion = rand(0:1, 7))\nfc = forecast(fitted, h = 7, newdata = newdata)","category":"section"},{"location":"#Automatic-ETS-Selection","page":"Home","title":"Automatic ETS Selection","text":"spec_ets = EtsSpec(@formula(sales = e(\"Z\") + t(\"Z\") + s(\"Z\")))\nfitted = fit(spec_ets, data, m = 12)\nfc = forecast(fitted, h = 12)\n\n","category":"section"},{"location":"#Base-Models-(Array-Interface)","page":"Home","title":"Base Models (Array Interface)","text":"using Durbyn\nusing Durbyn.ExponentialSmoothing\n\nap = air_passengers()\n\nfit_ets = ets(ap, 12, \"ZZZ\")\nfc_ets  = forecast(fit_ets, h = 12)\nplot(fc_ets)\n\nses_fit = ses(ap, 12)\nses_fc  = forecast(ses_fit, h = 12)\nplot(ses_fc)\n\nholt_fit = holt(ap, 12)\nholt_fc  = forecast(holt_fit, h = 12)\nplot(holt_fc)\n\nhw_fit = holt_winters(ap, 12)\nhw_fc  = forecast(hw_fit, h = 12)\nplot(hw_fc)\n\n","category":"section"},{"location":"#Intermittent-demand-(Croston-variants)","page":"Home","title":"Intermittent demand (Croston variants)","text":"data = [6, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0,\n0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, \n0, 0, 0, 0, 0];\n\n# Based on Shenstone & Hyndman (2005)\nm = 1\nfit_crst = croston(data, m)\nfc_crst  = forecast(fit_crst, 12)\nplot(fc_crst)\n\nusing Durbyn.IntermittentDemand\n\n# Classical Croston (Croston, 1972)\ncrst1 = croston_classic(data)\nfc1   = forecast(crst1, h = 12)\n\nresiduals(crst1); residuals(fc1);\nfitted(crst1);    fitted(fc1);\nplot(fc1, show_fitted = true)\n\n# Croston + SBA correction\ncrst2 = croston_sba(data)\nfc2   = forecast(crst2, h = 12)\nplot(fc2, show_fitted = true)\n\n# Croston + SBJ correction\ncrst3 = croston_sbj(data)\nfc3   = forecast(crst3, h = 12)\nplot(fc3, show_fitted = true)\n\n","category":"section"},{"location":"#ARIMA","page":"Home","title":"ARIMA","text":"using Durbyn.Arima\n\nap  = air_passengers()\n\n# manual ARIMA\narima_model = arima(ap, 12, order = PDQ(2,1,1), seasonal = PDQ(0,1,0))\nfc  = forecast(arima_model, h = 12)\n\n# auto ARIMA\nauto_arima_model = auto_arima(ap, 12, d = 1, D = 1)\nfc2  = forecast(auto_arima_model, h = 12)\nplot(fc2)\n\n","category":"section"},{"location":"#ARAR-/-ARARMA","page":"Home","title":"ARAR / ARARMA","text":"using Durbyn\nusing Durbyn.Ararma\n\nap = air_passengers()\n\narar_model_basic  = arar(ap, max_ar_depth = 13)\nfc   = forecast(arar_model_basic, h = 12)\nplot(fc)\n\nararma_model = ararma(ap, p = 0, q = 1)\nfc2  = forecast(ararma_model, h = 12)\nplot(fc2)\n\nauto_ararma_model = auto_ararma(ap)\nfc3  = forecast(auto_ararma_model, h = 12)\nplot(fc3)\n\n","category":"section"},{"location":"#License","page":"Home","title":"License","text":"MIT License.\n\n","category":"section"},{"location":"#What's-next","page":"Home","title":"What's next","text":"Grammar Guide (Recommended) — Learn the complete formula interface for ARIMA and ETS\nQuick Start — Get started quickly with formula and base models\nUser Guide pages:\nTable Operations — Data wrangling with Tables.jl for panel data\nARIMA — Formula interface and base models (ARIMA, SARIMA, Auto ARIMA)\nExponential Smoothing — Formula interface and base models (SES, Holt, Holt-Winters, ETS)\nIntermittent Demand — Croston methods\nARAR/ARARMA — Memory-shortening algorithms\nAPI Reference — Complete API documentation","category":"section"},{"location":"grammar/#Durbyn-Grammar","page":"Grammar","title":"Durbyn Grammar","text":"Durbyn provides an expressive, composable grammar for defining forecasting models. This unified interface lets you describe ARIMA, SARIMA, and exponential smoothing models with concise, readable syntax using the @formula macro and specialized model specifications.\n\nFuture releases will extend this grammar to support additional statistical models (state space models, structural time series, etc.) and machine learning forecasting methods, all accessible through the same consistent interface.\n\n","category":"section"},{"location":"grammar/#Overview","page":"Grammar","title":"Overview","text":"The Durbyn grammar system consists of:\n\nFormula interface: Use @formula to declaratively specify model components\nModel specifications: Wrap formulas in specs like ArimaSpec, EtsSpec, SesSpec, etc.\nUnified fitting: Call fit(spec, data) with optional grouping for panel data\nConsistent forecasting: Use forecast(fitted, h) for both single and grouped models; external variables can be passed if the model supports them\n\nThis design eliminates manual tuning loops and provides a consistent interface across all model families.\n\n","category":"section"},{"location":"grammar/#ARIMA-Grammar","page":"Grammar","title":"ARIMA Grammar","text":"The ARIMA grammar lets you describe ARIMA and SARIMA models with flexible order specifications and exogenous variable support.","category":"section"},{"location":"grammar/#Formula-Basics","page":"Grammar","title":"Formula Basics","text":"Define the relationship between a response variable (target in ML terminology) and its ARIMA structure:\n\n@formula(sales = p() + d() + q())\n\nEvery formula requires a response variable (left-hand side; called target in ML) and one or more model components (right-hand side). Components may specify ARIMA orders, seasonal orders, or regressors (exogenous variables; called features in ML).","category":"section"},{"location":"grammar/#Non-Seasonal-Orders","page":"Grammar","title":"Non-Seasonal Orders","text":"Function Meaning Default or form\np() Non-seasonal AR order Search range 2–5\np(k) Fix AR order Uses k exactly\np(min,max) Search AR order range Searches min through max\nd() Differencing order (auto) auto_arima chooses\nd(k) Fix differencing order Uses k exactly\nq() Non-seasonal MA order Search range 2–5\nq(k) Fix MA order Uses k exactly\nq(min,max) Search MA order range Searches min through max\n\nAny range (min,max) triggers full auto_arima search. If all orders are fixed, the formula interface automatically calls the faster arima routine.","category":"section"},{"location":"grammar/#Seasonal-Orders","page":"Grammar","title":"Seasonal Orders","text":"Seasonal counterparts include P, D, and Q:\n\n@formula(sales = p() + d() + q() + P() + Q())\n\nFunction Meaning Default or form\nP() Seasonal AR order Search range 1–2\nP(k) Fix seasonal AR order Uses k exactly\nP(min,max) Search seasonal AR order range Searches min through max\nD() Seasonal differencing (auto) auto_arima chooses\nD(k) Fix seasonal differencing order Uses k exactly\nQ() Seasonal MA order Search range 1–2\nQ(k) Fix seasonal MA order Uses k exactly\nQ(min,max) Search seasonal MA order range Searches min through max\n\nRemember to provide the seasonal period m when fitting: fit(spec, data, m=12).","category":"section"},{"location":"grammar/#Exogenous-Regressors","page":"Grammar","title":"Exogenous Regressors","text":"","category":"section"},{"location":"grammar/#Explicit-Variables","page":"Grammar","title":"Explicit Variables","text":"Add regressors (features) by listing column names:\n\n@formula(sales = p() + q() + price + promotion)\n\nThese become VarTerms—during fitting, Durbyn pulls the matching columns from your data.","category":"section"},{"location":"grammar/#Automatic-Selection-(auto())","page":"Grammar","title":"Automatic Selection (auto())","text":"Use auto() to include all numeric columns as regressors, excluding the response variable (target), group columns, and optional date column:\n\n@formula(sales = auto())                    # pure auto ARIMA + automatic xregs\n@formula(sales = p() + q() + auto())        # combine with explicit ARIMA orders\n\nAutomatic selection is mutually exclusive with explicit exogenous variables or xreg_formula.","category":"section"},{"location":"grammar/#Complex-Designs-(xreg_formula)","page":"Grammar","title":"Complex Designs (xreg_formula)","text":"For interactions or transformations, supply a secondary formula when constructing ArimaSpec:\n\nspec = ArimaSpec(\n    @formula(sales = p() + q()),\n    xreg_formula = Formula(\"~ temperature * promotion + price^2\")\n)\n\nThe xreg_formula is evaluated via Utils.model_matrix, producing the necessary design matrix before fitting.","category":"section"},{"location":"grammar/#ARIMA-Examples","page":"Grammar","title":"ARIMA Examples","text":"Fixed orders (fast estimation):\n\nspec = ArimaSpec(@formula(sales = p(1) + d(1) + q(1)))\nfitted = fit(spec, (sales = y,))\n\nAuto ARIMA with search ranges:\n\nspec = ArimaSpec(@formula(sales = p(0,3) + d() + q(0,3)))\nfitted = fit(spec, (sales = y,))\n\nSeasonal model with exogenous variables:\n\nspec = ArimaSpec(@formula(sales = p() + d() + q() + P() + Q() + price + promotion), m = 12)\nfitted = fit(spec, data; m = 12)\n\nPanel data with automatic xreg:\n\nspec = ArimaSpec(@formula(value = p() + d() + q() + P() + Q() + auto()))\npanel = PanelData(tbl; groupby = :store, date = :date, m = 12)\nfitted = fit(spec, panel)\nfc = forecast(fitted, h = 12)\n\n","category":"section"},{"location":"grammar/#ETS-Grammar","page":"Grammar","title":"ETS Grammar","text":"The ETS grammar mirrors the ARIMA DSL, letting you describe exponential smoothing models with expressive, composable terms.","category":"section"},{"location":"grammar/#Formula-Basics-2","page":"Grammar","title":"Formula Basics","text":"Use @formula to define the response variable (target) and its ETS components:\n\n@formula(sales = e(\"A\") + t(\"N\") + s(\"N\"))\n\nEach term is created with helper functions (e, t, s, drift). The resulting formula feeds into EtsSpec.","category":"section"},{"location":"grammar/#Component-Functions","page":"Grammar","title":"Component Functions","text":"Function Meaning Accepted Codes\ne() Error component \"A\" additive, \"M\" multiplicative, \"Z\" auto\nt() Trend component \"N\" none, \"A\" additive, \"M\" multiplicative, \"Z\" auto\ns() Seasonal component \"N\" none, \"A\" additive, \"M\" multiplicative, \"Z\" auto\n\nExamples:\n\ne(\"A\")              # Additive errors\nt(\"M\")              # Multiplicative trend\ns(\"Z\")              # Auto-select seasonal type\n\nAny component you omit defaults to \"Z\" (automatic selection). Combine the components as needed for your model structure.","category":"section"},{"location":"grammar/#Damping-and-Drift","page":"Grammar","title":"Damping and Drift","text":"Use drift() to control trend damping:\n\nCall Effect\ndrift() Force a damped trend (damped = true)\ndrift(false) Forbid damping (damped = false)\ndrift(:auto) Let ETS decide (damped = nothing)\ndrift(\"auto\") Same as drift(:auto)\n\nYou can combine drift with any trend choice. When omitted, the ETS search decides whether to include damping.","category":"section"},{"location":"grammar/#Creating-EtsSpec","page":"Grammar","title":"Creating EtsSpec","text":"Construct the specification with your formula and optional keywords (passed through to ets):\n\nspec = EtsSpec(\n    @formula(sales = e(\"Z\") + t(\"A\") + s(\"A\") + drift()),\n    m = 12,           # seasonal period\n    ic = \"aicc\"       # information criterion for model selection\n)\n\nfitted = fit(spec, (sales = sales_vec,); m = 12)\nfc = forecast(fitted, h = 12)\n\nYou can override spec options at fit time—keywords supplied to fit take precedence over those stored in the specification.","category":"section"},{"location":"grammar/#ETS-Quick-Recipes","page":"Grammar","title":"ETS Quick Recipes","text":"Simple Exponential Smoothing (SES):\n\nspec = EtsSpec(@formula(value = e(\"A\") + t(\"N\") + s(\"N\")))\nfitted = fit(spec, (value = y,))\n\nHolt's Linear Trend:\n\nspec = EtsSpec(@formula(value = e(\"A\") + t(\"A\") + s(\"N\") + drift(false)))\nfitted = fit(spec, (value = y,))\n\nHolt-Winters (Additive), monthly seasonality:\n\nspec = EtsSpec(@formula(value = e(\"A\") + t(\"A\") + s(\"A\") + drift(:auto)), m = 12)\nfitted = fit(spec, (value = y,), m = 12)\n\nAuto ETS with grouped data:\n\nspec = EtsSpec(@formula(value = e(\"Z\") + t(\"Z\") + s(\"Z\")))\nfitted = fit(spec, table; groupby = :store, m = 12)\nfc = forecast(fitted, h = 8)","category":"section"},{"location":"grammar/#Specialized-ETS-Shortcuts","page":"Grammar","title":"Specialized ETS Shortcuts","text":"You can also target specialized exponential smoothing families directly:\n\n# Simple Exponential Smoothing\nses_spec = SesSpec(@formula(value = ses()))\n\n# Holt's linear trend (damped trend forced on)\nholt_spec = HoltSpec(@formula(value = holt(damped=true)))\n\n# Holt-Winters with multiplicative seasonality\nhw_spec = HoltWintersSpec(@formula(value = hw(seasonal=\"multiplicative\")), m = 12)\n\n# Croston's intermittent-demand method\ncroston_spec = CrostonSpec(@formula(demand = croston()))\n\nThese specs share the same grouped/PanelData support as EtsSpec, and all options passed via the specification or fit keywords are forwarded to the underlying implementations.\n\n","category":"section"},{"location":"grammar/#Multi-Model-Fitting","page":"Grammar","title":"Multi-Model Fitting","text":"Use ModelCollection to fit multiple specifications simultaneously:\n\nusing Durbyn\nusing Durbyn.ModelSpecs\nusing Durbyn.Grammar\n\n# Long table with :series / :date / :value columns\npanel = PanelData(tbl; groupby = :series, date = :date, m = 12)\n\nmodels = model(\n    ArimaSpec(@formula(value = p() + q())),\n    EtsSpec(@formula(value = e(\"Z\") + t(\"Z\") + s(\"Z\") + drift(:auto))),\n    SesSpec(@formula(value = ses())),\n    HoltSpec(@formula(value = holt(damped=true))),\n    HoltWintersSpec(@formula(value = hw(seasonal=\"multiplicative\")); m = 12),\n    CrostonSpec(@formula(value = croston())),\n    names = [\"arima\", \"ets_auto\", \"ses\", \"holt_damped\", \"hw_mul\", \"croston\"]\n)\n\nfitted = fit(models, panel)       # each spec fitted to every series\nfc     = forecast(fitted, h = 12) # ForecastModelCollection\n\nforecast_table(fc)                # stacked tidy table with model_name column\n\nforecast_table stacks every model (and group) with a model_name column, so downstream comparisons stay tidy. You can filter to a specific model or pivot wider using Durbyn.TableOps functions, or use other Julia packages like DataFrames.jl, DataFramesMeta.jl, or Query.jl.\n\n","category":"section"},{"location":"grammar/#Complete-End-to-End-Example","page":"Grammar","title":"Complete End-to-End Example","text":"Here's a comprehensive workflow demonstrating model comparison, forecasting, and accuracy evaluation with panel data:\n\nnote: Optional Dependencies\nThis example requires CSV and Downloads packages:using Pkg\nPkg.add([\"CSV\", \"Downloads\"])\n\nusing Durbyn, Durbyn.TableOps, Durbyn.Grammar\nusing CSV, Downloads, Tables\n\n# 1. Load and prepare data\npath = Downloads.download(\"https://raw.githubusercontent.com/Akai01/example-time-series-datasets/refs/heads/main/Data/retail.csv\")\nwide = Tables.columntable(CSV.File(path))\n\n# Reshape to long format\ntbl = pivot_longer(wide; id_cols=:date, names_to=:series, values_to=:value)\nglimpse(tbl)\n\n# 2. Split into train and test sets\nall_dates = unique(tbl.date)\nsplit_date = all_dates[end-11]  # Hold out last 12 periods for testing\n\ntrain = query(tbl, row -> row.date <= split_date)\ntest = query(tbl, row -> row.date > split_date)\n\nprintln(\"Training data:\")\nglimpse(train)\nprintln(\"\\nTest data:\")\nglimpse(test)\n\n# 3. Create panel data wrapper\npanel = PanelData(train; groupby=:series, date=:date, m=12)\nglimpse(panel)\n\n# 4. Define multiple models for comparison\nmodels = model(\n    ArarSpec(@formula(value = arar())),                                # ARAR via grammar\n    ArimaSpec(@formula(value = p() + q())),                              # Auto ARIMA\n    EtsSpec(@formula(value = e(\"Z\") + t(\"Z\") + s(\"Z\") + drift(:auto))),  # Auto ETS with drift\n    SesSpec(@formula(value = ses())),                                    # Simple exponential smoothing\n    HoltSpec(@formula(value = holt(damped=true))),                       # Damped Holt\n    HoltWintersSpec(@formula(value = hw(seasonal=:multiplicative))),     # Holt-Winters multiplicative\n    CrostonSpec(@formula(value = croston())),                            # Croston's method\n    names=[\"arar\", \"arima\", \"ets_auto\", \"ses\", \"holt_damped\", \"hw_mul\", \"croston\"]\n)\n\n# 5. Fit all models to all series\nfitted = fit(models, panel)\n\n# 6. Generate forecasts (h=12 to match test set)\nfc = forecast(fitted, h=12)\n\n# 7. Convert to tidy table format\nfc_tbl = forecast_table(fc)\nglimpse(fc_tbl)\n\n# 8. Calculate accuracy metrics across all models and series\nacc_results = accuracy(fc, test)\nprintln(\"\\nAccuracy by Series and Model:\")\nglimpse(acc_results)\n\n# 9. Visualization\nlist_series(fc)  # Show available series\n\n# Quick overview of all series for first model\nplot(fc, series=:all, facet=true, n_cols=4)\n\n# Detailed inspection with actual values from test set\nplot(fc, series=\"series_10\", actual=test)\n\n# 10. Find best and worst performing series\n# Filter accuracy results for a specific metric (e.g., MAPE)\nbest_series = acc_results.series[argmin(acc_results.MAPE)]\nworst_series = acc_results.series[argmax(acc_results.MAPE)]\n\n# Compare best vs worst performers\nplot(fc, series=[best_series, worst_series], facet=true, actual=test)\n\nKey Features Demonstrated:\n\nData preparation: Download, reshape, and split data using TableOps\nModel comparison: Fit 7 different forecasting methods simultaneously (ARAR + classical methods)\nPanel forecasting: Automatic iteration over multiple time series\nTrain/test split: Proper out-of-sample evaluation\nAccuracy metrics: Compare model performance across series\nVisualization: Multiple plotting options for analysis\nTidy output: Structured forecast tables ready for downstream analysis\n\n","category":"section"},{"location":"grammar/#ARAR-Grammar","page":"Grammar","title":"ARAR Grammar","text":"The ARAR grammar exposes the arar() term so you can configure the adaptive-reduction model with the same declarative workflow as ARIMA and ETS.","category":"section"},{"location":"grammar/#Formula-term","page":"Grammar","title":"Formula term","text":"@formula(value = arar())                           # use defaults\n@formula(value = arar(max_ar_depth=20))            # custom depth\n@formula(value = arar(max_ar_depth=20, max_lag=40))\n\nBoth keywords are optional; if omitted, Durbyn derives appropriate values from the series length. Validation happens at macro-expansion time so mistakes are caught immediately.","category":"section"},{"location":"grammar/#Direct-formula-fitting","page":"Grammar","title":"Direct formula fitting","text":"using Durbyn\nusing Durbyn.Ararma\n\ndata = (value = air_passengers(),)\nformula = @formula(value = arar(max_lag=30))\narar_model = arar(formula, data)          # tables.jl compatible data\nfc  = forecast(arar_model; h = 12)\n\nThe estimator lives in the Durbyn.Ararma submodule, so call arar(formula, data) from there (either via using Durbyn.Ararma or Durbyn.Ararma.arar(...)). It works with any Tables.jl source and returns the familiar ARAR struct.","category":"section"},{"location":"grammar/#Model-specification-(ArarSpec)","page":"Grammar","title":"Model specification (ArarSpec)","text":"To leverage grouped fitting, forecasting, and model collections, wrap the formula in ArarSpec:\n\nspec = ArarSpec(@formula(value = arar(max_ar_depth=15)))\nfitted = fit(spec, data)\nfc = forecast(fitted; h = 8)\n\nFor panel data:\n\npanel = PanelData(tbl; groupby = :region)\ngroup_fit = fit(spec, panel)\ngroup_fc = forecast(group_fit; h = 6)\n\nAnd to compare against other specs:\n\nmodels = model(\n    ArarSpec(@formula(value = arar())),\n    ArimaSpec(@formula(value = p() + q())),\n    EtsSpec(@formula(value = e(\"Z\") + t(\"Z\") + s(\"Z\"))),\n    names = [\"arar\", \"arima\", \"ets\"]\n)\n\nfitted = fit(models, panel)\nfc = forecast(fitted; h = 12)\n\nThe ARAR grammar therefore integrates seamlessly with every Durbyn workflow—single series, grouped/panel data, and large-scale model comparisons.\n\n","category":"section"},{"location":"grammar/#ARARMA-Grammar","page":"Grammar","title":"ARARMA Grammar","text":"The ARARMA grammar extends the ARAR approach by fitting a short-memory ARMA(p,q) model after the adaptive reduction stage. Like ARIMA, it uses the p() and q() terms to specify model orders, but the distinction comes from using ArarmaSpec instead of ArimaSpec.","category":"section"},{"location":"grammar/#Formula-terms","page":"Grammar","title":"Formula terms","text":"ARARMA reuses ARIMA's order grammar:\n\n@formula(value = p() + q())                    # auto selection with defaults\n@formula(value = p(1) + q(2))                  # fixed ARARMA(1,2)\n@formula(value = p(0,3) + q(0,2))              # search ranges\n\nKey differences from ARIMA:\n\nARARMA does not support d(), D(), P(), or Q() terms (differencing is handled by the ARAR stage)\nARARMA does not support exogenous regressors (no variables, no auto())\nARARMA adds ARAR-specific parameters: max_ar_depth and max_lag","category":"section"},{"location":"grammar/#Automatic-vs-Fixed-Order-Selection","page":"Grammar","title":"Automatic vs Fixed Order Selection","text":"If ANY order is a range → uses auto_ararma():\n\np() + q() → searches with defaults (p: 0-4, q: 0-2)\np(0,3) + q() → searches p ∈ {0,1,2,3}, q with defaults\np(1) + q(0,2) → searches q ∈ {0,1,2} with fixed p=1\n\nIf ALL orders are fixed → uses ararma() directly (faster):\n\np(1) + q(2) → fits ARARMA(1,2) without search","category":"section"},{"location":"grammar/#Direct-formula-fitting-2","page":"Grammar","title":"Direct formula fitting","text":"using Durbyn\nusing Durbyn.Ararma\n\ndata = (value = air_passengers(),)\n\n# Fixed ARARMA(1,2)\nformula = @formula(value = p(1) + q(2))\nararma_model = ararma(formula, data)\nfc = forecast(ararma_model; h = 12)\n\n# Auto ARARMA with custom parameters\nformula = @formula(value = p() + q())\nararma_model = ararma(formula, data, max_ar_depth=20, max_lag=30, crit=:bic)\nfc = forecast(ararma_model; h = 12)\n\nThe estimator lives in the Durbyn.Ararma submodule. It works with any Tables.jl source and returns an ArarmaModel struct.","category":"section"},{"location":"grammar/#Model-specification-(ArarmaSpec)","page":"Grammar","title":"Model specification (ArarmaSpec)","text":"To leverage grouped fitting, forecasting, and model collections, wrap the formula in ArarmaSpec:\n\n# Fixed ARARMA(2,1)\nspec = ArarmaSpec(@formula(value = p(2) + q(1)))\nfitted = fit(spec, data)\nfc = forecast(fitted; h = 8)\n\n# Auto ARARMA with custom ARAR parameters\nspec = ArarmaSpec(\n    @formula(value = p() + q()),\n    max_ar_depth = 20,\n    max_lag = 30,\n    crit = :bic\n)\nfitted = fit(spec, data)\nfc = forecast(fitted; h = 12)\n\nFor panel data:\n\npanel = PanelData(tbl; groupby = :region, m = m)\nspec = ArarmaSpec(@formula(value = p(1) + q(1)))\ngroup_fit = fit(spec, panel)\ngroup_fc = forecast(group_fit; h = 6)\n\nAnd to compare against other specs:\n\nmodels = model(\n    ArarmaSpec(@formula(value = p() + q())),\n    ArarSpec(@formula(value = arar())),\n    ArimaSpec(@formula(value = p() + q() + P() + Q())),\n    EtsSpec(@formula(value = e(\"Z\") + t(\"Z\") + s(\"Z\"))),\n    names = [\"ararma\", \"arar\", \"arima\", \"ets\"]\n)\n\nfitted = fit(models, panel)\nfc = forecast(fitted; h = 12)\n\nThe ARARMA grammar therefore integrates seamlessly with every Durbyn workflow—single series, grouped/panel data, and large-scale model comparisons.\n\n","category":"section"},{"location":"grammar/#Croston-Grammar","page":"Grammar","title":"Croston Grammar","text":"The Croston grammar enables declarative specification of intermittent demand forecasting models through the same unified interface as ARIMA and ETS. Croston methods are designed for time series with many zero values and sporadic non-zero demands, common in spare parts inventory and slow-moving items.\n\nWhat is Intermittent Demand? Intermittent demand series exhibit:\n\nMany zero values (typically >50% zeros)\nSporadic, irregular non-zero demands\nUnpredictable timing between demand occurrences\n\nStandard forecasting methods (ARIMA, ETS) struggle with such data because they assume continuous patterns and cannot properly model the dual nature of intermittent demand: magnitude (how much) and timing (when).","category":"section"},{"location":"grammar/#Formula-Terms","page":"Grammar","title":"Formula Terms","text":"The croston() term supports multiple method variants and configuration options:\n\n# Default: Croston method (Shenstone & Hyndman 2005)\n@formula(demand = croston())\n\n# Syntetos-Boylan Approximation - RECOMMENDED (bias-corrected)\n@formula(demand = croston(method=\"sba\"))\n\n# Shale-Boylan-Johnston - Alternative bias correction\n@formula(demand = croston(method=\"sbj\"))\n\n# Classical Croston (1972) - Original method with modern optimization\n@formula(demand = croston(method=\"classic\"))\n\n# With custom optimization parameters (IntermittentDemand module)\n@formula(demand = croston(\n    method=\"sba\",\n    cost_metric=\"mar\",\n    number_of_params=2,\n    optimize_init=true\n))\n\nThe method parameter determines which algorithm to use, while additional parameters control optimization behavior for advanced methods.","category":"section"},{"location":"grammar/#Method-Variants","page":"Grammar","title":"Method Variants","text":"Four Croston method variants are available:\n\nMethod Description Module Best For Bias Correction\n\"sba\" ⭐ Syntetos-Boylan Approximation IntermittentDemand Default choice - bias-corrected, best accuracy 1 - α/2\n\"sbj\" Shale-Boylan-Johnston IntermittentDemand Alternative if SBA over-forecasts 1 - α/(2-α)\n\"classic\" Classical Croston (1972) IntermittentDemand Original method with modern optimization None (biased)\n\"hyndman\" Croston (Shenstone & Hyndman 2005) ExponentialSmoothing Standard implementation, fixed alpha None\n\nWhy Bias Correction Matters: The classical Croston method systematically over-forecasts due to Jensen's inequality when computing the ratio of smoothed demand to smoothed intervals. Both SBA and SBJ apply correction factors to reduce this bias, with empirical studies showing significant accuracy improvements.\n\nRecommendation: Start with method=\"sba\" - it's the most validated and generally performs best. Only consider SBJ if SBA shows consistent over-forecasting in your validation studies.","category":"section"},{"location":"grammar/#IntermittentDemand-Parameters","page":"Grammar","title":"IntermittentDemand Parameters","text":"When using \"classic\", \"sba\", or \"sbj\" methods, additional parameters control the optimization process (based on Kourentzes 2014 recommendations):\n\n@formula(demand = croston(\n    method = \"sba\",                  # Method variant\n    cost_metric = \"mar\",             # Loss function: \"mar\", \"msr\", \"mae\", \"mse\"\n    number_of_params = 2,            # 1 or 2 smoothing parameters\n    optimize_init = true,            # Optimize initial states\n    init_strategy = \"mean\",          # \"mean\" or \"naive\" initialization\n    rm_missing = false               # Remove missing values\n))\n\nParameter Details:\n\ncost_metric (default: \"mar\"): Optimization loss function\n\"mar\": Mean Absolute Rate error (recommended)\n\"msr\": Mean Squared Rate error (recommended)\n\"mae\": Mean Absolute Error (classical)\n\"mse\": Mean Squared Error (classical)\nnumber_of_params (default: 2): Number of smoothing parameters\n1: Single parameter for both demand size and intervals\n2: Separate parameters (recommended for better accuracy)\noptimize_init (default: true): Optimize initial state values\ntrue: Optimize starting values (recommended, especially for short series)\nfalse: Use heuristic initialization\ninit_strategy (default: \"mean\"): Initial value strategy\n\"mean\": Use mean of non-zero demands and intervals\n\"naive\": Use first observed values\nrm_missing (default: false): Handle missing values\ntrue: Remove missing observations\nfalse: Keep all observations\n\nNote: These parameters only apply to \"classic\", \"sba\", and \"sbj\" methods. They are ignored for method=\"hyndman\".","category":"section"},{"location":"grammar/#Direct-Formula-Fitting","page":"Grammar","title":"Direct Formula Fitting","text":"For single-series analysis, you can fit directly using the formula interface:\n\nusing Durbyn\n\n# Intermittent demand data (many zeros)\ndata = (demand = [6, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 3, 0],)\n\n# Recommended: Syntetos-Boylan Approximation (bias-corrected)\nspec = CrostonSpec(@formula(demand = croston(method=\"sba\")))\nfit_sba = fit(spec, data)\nfc_sba = forecast(fit_sba, h = 12)\nplot(fc_sba)\n\n# Alternative: Shale-Boylan-Johnston correction\nspec_sbj = CrostonSpec(@formula(demand = croston(method=\"sbj\")))\nfit_sbj = fit(spec_sbj, data)\nfc_sbj = forecast(fit_sbj, h = 12)\n\n# Classical Croston with custom optimization parameters\nspec_classic = CrostonSpec(@formula(demand = croston(\n    method = \"classic\",\n    cost_metric = \"msr\",        # Mean Squared Rate\n    number_of_params = 2,       # Separate smoothing parameters\n    optimize_init = true        # Optimize initial values\n)))\nfit_classic = fit(spec_classic, data)\nfc_classic = forecast(fit_classic, h = 12)\n\n# Compare methods\nprintln(\"SBA forecast:     \", mean(fc_sba.mean))\nprintln(\"SBJ forecast:     \", mean(fc_sbj.mean))\nprintln(\"Classic forecast: \", mean(fc_classic.mean))\n\nImplementation Details: CrostonSpec automatically routes to the appropriate estimator:\n\nmethod = \"hyndman\" → ExponentialSmoothing.croston (simple baseline)\nmethod = \"classic\", \"sba\", \"sbj\" → Durbyn.IntermittentDemand (advanced methods with optimization)\n\nNo additional modules need to be loaded beyond using Durbyn.","category":"section"},{"location":"grammar/#Panel-Data-and-Grouped-Fitting","page":"Grammar","title":"Panel Data and Grouped Fitting","text":"CrostonSpec integrates seamlessly with panel data for multi-product forecasting:\n\nusing Durbyn, CSV, Downloads, Tables\n\n# Load intermittent demand data with multiple products\n# Data should have columns: product_id, date, demand\npanel = PanelData(tbl; groupby = :product_id, date = :date)\n\n# Fit SBA to all products (automatically parallelized)\nspec = CrostonSpec(@formula(demand = croston(method=\"sba\")))\nfitted = fit(spec, panel)\n\n# Generate forecasts for all products\nfc = forecast(fitted, h = 12)\n\n# Convert to tidy table for analysis\nfc_table = forecast_table(fc)\nglimpse(fc_table)","category":"section"},{"location":"grammar/#Model-Comparison","page":"Grammar","title":"Model Comparison","text":"Compare Croston variants with other forecasting methods:\n\n# Define multiple models\nmodels = model(\n    CrostonSpec(@formula(demand = croston(method=\"sba\"))),\n    CrostonSpec(@formula(demand = croston(method=\"sbj\"))),\n    CrostonSpec(@formula(demand = croston(method=\"classic\"))),\n    SesSpec(@formula(demand = ses())),\n    EtsSpec(@formula(demand = e(\"Z\") + t(\"Z\") + s(\"N\"))),\n    names = [\"croston_sba\", \"croston_sbj\", \"croston_classic\", \"ses\", \"ets\"]\n)\n\n# Fit all models to panel data\nfitted = fit(models, panel)\n\n# Generate forecasts with all methods\nfc = forecast(fitted, h = 12)\n\n# Compare accuracy against test data\nacc_results = accuracy(fc, test_data)\n\n# Find best performing model\nbest_model = acc_results.model_name[argmin(acc_results.MAPE)]\nprintln(\"Best model: \", best_model)\n\n# Visualize comparison\nplot(fc, series = \"product_123\", actual = test_data)","category":"section"},{"location":"grammar/#Use-Cases-and-Best-Practices","page":"Grammar","title":"Use Cases and Best Practices","text":"When to use Croston methods:\n\nTime series with >50% zero values\nSporadic, irregular demand patterns\nSpare parts and slow-moving inventory\nSpecialty products with infrequent sales\n\nMethod selection:\n\n\"sba\" (Syntetos-Boylan Approximation): Best choice for most applications\n\"sbj\" (Shale-Boylan-Johnston): Alternative bias correction, try if SBA underperforms\n\"classic\": Historical comparison or when bias correction is not needed\n\"hyndman\": Quick baseline, simpler implementation\n\nParameter recommendations (Kourentzes 2014):\n\nUse cost_metric = \"mar\" or \"msr\" instead of classical MSE/MAE\nEnable number_of_params = 2 for separate smoothing of size and intervals\nSet optimize_init = true especially for short time series\nLet optimization run without restrictive parameter bounds\n\nIntegration tips:\n\nCroston works seamlessly with PanelData for multi-product forecasting\nCombine with other methods in ModelCollection for comprehensive comparison\nUse forecast_table() for tidy output ready for downstream analysis\nThe Croston grammar integrates with all Durbyn workflows—single series, grouped data, and model comparison","category":"section"},{"location":"grammar/#References","page":"Grammar","title":"References","text":"Croston, J. (1972). \"Forecasting and stock control for intermittent demands\". Operational Research Quarterly, 23(3), 289-303.\nSyntetos, A.A. and Boylan, J.E. (2005). \"The accuracy of intermittent demand estimates\". International Journal of Forecasting, 21(2), 303-314.\nKourentzes, N. (2014). \"On Intermittent Demand Model Optimisation and Selection\". International Journal of Production Economics, 156, 180-190.\n\n","category":"section"},{"location":"grammar/#Tips-and-Best-Practices","page":"Grammar","title":"Tips and Best Practices","text":"","category":"section"},{"location":"grammar/#ARIMA-Tips","page":"Grammar","title":"ARIMA Tips","text":"Any range triggers automatic model selection\nFixed orders call fast direct estimation\nExogenous support includes explicit columns, auto(), or complex formulas\nCombine with PanelData to store group/date metadata cleanly\nIf you omit newdata when forecasting, Durbyn reuses each group's most recent exogenous values","category":"section"},{"location":"grammar/#ETS-Tips","page":"Grammar","title":"ETS Tips","text":"Always specify m (seasonal period) when you expect seasonal behavior. If you omit it, ETS defaults to m = 1\nKeywords like lambda, alpha, or ic are forwarded directly to the underlying ets implementation\nGrouped fits reuse the same grammar—fit(spec, data; groupby = [:region]) returns GroupedFittedModels\nForecast works the same way for both single and grouped models","category":"section"},{"location":"grammar/#General-Tips","page":"Grammar","title":"General Tips","text":"Use PanelData to encapsulate grouping, date, and seasonal period information\nSpecifications are reusable—define once, fit to multiple datasets\nKeywords in fit() override those stored in the spec\nforecast_table() provides tidy output for downstream analysis and visualization\nCombine multiple specs in a ModelCollection for easy model comparison","category":"section"},{"location":"intermittent/#Intermittent-Demand-Forecasting","page":"Intermittent Demand","title":"Intermittent Demand Forecasting","text":"","category":"section"},{"location":"intermittent/#Overview","page":"Intermittent Demand","title":"Overview","text":"Intermittent demand occurs in time series with many zero values and occasional non-zero spikes, commonly found in spare parts inventory, specialty products, and slow-moving items. Traditional forecasting methods like ARIMA or exponential smoothing perform poorly on such data due to the preponderance of zeros and the sporadic nature of demand occurrences.\n\nThe Croston family of methods addresses intermittent demand by decomposing the forecasting problem into separate components: demand size when it occurs and demand timing (intervals or probabilities). This decomposition enables more accurate modeling of the underlying demand process.","category":"section"},{"location":"intermittent/#Croston's-Method","page":"Intermittent Demand","title":"Croston's Method","text":"Croston's method models intermittent demand by maintaining two exponentially smoothed states: demand size z_t when demand occurs, and inter-demand intervals x_t.\n\nReferences:\n\nCroston, J. (1972). \"Forecasting and stock control for intermittent demands\". Operational Research Quarterly, 23(3), 289-303.\nShenstone, L., and Hyndman, R.J. (2005). \"Stochastic models underlying Croston's method for intermittent demand forecasting\". Journal of Forecasting, 24, 389-402.","category":"section"},{"location":"intermittent/#Notation","page":"Intermittent Demand","title":"Notation","text":"y_t: observed demand at time t (often zero)\nz_t: non-zero demand size (observed only when y_t  0)\nx_t: inter-demand interval (time between non-zero demands)\nhatz_t hatx_t: exponentially smoothed estimates\nalpha_z alpha_x in (01: smoothing parameters for size and interval\nq: number of non-zero demands observed up to time t","category":"section"},{"location":"intermittent/#Update-Equations","page":"Intermittent Demand","title":"Update Equations","text":"The exponential smoothing updates occur only when demand is observed (y_t  0):\n\nhatz_q = alpha_z z_t + (1-alpha_z)hatz_q-1\n\nhatx_q = alpha_x x_t + (1-alpha_x)hatx_q-1\n\nwhere x_t is the time since the previous non-zero demand.","category":"section"},{"location":"intermittent/#Forecast","page":"Intermittent Demand","title":"Forecast","text":"The Croston forecast represents the expected demand rate per period:\n\nhaty_t+h = frachatz_qhatx_q quad h geq 1\n\nThis forecast is constant for all future periods (flat forecast profile).","category":"section"},{"location":"intermittent/#Implementation-Types","page":"Intermittent Demand","title":"Implementation Types","text":"The implementation handles four distinct cases based on the data characteristics:\n\nCrostonOne: All demands are zero - returns zero forecast\nCrostonTwo: Only one non-zero demand and one interval - returns constant forecast\nCrostonThree: Insufficient data (≤1 demand or ≤1 interval) - returns NaN\nCrostonFour: Standard case with multiple demands - applies full Croston method","category":"section"},{"location":"intermittent/#Data-Structures","page":"Intermittent Demand","title":"Data Structures","text":"","category":"section"},{"location":"intermittent/#CrostonFit","page":"Intermittent Demand","title":"CrostonFit","text":"Stores the fitted Croston model containing:\n\nmodely: Simple exponential smoothing model for demand sizes\nmodelp: Simple exponential smoothing model for inter-demand intervals\ntype: One of four CrostonType enum values indicating the fitting approach\nx: Original demand series\ny: Non-zero demands only\ntt: Inter-demand intervals\nm: Seasonal period (typically 1 for non-seasonal intermittent demand)","category":"section"},{"location":"intermittent/#CrostonForecast","page":"Intermittent Demand","title":"CrostonForecast","text":"Stores forecast output containing:\n\nmean: Forecast values (demand rate per period)\nmodel: The underlying CrostonFit object\nmethod: Description string (\"Croston's Method\")\nm: Seasonal period","category":"section"},{"location":"intermittent/#Functions","page":"Intermittent Demand","title":"Functions","text":"","category":"section"},{"location":"intermittent/#croston(y,-m;-alpha,-options)","page":"Intermittent Demand","title":"croston(y, m; alpha, options)","text":"Fits a Croston model to intermittent demand data.\n\nArguments:\n\ny::AbstractArray: Demand time series (may contain zeros)\nm::Int: Seasonal period (default: 1)\nalpha::Union{Float64,Bool,Nothing}: Smoothing parameter (nothing for automatic optimization)\noptions::NelderMeadOptions: Optimization settings for parameter estimation\n\nReturns:\n\nCrostonFit: Fitted model object\n\nExample:\n\nusing Durbyn.ExponentialSmoothing\n\n# Intermittent demand data\ndemand = [0, 0, 5, 0, 0, 3, 0, 0, 0, 7, 0, 0, 4, 0, 0]\n\n# Fit Croston model with automatic parameter optimization\ncroston_model = croston(demand)\n\n# Fit with fixed smoothing parameter\nfit_fixed = croston(demand, alpha=0.1)","category":"section"},{"location":"intermittent/#forecast(object::CrostonFit,-h::Int)","page":"Intermittent Demand","title":"forecast(object::CrostonFit, h::Int)","text":"Generates forecasts from a fitted Croston model.\n\nArguments:\n\nobject::CrostonFit: Fitted Croston model\nh::Int: Forecast horizon (number of periods ahead)\n\nReturns:\n\nCrostonForecast: Forecast object containing mean forecasts\n\nExample:\n\n# Generate 12-period-ahead forecast\nfc = forecast(fit, 12)\nprintln(fc.mean)  # Access forecast values","category":"section"},{"location":"intermittent/#fitted(object::CrostonFit)","page":"Intermittent Demand","title":"fitted(object::CrostonFit)","text":"Computes in-sample fitted values using one-step-ahead forecasts.\n\nArguments:\n\nobject::CrostonFit: Fitted Croston model\n\nReturns:\n\nVector: Fitted values (same length as original series)\n\nNote: The first value is NaN as no forecast is available for the first observation.\n\nExample:\n\nfitted_vals = fitted(fit)\nresiduals = demand .- fitted_vals","category":"section"},{"location":"intermittent/#plot(forecast::CrostonForecast;-show_fittedfalse)","page":"Intermittent Demand","title":"plot(forecast::CrostonForecast; show_fitted=false)","text":"Visualizes the forecast with optional fitted values.\n\nArguments:\n\nforecast::CrostonForecast: Forecast object to plot\nshow_fitted::Bool: Whether to display in-sample fitted values (default: false)\n\nReturns:\n\nPlots.jl plot object\n\nExample:\n\n# Plot forecast only\nplot(fc)\n\n# Plot forecast with fitted values\nplot(fc, show_fitted=true)","category":"section"},{"location":"intermittent/#Syntetos-Boylan-Approximation-(SBA)","page":"Intermittent Demand","title":"Syntetos-Boylan Approximation (SBA)","text":"The SBA method applies a bias correction to Croston's forecast. Syntetos and Boylan (2005) showed that Croston's method produces biased forecasts and proposed the following correction:\n\nhaty_t+h = left(1 - fracalpha_x2right) frachatz_qhatx_q\n\nThis correction reduces the upward bias inherent in the original Croston method.","category":"section"},{"location":"intermittent/#Teunter-Syntetos-Babai-(TSB)-Method","page":"Intermittent Demand","title":"Teunter-Syntetos-Babai (TSB) Method","text":"The TSB method reformulates the intermittent demand problem by modeling demand occurrence probability p_t and demand size z_t separately. This method provides an alternative theoretical framework but is not currently implemented in the IntermittentDemand module.","category":"section"},{"location":"intermittent/#Theoretical-Framework","page":"Intermittent Demand","title":"Theoretical Framework","text":"The probability of demand is updated every period:\n\nhatp_t = alpha_p d_t + (1-alpha_p)hatp_t-1\n\nwhere d_t = 1 if y_t  0, and d_t = 0 otherwise.\n\nThe demand size is updated only when demand occurs:\n\nhatz_q = alpha_z z_t + (1-alpha_z)hatz_q-1","category":"section"},{"location":"intermittent/#Forecast-2","page":"Intermittent Demand","title":"Forecast","text":"The TSB forecast is:\n\nhaty_t+h = hatp_t cdot hatz_q","category":"section"},{"location":"intermittent/#Shale-Boylan-Johnston-(SBJ)-Method","page":"Intermittent Demand","title":"Shale-Boylan-Johnston (SBJ) Method","text":"The SBJ method provides an alternative bias correction to Croston's method, particularly suited for Poisson demand arrivals. The correction factor is derived from the theoretical properties of the demand process.","category":"section"},{"location":"intermittent/#Optimization-and-Loss-Functions","page":"Intermittent Demand","title":"Optimization and Loss Functions","text":"","category":"section"},{"location":"intermittent/#Traditional-Loss-Functions","page":"Intermittent Demand","title":"Traditional Loss Functions","text":"Classical forecasting metrics often perform poorly for intermittent demand:\n\nMean Squared Error (MSE): displaystyle frac1nsum_t=1^n(y_t-haty_t)^2\nMean Absolute Error (MAE): displaystyle frac1nsum_t=1^ny_t-haty_t\n\nThese metrics compare forecasts against predominantly zero actual values, leading to downward-biased parameter estimates.","category":"section"},{"location":"intermittent/#Rate-Based-Loss-Functions","page":"Intermittent Demand","title":"Rate-Based Loss Functions","text":"Since Croston-type methods produce rate forecasts (expected demand per period), Kourentzes (2014) demonstrated that rate-based loss functions yield superior results:\n\nRate residual at time t:\n\nr_t = haty_t - frac1tsum_j=1^t y_j\n\nMean Absolute Rate error (MAR):\n\ntextMAR = frac1nsum_t=1^n r_t\n\nMean Squared Rate error (MSR):\n\ntextMSR = frac1nsum_t=1^n r_t^2","category":"section"},{"location":"intermittent/#Empirical-Findings","page":"Intermittent Demand","title":"Empirical Findings","text":"Kourentzes (2014) established through extensive simulation that:\n\nMAR and MSR perform equivalently and both substantially outperform MSE/MAE\nSeparate smoothing parameters (alpha_z neq alpha_x) improve performance for Croston variants\nInitial state optimization enhances accuracy, particularly for short series\nParameter bounds should allow values up to 1.0; restrictive upper bounds (e.g., 0.3) can degrade performance\nSmall smoothing parameters (typically 0.05-0.2) emerge naturally with proper optimization","category":"section"},{"location":"intermittent/#Model-Selection","page":"Intermittent Demand","title":"Model Selection","text":"Kourentzes (2014) found that:\n\nSimple Croston variants often perform competitively with complex model selection schemes\nBias-corrected methods (SBA, SBJ) generally outperform the classical Croston method\nFocus on proper optimization (using rate-based losses with separate parameters) matters more than complex model selection","category":"section"},{"location":"intermittent/#Implementation-Details","page":"Intermittent Demand","title":"Implementation Details","text":"The IntermittentDemand module provides three main functions that implement the Kourentzes (2014) recommendations:","category":"section"},{"location":"intermittent/#Available-Methods","page":"Intermittent Demand","title":"Available Methods","text":"croston_classic(): Classical Croston method\ncroston_sba(): Syntetos-Boylan Approximation\ncroston_sbj(): Shale-Boylan-Johnston bias correction","category":"section"},{"location":"intermittent/#Key-Parameters","page":"Intermittent Demand","title":"Key Parameters","text":"All methods support the following parameters aligned with Kourentzes (2014) findings:\n\ncost_metric: Loss function for optimization\n\"mar\" (recommended): Mean Absolute Rate error\n\"msr\" (recommended): Mean Squared Rate error\n\"mae\": Mean Absolute Error (classical)\n\"mse\": Mean Squared Error (classical)\nnumber_of_params: Number of smoothing parameters\n1: Single parameter for both size and interval\n2 (recommended): Separate parameters (alpha_z neq alpha_x)\noptimize_init: Whether to optimize initial states\ntrue (recommended): Optimize initial values\nfalse: Use heuristic initialization\ninit_strategy: Initialization method\n\"mean\" (default): Use mean of non-zero values and intervals\n\"naive\": Use first observed values","category":"section"},{"location":"intermittent/#Implementation-Notes","page":"Intermittent Demand","title":"Implementation Notes","text":"Rate-based optimization: MAR and MSR losses are implemented as recommended\nSeparate smoothing parameters: Supported via number_of_params = 2\nParameter bounds: Allow values up to 1.0 (no restrictive caps)\nBias corrections: SBA and SBJ corrections are built into the respective methods","category":"section"},{"location":"intermittent/#Forecasting-in-Julia","page":"Intermittent Demand","title":"Forecasting in Julia","text":"using Durbyn\nusing Durbyn.IntermittentDemand\n\n# Intermittent demand data\ndata = [6, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0,\n        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n        0, 0, 0, 0, 0]\n\n# Classical Croston method (using recommended MAR cost metric)\nfit_croston = croston_classic(data, cost_metric = \"mar\")\nfc_croston = forecast(fit_croston, h = 12)\n\n# Syntetos-Boylan Approximation with separate smoothing parameters\nfit_sba = croston_sba(data, cost_metric = \"mar\", number_of_params = 2)\nfc_sba = forecast(fit_sba, h = 12)\n\n# Shale-Boylan-Johnston method with initial state optimization\nfit_sbj = croston_sbj(data, cost_metric = \"mar\", optimize_init = true)\nfc_sbj = forecast(fit_sbj, h = 12)\n\n# Alternative cost metrics (classical - use with caution)\nfit_mse = croston_classic(data, cost_metric = \"mse\")  # Traditional MSE\nfit_mae = croston_classic(data, cost_metric = \"mae\")  # Traditional MAE\nfit_msr = croston_classic(data, cost_metric = \"msr\")  # Mean Squared Rate\n\n# Visualization\nplot(fc_croston, show_fitted = true)\nplot(fc_sba, show_fitted = true)\nplot(fc_sbj, show_fitted = true)\n\n# Model diagnostics\nresiduals(fit_croston)\nfitted(fit_croston)\n\n# Model comparison\nprintln(\"Croston weights: \", fit_croston.weights)\nprintln(\"SBA weights: \", fit_sba.weights)\nprintln(\"SBJ weights: \", fit_sbj.weights)","category":"section"},{"location":"intermittent/#Reference","page":"Intermittent Demand","title":"Reference","text":"Kourentzes, N. (2014). On Intermittent Demand Model Optimisation and Selection. International Journal of Production Economics, 156: 180-190.","category":"section"}]
}
